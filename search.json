[
  {
    "objectID": "topics/data-archiving.html",
    "href": "topics/data-archiving.html",
    "title": "Data Archiving",
    "section": "",
    "text": "When we mention data archiving at VU Amsterdam, we mean the following:\n\nCreation of a secure and immutable copy of research data, associated metadata, accompanying documentation, and software code (where relevant) with the intention to ensure (conditional) access for a predetermined, minimum, period of time.\n\nAs stated in the Research Data and Software Management Policy, researchers are responsible for archiving all research data and software that leads to a published result (either in an article or other narrative form) in a trusted repository for a period of at least ten years after this publication, unless legal requirements, discipline-specific guidelines or contractual arrangements dictate otherwise."
  },
  {
    "objectID": "topics/data-archiving.html#what-is-data-archiving",
    "href": "topics/data-archiving.html#what-is-data-archiving",
    "title": "Data Archiving",
    "section": "",
    "text": "When we mention data archiving at VU Amsterdam, we mean the following:\n\nCreation of a secure and immutable copy of research data, associated metadata, accompanying documentation, and software code (where relevant) with the intention to ensure (conditional) access for a predetermined, minimum, period of time.\n\nAs stated in the Research Data and Software Management Policy, researchers are responsible for archiving all research data and software that leads to a published result (either in an article or other narrative form) in a trusted repository for a period of at least ten years after this publication, unless legal requirements, discipline-specific guidelines or contractual arrangements dictate otherwise."
  },
  {
    "objectID": "topics/data-archiving.html#purpose",
    "href": "topics/data-archiving.html#purpose",
    "title": "Data Archiving",
    "section": "Purpose",
    "text": "Purpose\nData archiving is crucial for enabling verification of research data. Verification is important for a transparent research practice, a value VU Amsterdam is strongly committed to. Archiving your data ensures that data will be preserved for the long term and that data can be accessed if necessery, even when the Principal Investigator or other members of the research team are no longer available at VU Amsterdam."
  },
  {
    "objectID": "topics/data-archiving.html#requirements",
    "href": "topics/data-archiving.html#requirements",
    "title": "Data Archiving",
    "section": "Requirements",
    "text": "Requirements\nAt VU Amsterdam, we strive to make our research data FAIR. When datasets are archived in a repository provided by VU Amsterdam (Yoda or DataverseNL, the following requirements apply:\n\nthe data must be provided with Metadata according to the VU Minimal metadata guide;\nthe data and software must have a Persistent identifier (or Identifiers) to increase findability;\na licence must be applied to the data and software in order to indicate if it can be reused by others and if so, under which conditions.\n\nIf you use an external repository, these requirements are useful to keep in mind as well, because they make the data FAIR to a large extent, but in that case you will have to rely on the properties of the repository."
  },
  {
    "objectID": "topics/data-archiving.html#how-does-data-archiving-work-in-practice",
    "href": "topics/data-archiving.html#how-does-data-archiving-work-in-practice",
    "title": "Data Archiving",
    "section": "How does data archiving work in practice?",
    "text": "How does data archiving work in practice?\nAs mentioned above, data archiving must happen in a repository. This means that data storage solutions for during research, like Research Drive, are not suitable for data archiving. They don’t generate a Persistent Identifier and do not ask for metadata or a licence. Detailed workflows addressing archiving data can be found in the guides about making your data FAIR and archiving and publishing data."
  },
  {
    "objectID": "topics/data-backup.html",
    "href": "topics/data-backup.html",
    "title": "Data Backup",
    "section": "",
    "text": "Backing up your data is about ensuring your data are in at least two and ideally three independent places."
  },
  {
    "objectID": "topics/data-backup.html#why-backup",
    "href": "topics/data-backup.html#why-backup",
    "title": "Data Backup",
    "section": "Why backup?",
    "text": "Why backup?\nHard drives fail, computers get stolen or lost, or your data may accidentally get deleted. To avoid data loss, backing up your data regularly is essential. Ideally, you should have your data stored in at least two, but ideally three different locations. Most cloud-based tools will automatically do backup for you, but they don’t protect you from your own mistakes. If you work with data that cannot be easily recreated or recalculated and ensure that it is sufficiently backed up with the 3-2-1 rule. This is especially important when migrating your data, such as when updating your operating system to a new major version, or when you get a new computer."
  },
  {
    "objectID": "topics/data-backup.html#rule",
    "href": "topics/data-backup.html#rule",
    "title": "Data Backup",
    "section": "3-2-1 Rule",
    "text": "3-2-1 Rule\nThe 3-2-1 rule states that you should have:\n\n3 Copies of your data\n2 Different mediums (2 different kinds of storage)\n1 Copy is kept off-site\n\nIdeally, this is automated so that you as a user do not have to manually do anything extra to manage your data. If possible, automate this backup as well with computer scheduling tools such as Task Scheduler (Windows) or Crontab (Linux)."
  },
  {
    "objectID": "topics/data-backup.html#simple-synchronizing-solutions",
    "href": "topics/data-backup.html#simple-synchronizing-solutions",
    "title": "Data Backup",
    "section": "Simple Synchronizing Solutions",
    "text": "Simple Synchronizing Solutions\nThe VU provides access to multiple storage systems. You may use a mix of the different platforms. If you use these tools they will automatically synchronize your files to the cloud. If you accidentally delete a file, you can restore your folder to a previous date - various systems will have different retention periods but it is usually around 1 month."
  },
  {
    "objectID": "topics/data-backup.html#notes",
    "href": "topics/data-backup.html#notes",
    "title": "Data Backup",
    "section": "Notes",
    "text": "Notes\nUtrecht University Geo Data Team Services provide a detailed page on data backup including a discussion of data selection for backup.\nWhen your laptop and hard drive are in the same bag, the “backup” can easily get lost along with the primary data and there is thus no proper backup.\nThese are just some tips, please take responsibility over your data and make sure it’s protected from loss but also from your own mistakes."
  },
  {
    "objectID": "topics/research-data-management.html",
    "href": "topics/research-data-management.html",
    "title": "Research Data Management (RDM)",
    "section": "",
    "text": "RDM concerns the organisation, documentation, storage, archiving and sharing of digital and analogue data. Data management applies throughout the entire research data life cycle, which is visualised in the circle above. RDM aims to ensure reliable verification of results, and permits new and innovative research built on existing information. RDM is also part of the research process and is intended to make the research process as efficient as possible. The VU CS Department RDM and Open Science Handbook provides guidance on research data management planning, data storage and protection, data archiving, and other resources. The Data Management Plan provides information on how these activities will be carried out during the research project.\nGood data management will heighten the quality of your own research (data) as well as your institution’s scientific output, and it contributes significantly to your field as a whole.\nGood data management:\n\nPromotes the integrity of your research,\nIncreases the impact of your research,\nImproves the quality of your data,\nSupports future use of your research data, and\nComplies with internal and external regulations."
  },
  {
    "objectID": "topics/data-management-plan.html",
    "href": "topics/data-management-plan.html",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "A Data Management Plan (DMP) is a document outlining how research data will be handled throughout the research life cycle. A DMP is a structured way to address data collection, organization, storage, sharing, and preservation. It also outlines the measures taken to ensure data security and addresses how data will be preserved and made available for future use."
  },
  {
    "objectID": "topics/data-management-plan.html#what-is-a-dmp",
    "href": "topics/data-management-plan.html#what-is-a-dmp",
    "title": "Data Management Plan (DMP)",
    "section": "",
    "text": "A Data Management Plan (DMP) is a document outlining how research data will be handled throughout the research life cycle. A DMP is a structured way to address data collection, organization, storage, sharing, and preservation. It also outlines the measures taken to ensure data security and addresses how data will be preserved and made available for future use."
  },
  {
    "objectID": "topics/data-management-plan.html#dmponline",
    "href": "topics/data-management-plan.html#dmponline",
    "title": "Data Management Plan (DMP)",
    "section": "DMPonline",
    "text": "DMPonline\nVU Amsterdam offers the online tool DMPonline for writing Data Management Plans. DMPonline is a platform that offers a range of templates, ensuring that researchers can create DMPs to meet the standards of diverse funders and institutions associated with their projects. DMPonline makes it easy to work on a DMP together with colleagues, advisors, or other stakeholders. VU Amsterdam researchers can use the request feedback function of DMPonline to get their DMP reviewed by a faculty data steward or RDM Support Desk colleague.\nIf you have questions about DMPonline, or encounter problems when using the tool, please get in touch with rdm@vu.nl."
  },
  {
    "objectID": "topics/data-management-plan.html#choosing-the-right-template",
    "href": "topics/data-management-plan.html#choosing-the-right-template",
    "title": "Data Management Plan (DMP)",
    "section": "Choosing the right template",
    "text": "Choosing the right template\nVarious templates exist in which you can set up your DMP. We strongly recommend that you use the VU template, which is called VU DMP template 2021 (NWO & ZonMw certified) v1.4. Below you’ll find an explanation of how to access this template. If you need to write a DMP for funding agencies NWO, ZonMw or ERC, you can use the VU template as well.\n\nVU template\nYou can find the VU DMP template in DMPonline. It includes concise guidance on how to complete your DMP.\nYou can select the VU template by taking the following steps (see also the picture below).\n\nOn your dashboard, click on Create plan.\nEnter the title of your research project (you don’t have to select the check box for mock testing).\nSelect Vrije Universiteit Amsterdam as your primary research organisation.\nFor the question on primary funding organisation, select the check box on the right, saying that no funder is associated with your plan.\n\nNote: Follow these steps as well if you receive funding from NWO or ZonMw (see also below).\n\n\n\nScreenshot of a form for creating a data management plan, asking for the research project, where it is being done, who is funding it and what template you would like to use.\n\n\nIf you’re aiming to write a full DMP based on VU Amsterdam DMP template, please make sure you don’t select the GDPR registration form.\n\n\n\nA screenshot highlighting to not use VU Amsterdam GDPR Registration form\n\n\n\n\nFunder template\nWe recommend researchers to use VU Amsterdam DMP template whenever possible, especially for researchers who work with personal data. The VU DMP template includes questions that serve as input for the GDPR record of processing activities. This means that when you write a DMP based on the VU DMP template, you simultaneousely comply with the VU requirement to register the personal data you use in your research.\nHowever, it is also possible to use other templates in DMPonline. If your funder or partner organization requires you to use a certain template, it is possible to select that template in DMPonline. Please follow the steps below to select a funder’s template.\n\nOn your dashboard, click on Create plan.\nEnter the title of your research project (you don’t have to select the check box for mock testing).\nSelect Vrije Universiteit Amsterdam as your primary research organisation.\nIn the field under Select the primary funding organisation, start typing the name of your funder and select their template.\n\n\n\n\nScreenshot of a filled out form for creating a data management plan, with example data included.\n\n\nResearchers who don’t work with personal data and who wish to use another DMP template than the VU template, can also follow the steps above."
  },
  {
    "objectID": "topics/data-management-plan.html#register-your-processing-activities",
    "href": "topics/data-management-plan.html#register-your-processing-activities",
    "title": "Data Management Plan (DMP)",
    "section": "Register your processing activities",
    "text": "Register your processing activities\n\nHow does registration of personal data processing work in research?\nIf your research is subject to the GDPR, then you need to register information on your research in a central VU registry. This central registry lists all personal data processing activities carried out at VU Amsterdam. The registry indicates why and how personal data are processed, and with whom they are shared. The registry helps VU Amsterdam demonstrate compliance with the GDPR and in the case of a data breach, the registry helps with monitoring and acting swiftly to inform all relevant stakeholders.\nFor research projects, VU Amsterdam registers data processing via DMPonline. You can create your registration by logging into DMPonline and following the following instructions:\n\nOn your dashboard, click on Create plan.\nEnter the title of your research project (you don’t have to select the check box for mock testing).\nSelect Vrije Universiteit Amsterdam as your primary research organisation.\nFor the question on primary funding organisation, select the check box on the right, saying that no funder is associated with your plan.\n\n\n\n\nScreenshot of a form for creating a data management plan, asking for the research project, where it is being done, who is funding it and what template you would like to use.\n\n\nOnce you get to the two VU templates, you can fill in the VU DMP template 2021 v1.4 if you need to write a DMP anyway; the information you include in this DMP template will be used for the registry. If you don’t need to write a (new) DMP, you can use the separate VU GDPR registration form for research v1.1. Your faculty’s 🔒 Privacy Champion can help you with your registration.\nIf your research is primarily led by Amsterdam UMC, location VUmc, your research will be registered using their own separate system.\n\n\nRegister before you start your data collection\nIf you use personal data in your research, you should register your data processing activities before you start data collection. If you are not sure whether your research data are subject to the GDPR, contact your faculty’s 🔒 Privacy Champion. Your privacy champion can also assist you if your research is already running, but has not yet been registered."
  },
  {
    "objectID": "topics/data-management-plan.html#what-is-data",
    "href": "topics/data-management-plan.html#what-is-data",
    "title": "Data Management Plan (DMP)",
    "section": "What is data",
    "text": "What is data\nResearch data is any information that has been collected, observed, generated or created to validate original research findings. Examples of data could be interview recordings, experiment results, physical measurement, notes from focus group’s meetings, notes from fieldwork, observations captured in photographs, film or audio, text files extracted from a corpus, image of archival items or artworks, scraped websites, responses to survey questions. Algorithms, simulations, code, scripts and software are often also considered as research data. There is also physical data: (biological) samples, collections, artifacts etc.\nAdministrative documents, like informed consent forms and key files should be acknowledged as important elements of research data as well."
  },
  {
    "objectID": "topics/data-management-plan.html#data-assets",
    "href": "topics/data-management-plan.html#data-assets",
    "title": "Data Management Plan (DMP)",
    "section": "Data Assets",
    "text": "Data Assets\nAt VU Amsterdam, we sometimes use the term ‘Data Assets’. You can think of data assets as small ‘parcels’ of data that can change form or format throughout the research. For example, if you’re sending out surveys for your research, the survey responses are considered a data asset. If, in addition to the surveys, you’re also holding focus groups, the data collected from the focus group are also considered a data asset, separate from the survey results. Most projects will have more than one data asset per data stage. It is common to provide data assets based on the data stage such as raw, processed, or analysed. Raw Data refers to original data collected, Processed Data is data that has undergone some level of transformation or organisation. Processing involves cleaning, formatting, and structuring raw data to make them more understandable and suitable for analysis. Analysed Data usually results from statistical methods, detailed examination or interpretation.\nHere are some examples of data assets in research data management:\n\n\n\n\n\n\n\n\n\nData Stage\nDataset description\nType of data\nFormat\n\n\n\n\nRaw data\nInterviews\nAudio files\nMP3\n\n\n\nSpectographic analysis\nText files\nCSV\n\n\nProcessed data\nTranscription of interviews\nText files\nDocx\n\n\n\nData spreadsheet\nSPSS files\nSAV\n\n\nAnalysed data\nRegression graphic\nGraph\nPNG\n\n\n\nData table\nWord file\nDocx\n\n\nOther\nPoster presentation\nPowerpoint\nPPS\n\n\n\nProject Website\nHTML\n\n\n\n\nAnalysis code\nText files\nPython\n\n\n\nNote that these data assets also change in the different phases of the research! While the interview data are audio files in the raw stage, they are transcribed and become text files in the processed stage."
  },
  {
    "objectID": "topics/data-management-plan.html#dmp-elements",
    "href": "topics/data-management-plan.html#dmp-elements",
    "title": "Data Management Plan (DMP)",
    "section": "DMP Elements",
    "text": "DMP Elements\nVU Amsterdam DMP template consists of seven sections with questions. In DMPonline, there is guidance available for all sections, as well as example answers. When you are writing your DMP, you can consult this information directly in DMPonline. Below we provide references to information and support available for various RDM-related aspects.\n\nLegal and ethical requirements, codes of conduct\nIf you have questions about working with personal data in research, please get in touch with the Privacy Champion of your faculty. The 🔒 overview of Privacy Champions can be found on VU Amsterdam website. Make sure to contact your Privacy Champion in the following situations:\n\nIf you need to carry out a DPIA, or if you’re unsure if you need to do one\nIf you work with special category personal data, or otherwise very sensitive data\nIf you are collaborating with other parties\nIf you need software for which no licence is set up on behalf of VU Amsterdam\nIf you wish to reuse existing data containing personal data\n\nIt is impossible to provide an overview of tasks to be carried out to ensure compliance with the GDPR that fits all research projects. For that reason, it is important to contact your Privacy Champion. They will be able to identify what needs to be arranged to adhere to the GDPR.\nEthical aspects of research should be addressed in the ethics procedure of your faculty. Each faculty has their own ethics committee. The webpages of all committees are listed below. Please go to the page of the ethics committee of your faculty to find instructions for ethical review procedures for your study.\n\nACTA: ACTA Institutional Review Board (IRB)\nBeta: Research ethics review committee Faculty of Science (BETHCIE)\nFGB: 🔒 Scientific and Ethical Review Board (VCWE)\nFGW: Ethische Toetsingscommissie Onderzoek (EtCO)\nFSW: 🔒 Research Ethics Review Committee (RERC)\nRCH (Faculty of Law): Ethics Committee\nVUmc: METc (Medical Ethical Review Committee)\n\n\n\nStorage and backup during the research process\nAn overview of storage facilities at VU Amsterdam is available in the Data Storage Finder. You can use this as a starting point to navigate storage solutions.\nIf you have questions about data storage and backup, send an email to rdm@vu.nl.\n\n\nData archiving and publishing\nIf your research data contains personal data and you’re unsure about which data may be published, please contact your 🔒 Privacy Champion."
  },
  {
    "objectID": "topics/data-licensing.html",
    "href": "topics/data-licensing.html",
    "title": "Data Licensing",
    "section": "",
    "text": "A data licence agreement is a legal instrument that lets others know what they can and cannot do with your research data (and any documentation, scripts and metadata that are published with the data - information about software licensing can be found on the software licensing page). It is important to consider what kind of limitations are relevant. Usually, at least the following questions are considered:\n\nCan people make copies or even distribute copies?\nDo others (and you) reusing the dataset need to acknowledge you as the author of the original dataset? (This is called Attribution.)\nDo others (and you) who reuse the dataset and/or make derivatives of the dataset need to share their work under a similar licence? (This is called Share-Alike.)\nCan others (and you) use your dataset commercially? (A restriction on commercial use is called Non-Commercial.)\nCan others (and you) create a new work based on the dataset? (This is called a Derivative.)\n\nThe considerations above are the ‘building blocks’ that Creative Commons licences use. There are also other considerations, and also other licences.\n\n\n\nAn image of open data, made up of public domain icons\n\n\nIn principle, Dataverse allows you to choose your terms of use. If you publish your data in Yoda, there is guidance available on how to choose a licence and how to customise licences. Some data repositories require you to use a certain licence if you want to deposit your data with them. At Dryad, for example, all datasets are published under the terms of Creative Commons Zero to minimise legal barriers and to maximise the impact for research and education. Some funders may also require that you publish the data as open data. Open data are data that can be freely used, re-used and redistributed by anyone - subject only, at most, to the requirement to attribute and share alike (Open Knowledge International definition). If you need help with drawing up licence agreements, you can contact the VU’s legal office."
  },
  {
    "objectID": "topics/data-licensing.html#licensing-the-data",
    "href": "topics/data-licensing.html#licensing-the-data",
    "title": "Data Licensing",
    "section": "",
    "text": "A data licence agreement is a legal instrument that lets others know what they can and cannot do with your research data (and any documentation, scripts and metadata that are published with the data - information about software licensing can be found on the software licensing page). It is important to consider what kind of limitations are relevant. Usually, at least the following questions are considered:\n\nCan people make copies or even distribute copies?\nDo others (and you) reusing the dataset need to acknowledge you as the author of the original dataset? (This is called Attribution.)\nDo others (and you) who reuse the dataset and/or make derivatives of the dataset need to share their work under a similar licence? (This is called Share-Alike.)\nCan others (and you) use your dataset commercially? (A restriction on commercial use is called Non-Commercial.)\nCan others (and you) create a new work based on the dataset? (This is called a Derivative.)\n\nThe considerations above are the ‘building blocks’ that Creative Commons licences use. There are also other considerations, and also other licences.\n\n\n\nAn image of open data, made up of public domain icons\n\n\nIn principle, Dataverse allows you to choose your terms of use. If you publish your data in Yoda, there is guidance available on how to choose a licence and how to customise licences. Some data repositories require you to use a certain licence if you want to deposit your data with them. At Dryad, for example, all datasets are published under the terms of Creative Commons Zero to minimise legal barriers and to maximise the impact for research and education. Some funders may also require that you publish the data as open data. Open data are data that can be freely used, re-used and redistributed by anyone - subject only, at most, to the requirement to attribute and share alike (Open Knowledge International definition). If you need help with drawing up licence agreements, you can contact the VU’s legal office."
  },
  {
    "objectID": "topics/data-licensing.html#additional-websites-and-tools",
    "href": "topics/data-licensing.html#additional-websites-and-tools",
    "title": "Data Licensing",
    "section": "Additional websites and tools:",
    "text": "Additional websites and tools:\n\nExplanation about copyrights and licences by a professor from Leiden University (English subtitles available)\nThe Guide to Creative Commons for Scholarly Publishing and Educational Resources by NWO, VSNU and the University and Royal Libraries\nDCC how-to guide on licensing research data, a guide that links to the Creative Commons website, where many terms are explained\nOpen Data Commons Public Domain Dedication and License (PDDL)\nEUDAT B2SHARE licence selection wizard, which Pawel Kamocki (et al.) released under an open source licence.1"
  },
  {
    "objectID": "topics/data-licensing.html#footnotes",
    "href": "topics/data-licensing.html#footnotes",
    "title": "Data Licensing",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor the source code, see https://github.com/ufal/public-license-selector/↩︎"
  },
  {
    "objectID": "topics/data-collection.html",
    "href": "topics/data-collection.html",
    "title": "Data Collection",
    "section": "",
    "text": "Data collection may consist of the re-use of existing data and/or the generation of new data.\nFor data to be considered valid and reliable, data collection should occur consistently and systematically throughout the course of the research project. Within disciplines, there are established methodologies, procedures and techniques that help researchers ensure high quality of collected data. In general, important aspects of data collection include:\nSystematic data collection is essential for ensuring the reproducibility of research. When data is collected in a consistent and organized manner, it improves the quality and reliability of the research, making the data easier to share and reproduce by others. High-quality data also contributes to making data FAIR (Findable, Accessible, Interoperable, and Reusable), as well-organized and well-documented data is more likely to be reused effectively. The principles of making data FAIR are discussed in detail under the topic FAIR Principles."
  },
  {
    "objectID": "topics/data-collection.html#data-collection-tools",
    "href": "topics/data-collection.html#data-collection-tools",
    "title": "Data Collection",
    "section": "Data Collection Tools",
    "text": "Data Collection Tools\nThe tools being used in research to collect data are immensely diverse. For that reason, we will not provide an exhaustive overview here. What is important for data collection tools in relation to RDM is where such tools store the data that you collect and in which format. The storage location is particularly important when you are working with personal data. For example, the privacy legislation in the United States is very different from the European General Data Protection Regulation (GDPR). Hence, personal data collected in a Dutch research institute may not be stored on American servers. It is important to keep that in mind when you are contemplating which tool to use for your data collection.\nIf you are collecting personal data and you decide to use a tool for which no contract exists between VU Amsterdam and the provider of the software or tool, a service agreement and a processing agreement must be drawn up. Contact the 🔒 privacy champion of your faculty for more information and a model processing agreement.\n\nQuestionnaire tools\nThe Faculty of Behavioural and Movement Sciences has developed a document with tips for safe use of the questionnaire tools Qualtrics and Survalyzer. The document was made for FGB researchers specifically but can also be helpful for others. Consult this document if you need a questionnaire tool to collect your data."
  },
  {
    "objectID": "topics/data-collection.html#data-collection-in-collaboration",
    "href": "topics/data-collection.html#data-collection-in-collaboration",
    "title": "Data Collection",
    "section": "Data Collection in Collaboration",
    "text": "Data Collection in Collaboration\nSome research projects involve the participation of multiple organisations or institutes and may include even cross-border co-operation. When data is collected by several organisations, a Data Management Plan should provide information on who is responsible for which part of the data collection and storage. It should also provide information on how specific data collections are related to which part(s) of the research goal(s). Describing this precisely will help you to determine if a consortium agreement or joint controller agreement is necessary. You see a general example of such a specification in the table below:\n\n\n\n\n\n\n\n\n\n\nData Stage\nDataset description\nResponsible organization for collection\nData origin\nData purpose\n\n\n\n\nRaw data\nCommunity level surveys\nVU Amsterdam\nAmsterdam, The Hague, Rotterdam\nIdentifying perceived problems, System responsiveness\n\n\nRaw data\nTrials & Focus Group Interviews\nLondon School of Hygiene and Tropical Medicine (LSHTM)\nGermany, Switzerland\nTrials to evaluate programs on . . ., Focus Group interviews to identify barriers to . . .\n\n\nRaw data\nPollution measurements using fish\nOceanographic Institute of Sweden\nCoastal waters, Northeast Spain\nEstablish pollution levels of plastic"
  },
  {
    "objectID": "topics/data-collection.html#data-collection-protocols",
    "href": "topics/data-collection.html#data-collection-protocols",
    "title": "Data Collection",
    "section": "Data Collection Protocols",
    "text": "Data Collection Protocols\nRegardless of the field of study or preference for defining data (quantitative, qualitative), accurate data collection is essential to maintaining the integrity (structure) of research. Both the selection of appropriate data collection instruments (existing, modified, or newly developed) and clearly delineated instructions for their correct use reduce the likelihood of errors.\nThere are two approaches for reducing and/or detecting errors in data which can help to preserve the integrity of your data and ensure scientific validity. These are:\n\nQuality assurance - activities that take place before data collection begins\nQuality control - activities that take place during and after data collection\n\nQuality assurance precedes data collection and its main focus is ‘prevention’ (i.e., forestalling problems with data collection). Prevention is the most cost-effective activity to ensure the integrity of data collection. This proactive measure is best demonstrated by the standardization of protocol developed in a comprehensive and detailed procedures manual for data collection.\nWhile quality control activities (detection/monitoring and action) occur during and after data collection, the details should be carefully documented in the procedures manual. A clearly defined communication structure is a necessary pre-condition for monitoring and tracking down errors. Quality control also identifies the required responses, or ‘actions’ necessary to correct faulty data collection practices and also minimise future occurrences.\nSome sources for protocols:\n\nHANDS Handbook for Adequate Natural Data Stewardship by the Federation of Dutch University Medical Centers (UMCs)\nProtocols.io - an open access repository of protocols\nProtocols Online - website with protocols available on the internet, sorted by discipline.\nSpringer Protocols - free and subscribed protocols collected by Springer."
  },
  {
    "objectID": "topics/research-software.html",
    "href": "topics/research-software.html",
    "title": "Research Software",
    "section": "",
    "text": "Examples of how research software is integral to research; from Nieuwpoort en Katz\n\n\nThere is a broad definition of research software from the FAIR4RS working group:\n\n“Research Software includes source code files, algorithms, scripts, computational workflows and executables that were created during the research process or for a research purpose. Software components (e.g., operating systems, libraries, dependencies, packages, scripts, etc) that are used for research but were not created during or with a clear research intent should be considered software in research and not Research Software.”\n\nIt is important to note that not all software that is used in research is research software.\nFor example, a text editor that is used to write a paper is not research software. Nor is powerpoint, a web browser, or the software used to guide the telescope. Even tools like R or Python are not necessarily research software.\nThe code written in R or Python for an analysis would be research software, however. Just like a custom-made Excel macro that is used to analyse data. Or a custom-made web application that is used to collect data.\nResearch Software is mainly used in “Collecting” and “Processing & analyzing” steps. However, non-research software can also be used in these steps, and research software can also be used in other steps.\nMaterials adapted from the Netherlands eScience Center under CC-BY 4.0."
  },
  {
    "objectID": "topics/research-software.html#what-is-research-software",
    "href": "topics/research-software.html#what-is-research-software",
    "title": "Research Software",
    "section": "",
    "text": "Examples of how research software is integral to research; from Nieuwpoort en Katz\n\n\nThere is a broad definition of research software from the FAIR4RS working group:\n\n“Research Software includes source code files, algorithms, scripts, computational workflows and executables that were created during the research process or for a research purpose. Software components (e.g., operating systems, libraries, dependencies, packages, scripts, etc) that are used for research but were not created during or with a clear research intent should be considered software in research and not Research Software.”\n\nIt is important to note that not all software that is used in research is research software.\nFor example, a text editor that is used to write a paper is not research software. Nor is powerpoint, a web browser, or the software used to guide the telescope. Even tools like R or Python are not necessarily research software.\nThe code written in R or Python for an analysis would be research software, however. Just like a custom-made Excel macro that is used to analyse data. Or a custom-made web application that is used to collect data.\nResearch Software is mainly used in “Collecting” and “Processing & analyzing” steps. However, non-research software can also be used in these steps, and research software can also be used in other steps.\nMaterials adapted from the Netherlands eScience Center under CC-BY 4.0."
  },
  {
    "objectID": "topics/compute-hub.html",
    "href": "topics/compute-hub.html",
    "title": "VU Compute Hub",
    "section": "",
    "text": "The VU Compute Hub is a JupyterHub instance hosted by IT at VU Amsterdam. It allows you to run a number of common analysis tools on a server. The Hub is mainly aimed at providing environments for student courses, but is available for VU researchers as well."
  },
  {
    "objectID": "topics/compute-hub.html#what-is-it",
    "href": "topics/compute-hub.html#what-is-it",
    "title": "VU Compute Hub",
    "section": "",
    "text": "The VU Compute Hub is a JupyterHub instance hosted by IT at VU Amsterdam. It allows you to run a number of common analysis tools on a server. The Hub is mainly aimed at providing environments for student courses, but is available for VU researchers as well."
  },
  {
    "objectID": "topics/compute-hub.html#what-can-it-be-used-for",
    "href": "topics/compute-hub.html#what-can-it-be-used-for",
    "title": "VU Compute Hub",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nThe VU Compute Hub is a great environment to try if your analysis takes too much time on a laptop. It allows you to use the graphical tools you are familiar with in an environment with more compute power where you can leave your script running until it is finished.\nSince every VU researcher can just log in, the barrier to entry is very low.\nBe aware the service is mainly aimed at education. If your scripts use a lot of resources, it might be time for you to start using a High Performance Computing (HPC) environment: ADA at VU Amsterdam or the national supercomputer Snellius. Please contact IT for Research to discuss the best options.\n\nAvailable tools\nThe following applications are currently available: Jupyter Notebooks, MATLAB, STATA, R Studio and QGIS."
  },
  {
    "objectID": "topics/compute-hub.html#how-to-request-access",
    "href": "topics/compute-hub.html#how-to-request-access",
    "title": "VU Compute Hub",
    "section": "How to request access",
    "text": "How to request access\nYou do not need to request access. You can log in with your VU credentials."
  },
  {
    "objectID": "topics/compute-hub.html#are-there-costs-involved",
    "href": "topics/compute-hub.html#are-there-costs-involved",
    "title": "VU Compute Hub",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThere are no costs involved."
  },
  {
    "objectID": "topics/compute-hub.html#getting-started",
    "href": "topics/compute-hub.html#getting-started",
    "title": "VU Compute Hub",
    "section": "Getting started",
    "text": "Getting started\nYou can access the Linux Compute Services through VU JupyterHub in your web browser. The VU JupyterHub gives you access to familiar interfaces like Jupyter Notebooks, MATLAB and R Studio.\nIf you prefer using SSH, you can connect in the following way:\n\n$ ssh &lt;VUnetID&gt;@x.compute.vu.nl\n\n# from home or outside campus:\n$ ssh -J &lt;VUnetID&gt;@ssh.data.vu.nl &lt;VUnetID&gt;@x.compute.vu.nl\nReplace x with either 1, 2, or 3, depending on your choice."
  },
  {
    "objectID": "topics/compute-hub.html#contact",
    "href": "topics/compute-hub.html#contact",
    "title": "VU Compute Hub",
    "section": "Contact",
    "text": "Contact\nWondering if the VU Compute Hub fits your research needs? Please contact IT for Research.\nIf you run into any issues while using the Compute Servers please send a mail to the IT Service Desk mentioning “JupyterHub”."
  },
  {
    "objectID": "topics/scicloud.html",
    "href": "topics/scicloud.html",
    "title": "SciCloud",
    "section": "",
    "text": "IT for Research (ITvO) offers SciCloud, a service where server capacity can be purchased to support research applications. SciCloud virtual servers are easy to implement, easy to scale up and down and have competitive pricing based on agreed purchase. The virtual server can be placed in an external network, so services running on it can be made internet accessible. It can also run on an internal network for extra security and access to some VU services.\nSciCloud is based on the open source middleware OpenNebula (ONE) and offers a service that allows users to quickly start with a virtual server based on available templates, or to upload one of their own virtual images. This concept is known as Infrastructure as a Service (IaaS)."
  },
  {
    "objectID": "topics/scicloud.html#what-is-it",
    "href": "topics/scicloud.html#what-is-it",
    "title": "SciCloud",
    "section": "",
    "text": "IT for Research (ITvO) offers SciCloud, a service where server capacity can be purchased to support research applications. SciCloud virtual servers are easy to implement, easy to scale up and down and have competitive pricing based on agreed purchase. The virtual server can be placed in an external network, so services running on it can be made internet accessible. It can also run on an internal network for extra security and access to some VU services.\nSciCloud is based on the open source middleware OpenNebula (ONE) and offers a service that allows users to quickly start with a virtual server based on available templates, or to upload one of their own virtual images. This concept is known as Infrastructure as a Service (IaaS)."
  },
  {
    "objectID": "topics/scicloud.html#what-can-it-be-used-for",
    "href": "topics/scicloud.html#what-can-it-be-used-for",
    "title": "SciCloud",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nIn principle you can run any software you want on a SciCloud server. Linux OS is preferred, but a Windows server is also a possibility.\nTypical use cases are:\n\nRunning web applications and services that need to be publicly accessible 24/7, for example a website showcasing your research, a wiki, chatbot, etc.\nHosting a licensed server application for your research group, such as software for analysis, software needed to run lab equipment or elab journal software.\nThe Virtual Server can also be connected to SciStor for environments that need fast access to large amounts of data.\n\nNote that the SciCloud environment has no GPU, so it is not suitable for running graphical environments and machine learning."
  },
  {
    "objectID": "topics/scicloud.html#how-to-request-access",
    "href": "topics/scicloud.html#how-to-request-access",
    "title": "SciCloud",
    "section": "How to request access",
    "text": "How to request access\nVia a form on 🔒ServiceNow, go to: IT &gt; My work field &gt; Research &gt; SciCloud &gt; Order SciCloud capacity\nAfter you have requested a SciCloud virtual server, IT for Research will schedule an interview to discuss your wishes."
  },
  {
    "objectID": "topics/scicloud.html#are-there-costs-involved",
    "href": "topics/scicloud.html#are-there-costs-involved",
    "title": "SciCloud",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nConfigurations of a virtual server are based on standard “Building Blocks”, combinations of the following two options can be purchased:\n• Building Block 1: 1 CPU core with 2 GB RAM\n• Building Block 2: 1 CPU core with 4 GB RAM\nCosts are calculated as: €1 per CPU per month, €1 per GB memory per month, €0.40 per GB storage per year (minimum 20GB)"
  },
  {
    "objectID": "topics/scicloud.html#getting-started",
    "href": "topics/scicloud.html#getting-started",
    "title": "SciCloud",
    "section": "Getting started",
    "text": "Getting started\nThe IT for Research Team will set up the server(s) with the OS of your choice (Windows or Linux) and will set up a root account for you:\n\nFor access to a Linux server you will need to provide a personal SSH key protected with a passphrase. You will be able to access SSH from home.\nFor access to Windows servers use Remote Desktop Protocol (RDP), only via 🔒eduVPN institute access.\n\nRoot access to the server allows you to install all the software you need. Note that IT for Research can help you getting started and will automatically install OS security updates, but you are responsible for installing and maintaining software yourself.\nIt is possible to take snapshots or clones of the virtual server yourself. This allows you to go back to a previously created configuration, if necessary. In addition, ITvO makes daily backups with which a virtual machine can be restored for up to 30 days on request."
  },
  {
    "objectID": "topics/scicloud.html#contact",
    "href": "topics/scicloud.html#contact",
    "title": "SciCloud",
    "section": "Contact",
    "text": "Contact\nWondering if SciCloud fits your research needs? Please contact IT for Research"
  },
  {
    "objectID": "topics/data-publishing.html",
    "href": "topics/data-publishing.html",
    "title": "Data Publishing",
    "section": "",
    "text": "When we mention data publishing at VU Amsterdam, we mean the following:\n\nMaking research data, associated metadata, accompanying documentation, and software code (where relevant) accessible in a repository in such a manner that they can be discovered on the Web and referred to in a unique and persistent way (Inspired by the definition in the CODATA Research Data Management Terminology).\n\nAs stated in the Research Data and Software Management Policy, researchers are responsible for publishing all research data that leads to a published result (either in an article or other narrative form) for scientific reuse, meaning that these materials can be discovered on the Web and referred to in a unique and persistent way. This means that the existence of a dataset is announced and that basic information about this dataset (like title, creator, moment of publication, etc.) can be found online, but it doesn’t necessarily mean that others will be able to access and download the actual data. The level of accessibility to the data must be determined during the publication process. If data or software contain confidential information, information to which intellectual properties apply, and/or personal data, an assessment must take place to determine whether these data can be made available for reuse and if so, under which conditions. A custom licence (‘restricted’ or ‘closed’) will indicate if conditional access can be granted, and if so, what the conditions are."
  },
  {
    "objectID": "topics/data-publishing.html#what-is-data-publishing",
    "href": "topics/data-publishing.html#what-is-data-publishing",
    "title": "Data Publishing",
    "section": "",
    "text": "When we mention data publishing at VU Amsterdam, we mean the following:\n\nMaking research data, associated metadata, accompanying documentation, and software code (where relevant) accessible in a repository in such a manner that they can be discovered on the Web and referred to in a unique and persistent way (Inspired by the definition in the CODATA Research Data Management Terminology).\n\nAs stated in the Research Data and Software Management Policy, researchers are responsible for publishing all research data that leads to a published result (either in an article or other narrative form) for scientific reuse, meaning that these materials can be discovered on the Web and referred to in a unique and persistent way. This means that the existence of a dataset is announced and that basic information about this dataset (like title, creator, moment of publication, etc.) can be found online, but it doesn’t necessarily mean that others will be able to access and download the actual data. The level of accessibility to the data must be determined during the publication process. If data or software contain confidential information, information to which intellectual properties apply, and/or personal data, an assessment must take place to determine whether these data can be made available for reuse and if so, under which conditions. A custom licence (‘restricted’ or ‘closed’) will indicate if conditional access can be granted, and if so, what the conditions are."
  },
  {
    "objectID": "topics/data-publishing.html#purpose",
    "href": "topics/data-publishing.html#purpose",
    "title": "Data Publishing",
    "section": "Purpose",
    "text": "Purpose\nData publishing is crucial for the accessibility of research output. It helps to make VU Amsterdam’s research visible, verifiable and, where possible, reusable. These are important goals for VU Amsterdam, as they contribute to a transparent reseach practice and enable other researchers to build on work that has been done by VU researchers. Publishing data means that researchers make their datasets known to the world, even if they cannot be accessed by others directly, but only after granting conditional access. This enables other researchers reusing these data, leading to more impact of research that is carried out at VU Amsterdam. It may also result in new collaborations. Another advantage is that it makes the work of a researcher more visible, going beyond the visibility of a publication alone."
  },
  {
    "objectID": "topics/data-publishing.html#requirements",
    "href": "topics/data-publishing.html#requirements",
    "title": "Data Publishing",
    "section": "Requirements",
    "text": "Requirements\nAt VU Amsterdam, we strive to make our research data FAIR. Publishing data is a crucial step in making data findable. As explained in the definition above, publishing means that you make data discoverable on the internet. As a result, other researchers can find out about the existence of your dataset and consider whether it may be useful for them in their own research.\nA persistent identifier helps in making data findable, because it ensures that the persistent identifier always resolves to the correct digital object. Rich metadata also contribute to the findability of a dataset. The more information you provide, the more likely it is that others will be able to find your dataset. It is beneficial to use terminology that is common in your discipline when filling out the metadata fields in a repository. Rich information about your dataset will also help other researchers determine whether your dataset is potentially relevant for them.\nRepositories provided by VU Amsterdam (Yoda and DataverseNL) will generate a Persistent Identifier for your dataset and they will ask you to fill out metadata fields. In this way, they contribute to making your data findable. This will also be the case for external trusted repositories.\nWhen you publish your data, it is important to apply a licence to it. If you don’t do that, others will not be allowed to reuse your data. A licence is a legal instrument that tells others what they can and cannot do with your data and is therefore an important aspect of making data reusable."
  },
  {
    "objectID": "topics/data-publishing.html#how-does-data-publishing-work-in-practice",
    "href": "topics/data-publishing.html#how-does-data-publishing-work-in-practice",
    "title": "Data Publishing",
    "section": "How does data publishing work in practice?",
    "text": "How does data publishing work in practice?\nAs mentioned above, data publishing must happen through a repository. Detailed workflows addressing publishing data can be found in the guides about making your data FAIR and archiving and publishing data."
  },
  {
    "objectID": "topics/researchdrive.html",
    "href": "topics/researchdrive.html",
    "title": "Research Drive",
    "section": "",
    "text": "SURF Research Drive is an online storage and collaboration platform for research data. With Research Drive you can easily store and share files with other researchers, inside and outside VU Amsterdam. You can access your data via a web interface or tools, from anywhere in the world.\nResearch Drive is based on the Open Source ownCloud software and is hosted by SURF in their Amsterdam datacentre."
  },
  {
    "objectID": "topics/researchdrive.html#what-is-it",
    "href": "topics/researchdrive.html#what-is-it",
    "title": "Research Drive",
    "section": "",
    "text": "SURF Research Drive is an online storage and collaboration platform for research data. With Research Drive you can easily store and share files with other researchers, inside and outside VU Amsterdam. You can access your data via a web interface or tools, from anywhere in the world.\nResearch Drive is based on the Open Source ownCloud software and is hosted by SURF in their Amsterdam datacentre."
  },
  {
    "objectID": "topics/researchdrive.html#what-can-it-be-used-for",
    "href": "topics/researchdrive.html#what-can-it-be-used-for",
    "title": "Research Drive",
    "section": "What can it be used for?",
    "text": "What can it be used for?\n\nData storage\nResearch Drive is a Cloud storage solution that can be used for small (a few GBs) to larger (a few TBs) datasets. Because it is a cloud storage platform you will need to download data to your laptop to work with it. Research Drive makes this easy by using the ownCloud client, which allows you to automatically sync the folders you want to work with. Data is backed up daily.\n\n\nData sharing\nAs project owner you can invite internal and external collaborators yourself, or you can delegate this task to others.\nYou can set access rights to folders and subfolders yourself, making Research Drive ideal for use in collaborations with many institutions.\n\n\nSensitive data\nHosting at SURF and the use of Multi Factor Authentication (MFA), among other measures, makes Research Drive suitable for storing data that score Medium on confidentiality (see the Policy Classification of Research Data and the Research Data Classification Tool). Data that score High on confidentiality can be stored in Research Drive with additional security measures. Please make sure to contact the RDM Support Desk to check if further measures are needed.\n\n\nData life cycle\nResearch Drive is meant for data you are actively working with. We recommend archiving datasets that are no longer actively used, but can’t be deleted, in Yoda. This ensures Research Drive is used optimally and costs are kept down for your research group and VU Amsterdam.\n\n\nCollaborative tools\nWithin Research Drive, various apps and integrations are available to simplify the use and handling of research data, such as a tool to edit documents directly in the web interface. You can find a current list of app integrations on the SURF User Knowledge Base.\n\n\nSURFdrive replacement\nSince both are based on ownCloud, Research Drive is very similar to SURFdrive, the main difference is that SURFdrive is personal storage while Research Drive is group based.\nResearchers looking for a new home for research data currently on SURFdrive are encouraged to migrate to Research Drive. Manuals for migrating data to Research Drive are available in English and Dutch. Please contact the Research Support Desk if you have any questions about migrating to Research Drive."
  },
  {
    "objectID": "topics/researchdrive.html#how-to-request-access",
    "href": "topics/researchdrive.html#how-to-request-access",
    "title": "Research Drive",
    "section": "How to request access",
    "text": "How to request access\nA new Research Drive projectfolder can be requested via the form on 🔒 ServiceNow, go to: Research Data Support &gt; Research Data Support &gt; Request Research Drive.\nOnce the projectfolder is created you can invite internal and external collaborators yourself."
  },
  {
    "objectID": "topics/researchdrive.html#are-there-costs-involved",
    "href": "topics/researchdrive.html#are-there-costs-involved",
    "title": "Research Drive",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThe costs of storing data in Research Drive are detailed on the 🔒 VU website."
  },
  {
    "objectID": "topics/researchdrive.html#getting-started",
    "href": "topics/researchdrive.html#getting-started",
    "title": "Research Drive",
    "section": "Getting started",
    "text": "Getting started\n\nLog in to the Research Drive web application at vu.data.surfsara.nl. You are only able to log in after you have been invited to one or more project folders. The login process requires a Multi-Factor Authentication (MFA) account, which students do not have by default. If you do not yet have an MFA account, you can, as a VU student, researcher or employee, request an account at the IT Servicedesk in the main building with a legitimate ID.\nInstall the ownCloud Client software, you can find installation instructions on the SURF User Knowledge Base. The Server Address is https://vu.data.surfsara.nl.\n\nThe SURF User Knowledge Base contains a number of Tutorials on working with Research Drive."
  },
  {
    "objectID": "topics/researchdrive.html#contact",
    "href": "topics/researchdrive.html#contact",
    "title": "Research Drive",
    "section": "Contact",
    "text": "Contact\nWondering if Research Drive fits your research needs? Please contact the Research Support Desk."
  },
  {
    "objectID": "topics/data-management-section.html",
    "href": "topics/data-management-section.html",
    "title": "Data Management Section",
    "section": "",
    "text": "Many funders require researchers to include a section in their project proposal about Research Data Management, in which they explain whether existing data will be reused, whether new data will be collected or generated during the project, and how they plan to structure, archive and share their data. Depending on requirements of the funder, the paragraph can be short or more extensive.\nFunders may have different requirements for the data management section in the project proposal. Always check what your funder asks for. Below is a list of information on data management sections from main Dutch funding bodies.\n\nNWO\nZonMw\n\nWe recommend you to ask advice from the RDM Support Desk when writing your data management section."
  },
  {
    "objectID": "topics/safe-data-transfer.html",
    "href": "topics/safe-data-transfer.html",
    "title": "Safe Data Transportation and Transfer",
    "section": "",
    "text": "It is important to protect your data during the entire data life cycle. To find out whether your data are secure during all stages of your research, think about your data flow: where do your data originate and where do they go to? If data need to be transported from one physical place to the other, or need to be transferred from one device to another, these actions should happen in a secure way.\n\nTransferring digital data\n\nOnline connection on campus\nIf data collection takes place through a certain measurement device (e.g. MRI scanner, EEG scanner, eye tracker), the data need to be transferred from the measurement device to the storage location that you will use during your research project. Make sure that this transfer takes place in a secure way and also make a plan for the data on the measurement device; find out whether they need to be destroyed or can remain there.\n\n\nOnline connection outside campus (with and without VUnetID)\nIf you are doing fieldwork outside the campus and you have reliable and secure internet access, it is a good idea to upload the data to a storage location that is regularly backed up and secure, in order to prevent data loss. If you have a VUnetID, you can for example use:\n\nResearch Drive to securely and easily store and share research data.\nSURFfilesender to send you data to a colleague or consortium partner, who can store your data in an appropriate place\n\nYou can find more information about each of these storage options in the Data Storage topic.\nIf you need to receive data from colleagues in your project who don’t have access to these tools (e.g. because they are students, don’t work for a Dutch educational institution, or have no VUnetID), Research Drive, Yoda, SURFfilesender and secure emailing with Zivver can also be used:\n\nResearch Drive: This cloud storage service provided by SURF enables researchers from VU and external researchers to manage files and folders in a shared storage location.\nSURFfilesender: as a SURFfilesender user, you can send a voucher to someone who doesn’t have access to this tool. This person can use this voucher to send documents to you. These files can be encrypted.\nYoda: This cloud storage service provided by SURF enables researchers from VU and external researchers to manage files and folders in a shared storage location.\n🔒 Zivver is an email plugin with which you can encrypt emails and attachments.\n\n\n\nOffline data outside campus\nIf you are doing fieldwork in an area with limited internet access, you might use a portable device to initially store your data during the phase of data collection, such as a USB drive or an external hard drive. These data can be transferred to a storage location that is connected to the internet (e.g. Research Drive, Yoda) later. Please make sure that the data on such portable devices are secured, by using encryption (and by transporting them safely by using a lockable briefcase or backpack).\n\n\n\nTransporting physical data\nIf physical objects need to be transported, you should check with the data manager at your department (if available) what options are available. Special briefcases that can be locked or secure backpacks may need to be used to keep informed consent forms or other sensitive data objects (USB drives etc.) secure during transport. A checklist may help to ensure all objects will be taken along.\n\n\nData transportation and transfer across borders\nSome countries have rules to control the movement of encryption technology that enter or exit their borders. If you need to travel with an encrypted laptop to secure your data, for example during fieldwork abroad, please keep this in mind. If you need to transfer data in and out of such countries, please get advice on encryption and secure transportation at the IT Service Desk.\n\n\nSupport\nIf you have general questions about how to protect your data when transporting or transferring them, you can contact the IT Service Desk. In case of complex situations for which you need tailored support, you can consult the IT Relationship Manager representing the research domain, who can request capacity at IT for setting up an information security plan. Such a plan is usually based on documents which need to be completed beforehand, like a Data Protection Impact Assessment and a Data Classification."
  },
  {
    "objectID": "topics/gdpr.html",
    "href": "topics/gdpr.html",
    "title": "General Data Protection Regulation",
    "section": "",
    "text": "The General Data Protection Regulation (GDPR) is a European legislation that lays down rules relating to the protection of natural persons with regard to the processing of personal data. The Dutch Implementation Act for the GDPR (UAVG) describes the implementation of the GDPR for the Netherlands."
  },
  {
    "objectID": "topics/gdpr.html#introduction",
    "href": "topics/gdpr.html#introduction",
    "title": "General Data Protection Regulation",
    "section": "",
    "text": "The General Data Protection Regulation (GDPR) is a European legislation that lays down rules relating to the protection of natural persons with regard to the processing of personal data. The Dutch Implementation Act for the GDPR (UAVG) describes the implementation of the GDPR for the Netherlands."
  },
  {
    "objectID": "topics/gdpr.html#definitions",
    "href": "topics/gdpr.html#definitions",
    "title": "General Data Protection Regulation",
    "section": "Definitions",
    "text": "Definitions\n\nPersonal data refers to any information relating to an identified or identifiable natural person (‘data subject’). See also the definition of ’personal data’ according to the official text of the GDPR.\nData processing refers to any action performed on data, such as collecting, storing, modifying, distributing, deleting data. See also the definition of ‘processing’ according the official text of the GDPR.\nDirect and indirect identification: Some identifiers enable you to single out an indiviual directly, such as name, address, IP-address etc. Individuals can also be identifed indirectly through:\n\na combination of information that uniquely singles out an individual (e.g. a male with breast cancer in a breast cancer registry, a pregnant individual over 50 etc.), this includes information in one record and information across different data files or datasets\nunique information or patterns that are specific to an individual (e.g. genomic data, a very specific occupation, such as the president of a large company, repeated physical measurements or movement patterns that create a unique profile of an individual or measurements that are extreme and could be linked to subjects such as high-level athletes)\ndata that are linked to directly identifying information through a random identification code or number\n\nPseudonymous data: Data that are indirectly identifiable are generally considered to be pseudonymous; this means that they are NOT anonymous and still qualify as personal data. Therefore privacy laws, such as the GDPR, do in fact apply to these data. This is for example the case when direct identifiers are removed from the research data and put into a key file (or what is usually called a subject identification log in medical research) with which the direct identifiers can be mapped to the research data through unique codes, so that reidentification is possible. These data are therefore pseudonymous, and not anonymous. The LCRDM has made a reference card that illustrates the difference between pseudonymous and anonymous data."
  },
  {
    "objectID": "topics/gdpr.html#background-information",
    "href": "topics/gdpr.html#background-information",
    "title": "General Data Protection Regulation",
    "section": "Background information",
    "text": "Background information\n\nPrivacy in research - Privacy five-step plan\nWhere research requires the collection of personal data, the researcher has to follow the Privacy five-step plan to make sure to carry out the research in line with the GDPR.\n\n\nVSNU Code of Conduct for using personal data in research\nThe VSNU’s Code of Conduct for Research Integrity (Dutch, English, 2018) includes a reference to the GDPR and its Dutch implementation law UAVG. An updated Code of Conduct for Using Personal Data in Research which complies with GDPR is still work in progress."
  },
  {
    "objectID": "topics/gdpr.html#support-in-your-faculty-privacy-champions",
    "href": "topics/gdpr.html#support-in-your-faculty-privacy-champions",
    "title": "General Data Protection Regulation",
    "section": "Support in your faculty: Privacy Champions",
    "text": "Support in your faculty: Privacy Champions\nEach faculty has one or more Privacy Champions, who are the first point of contact for questions relating to privacy and the GDPR. The Privacy Champions can help you with completing a Data Protection Impact Assessment, registering your research in the record of processing activities, designing informed consent forms and other questions relating to the GDPR. The 🔒 list of Privacy Champions can be found on the VU website."
  },
  {
    "objectID": "topics/gdpr.html#more-information",
    "href": "topics/gdpr.html#more-information",
    "title": "General Data Protection Regulation",
    "section": "More information",
    "text": "More information\nOn the VU page Working with personal data, you can find more information about how VU Amsterdam protects personal data."
  },
  {
    "objectID": "topics/ethical-review.html",
    "href": "topics/ethical-review.html",
    "title": "Ethical Review",
    "section": "",
    "text": "In cases where research involves human or animal participants, a research proposal may need to be reviewed by an ethics committee. VU Amsterdam and Amsterdam UMC (location VUmc), have several ethics committees, which are listed below. Please note that researchers at VU Amsterdam also have to go to the METc at VUmc if their research is subject to the WMO, which is not restricted to research at VUmc."
  },
  {
    "objectID": "topics/ethical-review.html#ethics-committees",
    "href": "topics/ethical-review.html#ethics-committees",
    "title": "Ethical Review",
    "section": "Ethics committees",
    "text": "Ethics committees\n\nACTA: ACTA Ethics Review Board (ETC)\nBeta: Research ethics review committee Faculty of Science (BETHCIE)\nFGB: 🔒 Scientific and Ethical Review Board (VCWE)\nFGW: Ethische Toetsingscommissie Onderzoek (EtCO)\nFSW: 🔒 Research Ethics Review Committee (RERC)\nRCH (Faculty of Law): Ethics Committee\nSBE: Ethical Review Board (ERB)\nVUmc (Amsterdam UMC): Medical Ethical Review Committee (METc)"
  },
  {
    "objectID": "topics/data-documentation.html",
    "href": "topics/data-documentation.html",
    "title": "Data Documentation",
    "section": "",
    "text": "By creating documentation about your research data you can make it easier for yourself or for others to manage, find, assess and use your data. The process of documenting means to describe your data and the methods by which they were collected, processed and analysed. The documentation or descriptions are also referred to as metadata, i.e. data about data. These metadata can take various forms and can describe data on different levels.\nAn example that is frequently used to illustrate the importance of metadata is the use of the label on a can of soup. The label tells you what kind of soup the can contains, what ingredients are used, who made it, when it expires and how you should prepare the soup for consumption.\nWhen you are documenting data, you should take into account that there are different kinds of metadata and that these metadata are governed by various standards. These include, but are not limited to:\nThe CESSDA has made very detailed guidance available for creating documentation and metadata for your data."
  },
  {
    "objectID": "topics/data-documentation.html#fair-data-principles",
    "href": "topics/data-documentation.html#fair-data-principles",
    "title": "Data Documentation",
    "section": "FAIR data principles",
    "text": "FAIR data principles\nThe FAIR data principles provide guidelines to improve the Findability, Accessibility, Interoperability, and Reuse of digital assets. The principles emphasise machine-actionability, i.e., the capacity of computational systems to find, access, interoperate, and reuse data with none or minimal human intervention.\nMore information can be found in the section about the FAIR data principles."
  },
  {
    "objectID": "topics/data-documentation.html#unstructured-metadata",
    "href": "topics/data-documentation.html#unstructured-metadata",
    "title": "Data Documentation",
    "section": "Unstructured metadata",
    "text": "Unstructured metadata\nMost data documentation is an example of unstructured metadata. Unstructured metadata are mainly intended to provide more detailed information about the data and is primarily readable for humans. The type of research and the nature of the data influence what kind of unstructured metadata is necessary. Unstructured metadata are attached to the data in a file. The format of the file is chosen by the researcher. More explanation about structured metadata can be found on the metadata page.\n\nREADME\nA README file provides information about data and is intended to ensure that data can be correctly interpreted, by yourself or by others. A README file is required whenever you are archiving or publishing data.\nExample of READMEs\n\nGuidelines for creating a README file – 4TU.ResearchData\nGuide to writing “readme”-style metatada - Cornell Data Services\nGuidelines for researchers of VU Amsterdam Faculty of Behavioural and Movement Sciences on what a README file should contain\n\n\n\nCodebook\nA Codebook is another way to describe the contents, structure and layout of the data. A well documented codebook is intended to be complete and self-explanatory and contains information about each variable in a data file. A codebook must be submitted along with the data.\nThere are several guides for creating a codebook available:\n\nCreating a codebook - Kent State University\nCreating a codebook - for researchers at VU Amsterdam Faculty for Behavioural and Movement Sciences\nCodebook - Amsterdam Public Health\nDDI-Codebook - Data Documentation Initiative Alliance"
  },
  {
    "objectID": "topics/data-citation.html",
    "href": "topics/data-citation.html",
    "title": "Data Citation",
    "section": "",
    "text": "Citing data is not different from citing a journal publication. Similar to citing a journal publication, it helps to give and receive credit, and show the impact of the original source.\nMake sure to check the rules of the journal to know how you should cite when writing an article for a specific academic journal. For all of the journals, however, the minimum compulsory elements in a data citation include:\n\nAuthor(s): Name of the author (creator) of the dataset\nTitle: Name of the dataset\nDate of publication\nPublisher: Archive where dataset is stored\nPersistent Identifier: Unique identifier, most common is the DOI (see section Persistent Identifier).\n\nOptional elements that may be included in the reference are:\n\nFile Type: Codebook, movie, software\nVersion: Version number of the edition\nCreation Date\nDate of Consultation (last)\n\n\n\nStephens, William, 2020, “Resiliences to Radicalisation - QSort Data”, https://doi.org/10.34894/35MTMN, DataverseNL, V1.\n\nFor more information, see the following guidelines:\n\nDataverse\nDataCite\nDCC UK\nData Citation Synthesis Group (2014). Joint Declaration of Data Citation Principles. Martone M. (ed.) San Diego CA: FORCE11\n\nRelevant is also the Citation File Format (CFF)."
  },
  {
    "objectID": "topics/data-citation.html#citation-elements",
    "href": "topics/data-citation.html#citation-elements",
    "title": "Data Citation",
    "section": "",
    "text": "Citing data is not different from citing a journal publication. Similar to citing a journal publication, it helps to give and receive credit, and show the impact of the original source.\nMake sure to check the rules of the journal to know how you should cite when writing an article for a specific academic journal. For all of the journals, however, the minimum compulsory elements in a data citation include:\n\nAuthor(s): Name of the author (creator) of the dataset\nTitle: Name of the dataset\nDate of publication\nPublisher: Archive where dataset is stored\nPersistent Identifier: Unique identifier, most common is the DOI (see section Persistent Identifier).\n\nOptional elements that may be included in the reference are:\n\nFile Type: Codebook, movie, software\nVersion: Version number of the edition\nCreation Date\nDate of Consultation (last)\n\n\n\nStephens, William, 2020, “Resiliences to Radicalisation - QSort Data”, https://doi.org/10.34894/35MTMN, DataverseNL, V1.\n\nFor more information, see the following guidelines:\n\nDataverse\nDataCite\nDCC UK\nData Citation Synthesis Group (2014). Joint Declaration of Data Citation Principles. Martone M. (ed.) San Diego CA: FORCE11\n\nRelevant is also the Citation File Format (CFF)."
  },
  {
    "objectID": "topics/software-licensing.html",
    "href": "topics/software-licensing.html",
    "title": "Software Licensing",
    "section": "",
    "text": "Publishing research software under an appropriate licence is crucial for its accessibility, usability, and further integration into research. Choosing a licence usually happens right when you start developing the software or when you put it in a public repository, rather than when the software is finished and fully baked.\nA software licence states how other people may re-use your code and under which circumstances. For research software, it is recommended (and often required by funders) that licences are as permissible as possible.\nThere are many licences out there; below we list some very frequently used licences in research software. However, if none of these licences fit your case, there are several tools that can help you to choose a suitable software licence. If you need guidance in choosing a licence for your software, get in touch with the RDM Support Desk."
  },
  {
    "objectID": "topics/software-licensing.html#licensing-software",
    "href": "topics/software-licensing.html#licensing-software",
    "title": "Software Licensing",
    "section": "",
    "text": "Publishing research software under an appropriate licence is crucial for its accessibility, usability, and further integration into research. Choosing a licence usually happens right when you start developing the software or when you put it in a public repository, rather than when the software is finished and fully baked.\nA software licence states how other people may re-use your code and under which circumstances. For research software, it is recommended (and often required by funders) that licences are as permissible as possible.\nThere are many licences out there; below we list some very frequently used licences in research software. However, if none of these licences fit your case, there are several tools that can help you to choose a suitable software licence. If you need guidance in choosing a licence for your software, get in touch with the RDM Support Desk."
  },
  {
    "objectID": "topics/software-licensing.html#mit-license",
    "href": "topics/software-licensing.html#mit-license",
    "title": "Software Licensing",
    "section": "MIT License",
    "text": "MIT License\nThe MIT License is a popular choice, due to its readability and permissiveness. It allows users to reuse the software for any purpose, including using, copying, modifying, and distributing it, provided they include the original copyright notice and licence text.\nHowever, its permissiveness means that derivative works can be closed-source and do not need to mention that they use your code, which might not align with all scientific openness goals or general."
  },
  {
    "objectID": "topics/software-licensing.html#gnu-gplv3",
    "href": "topics/software-licensing.html#gnu-gplv3",
    "title": "Software Licensing",
    "section": "GNU GPLv3",
    "text": "GNU GPLv3\nThe GNU General Public License (GPLv3) is another option, designed to ensure that the software and any derivatives remain open-source.\nThis encourages collaborative improvement of software. Any software that includes GPL-licensed code must also be open-source under the GPLpotentially deterring commercial use or integration with proprietary software. In conclusion, when you want your code to be used by others, but only the code that uses your code is also open source, this is the way to go."
  },
  {
    "objectID": "topics/software-licensing.html#apache-license-2.0",
    "href": "topics/software-licensing.html#apache-license-2.0",
    "title": "Software Licensing",
    "section": "Apache License 2.0",
    "text": "Apache License 2.0\nThe Apache License 2.0 allows for modification and distribution of the software and its derivative works, with the requirement that changes to the original code are documented.\nIt is a more complex licence than the MIT License and can be incompatible with GPL-licensed software. The specifics of this go beyond the scope of the handbook."
  },
  {
    "objectID": "topics/software-licensing.html#adding-a-licence-to-github",
    "href": "topics/software-licensing.html#adding-a-licence-to-github",
    "title": "Software Licensing",
    "section": "Adding a licence to GitHub",
    "text": "Adding a licence to GitHub\nOn GitHub you add a licence on creating a new repository, by selecting the licence from the drop-down menu. If your repository already exists, add a new file called “LICENSE” using the “+”-button on top of the repository (see below).\n\n\n\nLocation of file creation button\n\n\nOne the next page, start to type LICENSE as the file name, and a button to “Choose a license template” should automatically pop up. Follow the steps provided by GitHub to finish adding the licence to the repository.\nYou should now see your licence shown on the main page of your repository."
  },
  {
    "objectID": "topics/software-licensing.html#further-considerations",
    "href": "topics/software-licensing.html#further-considerations",
    "title": "Software Licensing",
    "section": "Further considerations",
    "text": "Further considerations\n\nIf you are reusing software or libraries written by someone else, you must stick to the clauses of the licence given to the original software/library;\nWhen choosing a licence, do not just think about what others may do with the software, but also what you might want to do with the software in the future."
  },
  {
    "objectID": "topics/research-data-and-software-management-policy.html",
    "href": "topics/research-data-and-software-management-policy.html",
    "title": "Research Data and Software Management Policy",
    "section": "",
    "text": "VU Amsterdam considers the careful handling of research data and software to be very important. The university has therefore formulated a Research Data and Software Management Policy which articulates how to handle research data and software. The policy lists the responsibilities regarding research data and software management for researchers, department heads, faculty boards and the university as a whole.\n\nVU Research Data and Software Management Policy (2024) in English and in Dutch\n\nSince the VU Amsterdam policy for Research Data and Software Management is formulated in general terms, faculties have worked out more detailed policies and guidelines for their own faculty. These faculty-specific guidelines can be found below.\n\nACTA RDM policy, Academisch Centrum Tandheelkunde Amsterdam (2020, in Dutch)\nBeta RDM policy, Faculty of Science (2022)\nFGB RDM policy, Faculty of Behavioural and Movement Sciences (2023)\nFGW RDM policy , Faculty of Humanities (2023)\nFRT RDM policy, Faculty of Religion and Theology (2024)\n🔒 FSW RDM policy, Faculty of Social Sciences (2023)\nRCH RDM policy, Faculty of Law (2021)\nSBE RDM policy, School of Business and Economics (2023)\n\nFor RDM policies and guidelines at Amsterdam UMC, location VUmc, please get in touch with Research Data Management Support at Amsterdam UMC.\nIf you have questions about the VU-central Research Data and Software Management Policy, please contact the RDM Support Desk."
  },
  {
    "objectID": "RDM-guidelines.html",
    "href": "RDM-guidelines.html",
    "title": "RDM Guidelines",
    "section": "",
    "text": "What is a guide?\n\n\n\nThese guides help you find answers to questions that come up while doing research. They help guide you through various topics at once.\nMissing a guide? You can submit questions you are dealing with using the Contribution portal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVU Computer Science Data Storage Platforms\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat research resources are available for VU researchers related to research data management?\n\n\nA page that summarized all the links.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Contributing",
    "section": "",
    "text": "You can contribute to the VU CS Department RDM and Open Science Handbook by making small edits, writing entirely new topics, or writing guides. All contributions are welcome and appreciated, small and large. If you are in need of specific information, you can skip ahead using the table of contents."
  },
  {
    "objectID": "contributing.html#contributing-portal",
    "href": "contributing.html#contributing-portal",
    "title": "Contributing",
    "section": "Contributing portal",
    "text": "Contributing portal\nWe offer a portal to reduce the barriers to contribute to the VU CS Department RDM and Open Science Handbook. You only need an internet connection and articulate what you want us to include. No accounts necessary 😊\n\n\n\n\n\n\nNote\n\n\n\nOpen the contribution portal by clicking here or copy-pasting: https://ez-github-contributor.netlify.app/\n\n\nYou can report issues you find with the VU CS Department RDM and Open Science Handbook using the “Report a problem” tab. This is a way for you to share your feedback with us.\nYou can propose new topics or guides to the VU CS Department RDM and Open Science Handbook using the “Propose new page” tab. This will be considered for inclusion. Please mention whether it should be a topic or a guide. The text editor allows you to use rich text formatting.\n\n\n\n\n\n\nWarning\n\n\n\nThe portal does not save your work. Use the portal when you are ready to submit your work, but do not use it to manage your submissions.\n\n\n\n\n\nScreenshot of the contributor portal\n\n\nIf you want to be credited with contributing, please share your name. If you’d like to hear back about what was done with your feedback or proposal, please also provide a direct way to contact you."
  },
  {
    "objectID": "contributing.html#contributing-via-github",
    "href": "contributing.html#contributing-via-github",
    "title": "Contributing",
    "section": "Contributing via GitHub",
    "text": "Contributing via GitHub\n\n\n\n\n\n\nNote\n\n\n\nFor the next steps you need a GitHub account to contribute. You can create one directly on GitHub.\n\n\n\nSuggesting edits\nThe easiest and quickest way to contribute to the book is make suggested edits. On each page you will find a button reading “Edit this page” (usually on the right).\n\n\n\nScreenshot of a handbook topic, with a red box on the right hand side of the page indicating where to find the “Edit this page” button\n\n\nWhen you click that, you will immediately be taken to GitHub to edit the text of that specific page. You may be prompted to create a fork (forking) in case these are your first edits.\n\n\n\nScreenshot of the GitHub file editor, with some changes made and the “Commit changes” button active\n\n\nOnce you made your edits, you are ready to commit (save) your changes and submit your pull request, requesting those changes to be included in the handbook.\n\n\nAdding a topic\nTo add a new topic, you need to create a new file ending in .qmd in the topics folder (e.g., topics/example.qmd). You can do this by visiting the handbook page on GitHub and clicking Add file -&gt; New file.\n\n\n\nScreenshot of GitHub highlighting where to find the “New file” button\n\n\nWhen you click this button you may be asked to fork the repository. This is not a problem so go ahead!\nThe topic itself needs to be written in Markdown. Every topic must be a noun/noun phrase and contain the title as such:\n---\ntitle: Example topic\n---\nSection headings are second level headings (e.g., ## Section). You can add all needed information as you want, but please mind that topics are supposed to short and self-contained for readers of the VU CS Department RDM and Open Science Handbook.\nAfter that, you are ready to submit your pull request! The reviewers will help you place the topic in the right place of the book.\n\n\nAdding a guide\nTo add a new guide, you need to create a new file ending in .qmd in the guides folder (e.g., guides/example.qmd). You can do this by visiting the handbook page on GitHub and clicking Add file -&gt; New file.\n\n\n\nScreenshot of GitHub highlighting where to find the “New file” button\n\n\nWhen you click this button you may be asked to fork the repository. This is not a problem so go ahead!\nEvery guide title must reflect the question the guide answers. Add the title by adding the following information at the top of your document:\n---\ntitle: How do I create a guide?\n---\nSection headings are second level headings (e.g., ## Section). The guide itself needs to be written in Markdown.\nYou can re-use topics literally in your guides. For each topic you want to include, you can either mention so on a line surrounded by whitespaces:\nINSERT TOPIC: DATA MANAGEMENT PLAN\nThis will tell the editorial team to include that topic there. Please be specific in naming the topic. You can also directly include the topic yourself directly using the following code:\n\n## Topic name\n\n    ```{.include shift-heading-level-by=2}\n    ../topics/replace-with-filename.qmd\n    ```\nYou need to count the heading level in your guide to identify your shift number. In this case, there are two ## so we shift by two. You can verify the filename directly, but it should correspond to each word separated by a minus sign (for example, data-management-plan.qmd).\nAfter that, you are ready to submit your pull request!\n\n\nSubmit a pull request\nOnce you have made suggested changes, a pull request is the way for you to ask for your changes to be incorporated into the VU CS Department RDM and Open Science Handbook. The handbook editors will review what you wrote, ask some questions, and accept or decline your contributions.\nWe recommend keeping your suggested changes small or limited in scope, and explaining why you are suggesting these changes. It is more likely your changes are included when you are fixing a typo or adding a paragraph, and less likely if you are revising the entire handbook. It is also more likely they are included if you explain why you are suggesting the changes, rather than dropping by and making edits without any context.\nIf you are adding a new topic or guide, it is definitely recommended to open an issue first to see whether there is a need for it (and maybe you’ll find collaborators!).\nDuring the review process you may be asked to update your changes, or revisions may be added by the people maintaining the handbook. It is helpful if you keep an eye on your GitHub account to ensure timely responses to help the process along. By contributing, you become part of the process :blush:\n\n\nWriting text\nThe book is created using Markdown - you can get familiarized with the basic syntax on the Markdown website. The getting started quick items are:\n# Heading level 1\n## Heading level 2\n### Heading level 3\n\nYou simply write text as you are used to. To make something *italic*, **bold**, or ***bold and italic***.\n\n&gt; this is how you add quotes\n\n- or lists\n- that can go on \n- and on\nIf you want to add code, use references, create links, or footnotes - it is all possible. We will expand examples here based on your needs, so if you need help, let us know by reporting an issue!\n\nAdding relative links\nOften, you will want to link to other pages or sections in the VU CS Department RDM and Open Science Handbook. Instead of going to the website, and pasting the link from there (for example, https://ubvu.github.io/open-handbook/contributing.html), you can add what is called “relative links.”\nRelative links require three concepts:\n\nWorking directory: The folder in which the file you are editing is located\n./ = indicates the current folder\n../ = indicates the folder one level up\n\nThis Contributing guide is located in the “root” directory, and there is no upper folder. If we wanted to link to a topic, we would use ../topics/example-topic.qmd. This would create a relative link to the example file.\n\n\n\n\n\n\nNote\n\n\n\nRelative links link to the .qmd files, never to the .html pages. These only exist when the pages are rendered!\n\n\nIf we were editing a topic, and we wanted to link out to a guide, we would need to use ../guides/example-guide.qmd. This because we would be in the topic folder for that file, and need to navigate one level up (../) and then down into the guides folder.\n\nSection links\nWhenever we link to a specific guide or topic, you can also link to a specific section. This helps you point readers to what you want them to read, and helps them find the information they need.\nThe easiest way to find these section links is to navigate to the relevant page, and click on the link icon next to the heading. This will cause your URL to change.\n\n\n\nScreenshot indicating the link icon next to a heading, and the updated URL as a result\n\n\nYou add the #adding-a-guide (as applicable in your case) to the end of your relative link, and you will have created a relative section link! :blush:\nIf the section is on the same, you can drop the relative link altogether and keep only the part after the # (for example, #adding-a-guide).\n\n\n\n\nAdding images\nIn markdown, you can easily add images and alt text at the same time. We require alt text on all images, and if you are contributing an image, you can best describe its value in the text.\nYou add images by using:\n![Alt text](URL)\nIf you want the image to be hosted in the Research Support Handbook, use the following steps:\n\nAdd the image you want to the public/ folder\nMark the exact filename\nUse ../public/&lt;filename&gt; as the URL for the image (for example ../public/image.png)\n\n\n\nMore information about GitHub\nWe use GitHub to create this website automatically, and to manage all the incoming updates. You do not need to know how it works entirely, but we want to help you understand some things so you are not confused.\n\nRepository\nA repository on GitHub is like a folder on your computer. This can be many things, depending on what files it contains.\nWhen we mention a repository here, we mean that we want you to look at a specific folder. The repository for this website for example can be found on GitHub directly. You will always be contributing to a repository, in order to contribute to the handbook.\n\n\nForking\nA repository is owned by one or multiple people on GitHub. If you are not one of them, you can create a copy of the repository (folder) to make your edits in. This act of creating a copy is called “forking.”\nWhen you create a copy, you do not have to worry about accidentally removing or destroying the handbook. Your changes are not reflected in the website until you submit a pull request."
  },
  {
    "objectID": "contributing.html#adding-references",
    "href": "contributing.html#adding-references",
    "title": "Contributing",
    "section": "Adding references",
    "text": "Adding references\nIf you want to include references throughout the handbook, we recommend you do so in the following way.\n\nAdd the BibTex\nYou can find the relevant BibTeX information using a tool like the DOI to BibTeX converter. Counterintuitively, it also works on ISBNs for example.\nAfter you found the BibTeX information, you add it to the references.bib file (preferably all the way at the bottom). Example BibTeX information is:\n@ARTICLE{example-code,\n  title     = \"Example Title\",\n  author    = \"Author, Example\"\n  journal   = \"Example Journal\",\n  year      =  2042,\n  copyright = \"https://creativecommons.org/licenses/by/4.0\",\n  language  = \"en\"\n}\n\n\nAdd the citation\nTo add the citation to a page, you use [@example-code] or @example-code.\n@example-code will result in an in-text citation, like “Author (2042).”\n[@example-code] will result in a regular citation such as “(Author, 2042)”.\nFor more details on citations, see also the Quarto help page on citations."
  },
  {
    "objectID": "contributing.html#rendering-handbook-locally",
    "href": "contributing.html#rendering-handbook-locally",
    "title": "Contributing",
    "section": "Rendering handbook locally",
    "text": "Rendering handbook locally\nSometimes you may want to preview the changes you are making to the handbook. That is possible in most cases, but requires you to install some software. You need to install Quarto and assuming a successful installation, you then need to run the following code in your terminal:\n# Clone the git repository\ngit repo clone https://github.com/ubvu/open-handbook\n# Go into the right folder\ncd open-handbook\n# Render the handbook\nquarto render .\nWe do not guarantee this will work immediately, but should cover most instances. If you are looking to contribute and want to render things locally, try this first, and if you run into any issues, let us know in an issue report. We’re happy to try our best if you share your error messages :blush:"
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "",
    "text": "This document is created as a guideline for the selection of storage platform for the research projects in the Computer Science department of the Vrije Universiteit Amsterdam. This guideline makes concrete suggestions for our department based on the 2020 university RDM policy and information provided by the UBVU (University Library) RDM team and VU/IT department. The guideline takes into account the current state of several ongoing and recently completed projects in our department, based on a department-wide survey held in 2023.\nThe document provides an overview of available options for data storage, explains how they are suggested for use in our department, and helps researchers choose the most suitable storage option for projects. While this document covers only data storage, the data stewards are aware that in practice, there could be much more to take into consideration. Feel free to consult the data stewards in specific cases.\nUsing many different storage options can lead to fragmentation and operational overheads when working with multiple data sources. Therefore, in our department we want to limit the commonly used storage options to a preferred shortlist. This document serves as a guideline for this convergence.\nThe online VU tool Data Storage Finder has no less than 10 storage options listed. More detailed information and metrics about these options can be found on the University Library’s Data Storage guide.\nThe data storage options are classified as appropriate or not according to the following criteria:\n\n\n\n\n\n\n\nData classification (sensitivity)\nlow / medium / high / very high\n\n\n\n\n\n\nData sharing\nnot needed / with VU colleagues / with anyone\n\n\n\n\n\n\nData volume\nbelow 500 GB / above 500 GB\n\n\n\n\n\n\nPossible features\n\nBasic storage\nCompute/HPC\nFine-grained access rights\nCollaboration tools\nArchiving/Publishing\n\n\n\n\nNote: these classifications are per “project”. The formal status, scale, type and personal participation of projects can differ significantly:\n\nsome large projects have budgets of their own (with partial external funding);\n\nsmaller projects might be fully supported via the “zero-cost” base resources available per project;\n\nin between are projects that are supported by a contribution from the budget of the PI.\n\nApart from the options mentioned, personal laptops and storage tied to data processing resources like HPC clusters are also important data storage resources for research. However, these should only be used to work on (copies of) the actual datasets that are stored on and shared via the selected primary storage platform.\nVersion management of primary and derived research data is an important topic in itself, which needs to be addressed in a project’s data management plan, and which should be made explicit in operational guidelines which can also include suitable synchronization mechanisms. It is orthogonal to the selection of the storage platform.\nClosely related to data storage is data sharing and data archiving. This will be addressed in future versions of the guidelines.\nAnother important aspect to consider is the backup of the data, to be able to retrieve data that was lost or that was somehow corrupted. A general rule for backup is the 3-2-1 rule and does scale depending on how backups are structured: 3 copies (1 original, two backup), on 2 different types of media, with at least 1 off-site (physically) or in separate, dedicated cloud storage.\nTypically each of the storage platforms discussed below will have some mechanism to restore a previous version of a specific file from backup, but the extent to which this is possible may vary significantly. Being able to retrieve a single file version from a week ago should not be a problem, but for many projects it is necessary to be able to retrieve a consistent snapshot of a large number of files (see the discussion of version management above). Where requirements for retrieval of previous file versions are higher than offered by the storage platform directly, additional versioning functionality will have to be designed and implemented (e.g., daily/weekly consistent snapshots of the project data). This should be made explicit in the project’s data management plan."
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#most-suitable",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#most-suitable",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "3.1 Most suitable",
    "text": "3.1 Most suitable\n\n\n\n\n\n\n\nResearch Drive\n\nSURF supported\nsharing data inside and outside VU\nsuitable for potentially sensitive data\n\n\n\n\n\n\n\nYODA\n\nSURF supported\nsharing data inside and outside VU\nsuitable for potentially sensitive data\n\n\n\n\n\n\n\nSciStor\n\nVU/IT supported\nlow latency high throughput access at VU\ngood for quickly synchronizing many files\nthe department has pre-paid 40 TB SciStor capacity, so many projects can benefit from this without project-specific funding\nBUT: only possible to share data within VU\n\n\n\n\nHere are a few important differences between YODA and Research Drive:\n\nYODA has a basic classification that is higher than Research Drive (Research Drive can hold data with classification High, but needs additional measures);\n\nResearch Drive enables fine-grained access permissions: you can give collaborators access to only one folder and not the entire project (this is not possible with YODA, and quite useful when e.g. working with students or external project partners);\n\nYODA includes a vault for archiving while ResearchDrive does not;\n\nYODA enables adding metadata as you go; Research Drive does not."
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#suitable-only-for-specific-purposes",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#suitable-only-for-specific-purposes",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "3.2 Suitable only for specific purposes",
    "text": "3.2 Suitable only for specific purposes\n\n\n\n\n\n\n\nGoogle Drive VU\n\nuseful for quick ad hoc sharing, including online editing shared contents\ncan store datasets with high data volume (many TB) without privacy concerns, for which no project budget is available\n\n\n\n\n\n\n\nMicrosoft Sharepoint (Teams)\n\nuseful for quick ad hoc sharing, including online editing shared contents\nBUT: Use only if Microsoft-based document sharing is the best match for a small scale project. Sharepoint is a relatively new option supported by VU/IT, but the functionality is quite diverse and partially overlaps with the Google option, just in a Microsoft flavor.\n\n\n\n\n\n\n\nOpen Science Framework\n\nspecifically suitable when collaborating with external partners in Open Science contexts, where widely sharing data, analysis techniques and results are the primary goal.\n\n\n\n\n\n\n\nEncrypted portable storage (SSD)\n\nuseful for regular laptop backups\nBUT: Do not use this to store research datasets, given the risks of losing the only physical copy, and the challenges to share the data\n\n\n\n\n\n\n\nGithub, GitLab, Bitbucket\n\nvery useful for software development and sharing\nmight be used for small scale data sharing, e.g., as part of a publication whose focus is on a developed algorithm or system\nBUT: less suitable for large scale data sharing, given the limits on file size and data volume"
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#typically-less-suitable",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#typically-less-suitable",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "3.3 Typically less suitable",
    "text": "3.3 Typically less suitable\nIf possible, best avoid the next options since they usually have little benefits compared\nto the suitable options above, but do have some downsides, and we would like to avoid\nfragmentation and interoperability problems for projects.\n\n\n\n\n\n\n\nOneDrive\n– Tied to personal VU-relation of owner, so not suitable for long term project storage\n\n\n\n\n\n\nSURFdrive\n– Basically a more limited precursor of ResearchDrive, so for research purposes consider using that instead. - It has been announced to be deprecated and VU/IT will stop the contract July 1, 2025.\n\n\n\n\n\n\nCustom solutions\n– E.g., group/project-specific RAID systems. Typically there are hidden costs maintaining the setup. If there are very specific reasons why none of the standard solutions seem to match, best talk with the RDM advisors before introducing a custom solution."
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#legacy-storage-options",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#legacy-storage-options",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "3.4 Legacy storage options",
    "text": "3.4 Legacy storage options\nIn the past, some more storage options were available. They are not mentioned in the online storage selector, and their use should be limited as much as possible. Preferably they should be phased out, by migrating them to preferable options listed above. New projects should not be started using these “legacy” storage options.\n\n\n\n\n\n\n\nLegacy Home folder, or “H drive”\n\nThe original home folders are phased out and are also no longer available via logging in to the SSH stepstone. In case the user has not migrated the contents in time, they can be retrieved from backup by contacting VU/IT. For our department, SciStor provides a suitable alternative since it preserves almost all the previous functionality.\n\n\n\n\n\n\n\nLegacy Group/Projects folder\n\nThe old group/projects folders are still available via the SSH stepstone, but capacity is limited, and costs per gigabyte are high. This data should also be migrated, and no projects should be added anymore.\n\n\n\n\n\n\n\nDropbox\n\nDropbox has useful syncing options between various devices, and can be used for ad hoc file sharing, but the costs are relatively high. Dropbox is not a VU/IT supported storage platform and it should not be used for research datasets.\n\n\n\n\nMore guidelines on data archiving will be provided in future guidelines."
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#research-drive",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#research-drive",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "4.1 Research Drive",
    "text": "4.1 Research Drive\nResearch Drive enables you to easily store and share files with other users, inside and outside the VU. Please note: storing data with a ‘high’ classification in Research Drive is permissible, but may require taking extra security measures. Please get in touch with the Research Data Management Support Desk via rdm@vu.nl if you want to store high-classification data in Research Drive.\n\n\n\n\n\n\n\nResearch Drive details\n\n\n\n\n\nMax. storage size\nTerabytes of data\n\n\nCosts\n\nbelow 500 GB: free of charge\n500 GB to 2 TB: €200 per year\nabove 2 TB: €200 + €250 for every TB above 2 TB\n\n\n\nSharing and collaboration\nWith anyone\n\n\nLocation\nSURFsara (NL)\n\n\nFile recovery\nVia versioning, Deleted files or file restore request\n\n\nData classification\nMedium, but with additional steps: High"
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#yoda",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#yoda",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "4.2 YODA",
    "text": "4.2 YODA\nYODA is a platform that supports research data management throughout the entire research cycle: from safe and easy storage and sharing of data during the research process, to sharing of data within research groups and projects and, ultimately, to research data archiving and publication.\n\n\n\n\n\n\n\nYODA details\n\n\n\n\n\nMax. storage size\nTerabytes of data\n\n\nCosts basic storage\n\nbelow 500 GB: free of charge\n500 GB to 2 TB: €200 per year\nabove 2 TB: €200 + €250 for every TB above 2 TB\n\n\n\nCosts archiving\n\nbelow 500 GB: free of charge\n500 GB to 2TB: €25 per year\nabove 2TB: €25 + €25 for every TB above 2 TB\n\nNOTE: Archiving will be billed for a 10-year period\n\n\nSharing and collaboration\nWith anyone\n\n\nLocation\nSURFsara (NL)\n\n\nFile recovery\nVia versioning or file restore request\n\n\nData classification\nHigh"
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#scistor",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#scistor",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "4.3 SciStor",
    "text": "4.3 SciStor\nBesides basic storage, SciStor is best suited for over-the-network use with lab\ninstruments and high-performance computing (HPC/BAZIS), either via SMB or NFS.\n\n\n\n\n\n\n\nSciStor details\n\n\n\n\n\nMax. storage size\nTerabytes of data\n\n\nCosts\n€0,10 per GB per year for reserved space (price doubles with backup for file recovery)\n\n\nSharing and collaboration\nVU employees and students\n\n\nLocation\nVU Campus (NL)\n\n\nFile recovery\nVia file restore request or versioning\n\n\nData classification\nMedium"
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#google-drive-vu",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#google-drive-vu",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "4.4 Google Drive VU",
    "text": "4.4 Google Drive VU\nThis is the well known Google Drive, only with a VU license allowing storing more data. Besides Google Drive, most applications within the Google Workspace environment, such as Google Docs, Google Sheets and Google Slides, are also available and accessible on any device.\n\n\n\n\n\n\n\nGoogle Drive VU details\n\n\n\n\n\nMax. storage size\nTerabytes of data\n\n\nCosts\nNone\n\n\nSharing and collaboration\nWith anyone\n\n\nLocation\nGoogle (WORLD)\n\n\nFile recovery\nVia versioning\n\n\nData classification\nLow"
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#microsoft-sharepoint-teams",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#microsoft-sharepoint-teams",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "4.5 Microsoft Sharepoint (Teams)",
    "text": "4.5 Microsoft Sharepoint (Teams)\nMicrosoft 365 cloud storage and collaboration.\n\n\n\n\n\n\n\nMicrosoft Sharepoint/Teams details\n\n\n\n\n\nMax. storage size\n1TB, up to 25TB\n\n\nCosts\nNone\n\n\nSharing and collaboration\nWith anyone (A Microsoft account may be required.)\n\n\nLocation\nMicrosoft Cloud (EU)\n\n\nFile recovery\nVia versioning or Recycle Bin\n\n\nData classification\nMedium"
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#open-science-framework",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#open-science-framework",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "4.6 Open Science Framework",
    "text": "4.6 Open Science Framework\nThe OSF is an open-source collaboration tool geared towards Open Science.\nAlthough not primarily a storage tool, OSF can be a very useful and easy to use way\nto share and publish your data, project documentation, or pre-registrations.\nIt is possible to connect Research Drive or Dataverse storage to OSF if your data volume is\nlarger than what OSF offers.\nThe OSF is developed by the Center for Open Science (COS) that strives to increase\nopenness, integrity, and reproducibility of research.\n\n\n\n\n\n\n\nOpen Science Framework details\n\n\n\n\n\nMax. storage size\n\nPrivate project: 5 GB\nPublic project: 50 GB (Extra storage possible on request)\n\n\n\nCosts\nNone\n\n\nSharing and collaboration\nWith anyone\n\n\nLocation\nGoogle (EU)\n\n\nFile recovery\nVia versioning or Recycle Bin\n\n\nData classification\nLow"
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#encrypted-portable-storage",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#encrypted-portable-storage",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "4.7 Encrypted portable storage",
    "text": "4.7 Encrypted portable storage\nEncrypted USB drive/disk or USB flash drive (USB stick).\nYou can order a drive or disk via the Order accessories form found in the service portal.\nPlease note that it is highly recommended to always use encryption with portable\nstorage, even if your data is classified as low.\n\n\n\n\n\n\n\nEncrypted portable storage details\n\n\n\n\n\nMax. storage size\nDepends on the device chosen\n\n\nCosts\nDepends on the device chosen (about EUR 100 per TB)\n\n\nSharing and collaboration\nNot applicable\n\n\nLocation\nLocal, direct connection\n\n\nFile recovery\nCan be configured\n\n\nData classification\nMedium (with encryption), Low (without encryption)"
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#onedrive",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#onedrive",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "4.8 OneDrive",
    "text": "4.8 OneDrive\nOneDrive for Business is part of VU Microsoft 365 cloud - also referred to as Digital@VU - and is available for employees and students. Please note that this is personal storage that is linked to the existence of your account at the VU. If you disappear, your data in OneDrive\nalso disappear.\n\n\n\n\n\n\n\nOneDrive details\n\n\n\n\n\nMax. storage size\n1TB\n\n\nCosts\nNone\n\n\nSharing and collaboration\nWith anyone\n\n\nLocation\nMicrosoft Cloud (EU)\n\n\nFile recovery\nVia versioning or Recycle Bin\n\n\nData classification\nMedium"
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#surfdrive",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#surfdrive",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "4.9 SURFdrive",
    "text": "4.9 SURFdrive\nSURFdrive is a personal cloud storage service for the Dutch education and research community, offering staff and researchers a secure and easy way to store, synchronize and share files in the SURF community cloud. Please note that SURFdrive is not available for students. However, it is possible to share files with students and others. Note that SURFdrive will be phased out at the VU before 1 July 2025\n\n\n\n\n\n\n\nSURFdrive details\n\n\n\n\n\nMax. storage size\n500GB\n\n\nCosts\nNone\n\n\nSharing and collaboration\nWith anyone\n\n\nLocation\nSURFsara (NL)\n\n\nFile recovery\nVia versioning or Deleted files\n\n\nData classification\nMedium"
  },
  {
    "objectID": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#custom-solutions",
    "href": "RDM-guidelines/VU-CS-RDM-Storage-Selection.html#custom-solutions",
    "title": "VU Computer Science Data Storage Platforms",
    "section": "4.10 Custom solutions",
    "text": "4.10 Custom solutions\nIf none of the options satisfy your requirements, a custom setup or configuration may be possible. Contact the University RDM Support Desk (rdm@vu.nl) or the department RDM contacts Shuai Wang (shuai.wang@vu.nl) and Kees Verstoep (c.verstoep@vu.nl) to explore the options.\nFor example, in our department there are currently two additional group-specific data storage options: The CI “rippers” and the LOD (Linked Open Data) server. The CI rippers are being used by researchers in the Computational Intelligence group. The LOD server is mostly used by researchers in the UCDS group and the former KRR group. The server has approximately 20TB of data storage. There are some valuable datasets on it that are not available via other data storage/archiving options. Also, the server provides LOD-specific tools to support a particular research domain.\nAnother example is the storage attached to compute facilities like DAS-5 and DAS-6 and the SURF Snellius. These storage solutions enable storing local copies of original and derived datasets for purposes of efficient high performance computing. Still, the primary copies of the source and processed datasets should typically not be kept permanently on such resources, but on the suitable storage options discussed earlier."
  },
  {
    "objectID": "OS-guidelines/open-science-resources.html#support",
    "href": "OS-guidelines/open-science-resources.html#support",
    "title": "What research resources are available for VU researchers for Open Science?",
    "section": "Support",
    "text": "Support\n\nResearch Data Services\n\n\n\nImage showing the relations between VU Research Data Support Offices, at the center with grants, legal, library, security, IT for Research, and IXA around it.\n\n\nResearch Data Management is supported by various departments at the VU. These departments will help all VU researchers. There are also faculty specific support departments for research data support; they support their own faculty members.\nHere you find references to other organisational units and departments that can help you with matters related to collecting and managing data.\nVU research data support (for all researchers)*\n\nGrant office\nLibrary\nLegal\n🔒 IT for Research\nIXA"
  },
  {
    "objectID": "blog/2024-09-30hackathon.html",
    "href": "blog/2024-09-30hackathon.html",
    "title": "Third Handbook Hackathon",
    "section": "",
    "text": "In the third hackathon for the Research Support Handbook, held on September 25th, 2024, contributors gathered to make significant progress towards migrating the handbook to the VU domain (rdm.vu.nl). The event centered around sprinting to a finish line by refining existing content and ensuring accessibility standards are met.\nKey activities included:\nOverall, the hackathon was a productive session, and the handbook is now in its final stage, with the team preparing for the official launch on &lt;rdm.vu.nl&gt;. In next hackathons, we may focus on splitting existing topics and adding new ones, as our list of idea topics is growing rapidly."
  },
  {
    "objectID": "blog/2024-09-30hackathon.html#hackathon-issues",
    "href": "blog/2024-09-30hackathon.html#hackathon-issues",
    "title": "Third Handbook Hackathon",
    "section": "Hackathon Issues",
    "text": "Hackathon Issues\nhttps://github.com/ubvu/open-handbook/issues/175 https://github.com/ubvu/open-handbook/issues/178"
  },
  {
    "objectID": "blog/2024-09-30hackathon.html#hackathon-pull-requests",
    "href": "blog/2024-09-30hackathon.html#hackathon-pull-requests",
    "title": "Third Handbook Hackathon",
    "section": "Hackathon Pull Requests",
    "text": "Hackathon Pull Requests\nhttps://github.com/ubvu/open-handbook/pull/118 https://github.com/ubvu/open-handbook/pull/165 https://github.com/ubvu/open-handbook/pull/176 https://github.com/ubvu/open-handbook/pull/177 https://github.com/ubvu/open-handbook/pull/179 https://github.com/ubvu/open-handbook/pull/180 https://github.com/ubvu/open-handbook/pull/181 https://github.com/ubvu/open-handbook/pull/184 https://github.com/ubvu/open-handbook/pull/186 https://github.com/ubvu/open-handbook/pull/188"
  },
  {
    "objectID": "blog/2024-05-23welcome.html",
    "href": "blog/2024-05-23welcome.html",
    "title": "Hello world!",
    "section": "",
    "text": "This is the first blog entry on the Research Support Handbook. We will be posting more at a later time, and are looking forward to your contributions as well.\nWe will follow up with more details later."
  },
  {
    "objectID": "blog/2024-06-27hackathon.html",
    "href": "blog/2024-06-27hackathon.html",
    "title": "First Handbook Hackathon",
    "section": "",
    "text": "On June 27th, 2024, the first hackathon for the Research Support Handbook took place with all the post authors. For this hackathon, we focused on non-GitHub based contributions, to make it as easy as possible to contribute. To make getting started with contributing easier, we created a choose your own adventure game. We document some lessons and clarifications below, in addition to the twelve reported problems and suggested changes.\nThe workshop helped articulate the dynamic relation between topics and pathways. Topics are contained pages around a specific subject; pathways are a collection of topics. This means that pathways include the topics directly and that this content should be up to date at any given time. When topics are changed, pathways are dynamically updated, making sure there are no discrepancies. The only situation where this may not be the case, is when a pathway is still a work in progress and the topics are not yet properly linked.\nPathways will become more efficient to create as we include more topics in the handbook. Given that pathways are primarily collections of topics, this means that there is barely any new content in there, if any at all. As we include more topics (eight at this time), pathways can focus more and more on the structuring of content, and focus less on creating the content itself.\nWith new contributions, contributors surfaced the need to preview the changes to the handbook. We documented two ways to render the handbook for such previews: (1) creating a Pull Request automatically deploys a preview website and (2) running quarto render locally on the code. Option 1 requires no additional software to be installed, but requires some knowledge of GitHub. Option 2 does not require much knowledge of GitHub, but requires the Quarto software to be installed. There was also the note that deploying the handbook using GitHub pages required a change to the URL, which may cause issues when merging the changes back into the main handbook. This highlights that ensuring reliable previews of contributed content is of importance to some contributors to the handbook.\nLastly, the hackathon surfaced many questions and discussions around the collaborative decisions that will need to be made. When does a topic become too long and should it be split up into multiple topics? Can a topic include subtopics? How is the GitHub environment maintained? How much technical expertise is necessary to ensure the content does not go offline? What contributor roles are there and who has which role? How do roles get distributed and can people volunteer for them? This highlights the engagement with the handbook, and we encourage everyone (including ourselves) to generously surface these discussions in issues or in a next hackathon.\nIn summary, the first hackathon is a success! This is the start of the next phase of the handbook journey, moving from design and scaffolding to nurturing and growing the contents. There will be more hackathons, and these will be announced on this blog and on other channels at VU Amsterdam. Until the next one!"
  },
  {
    "objectID": "news/2024-06-04OSCAR.html",
    "href": "news/2024-06-04OSCAR.html",
    "title": "Shuai Wang and colleagues won the Open Science Community Amsterdam Award (OSCA)!",
    "section": "",
    "text": "Through the OSCAWARDS, open science in Amsterdam is highlighted. All groups and projects with open science related aspects or challenges can be nominated for the awards.\nA project by Shuai Wang, Ronald Siebes, Jacco van Ossenbruggen, Tobias Kuhn, a bachelor student Navroop K Singh, together with colleagues from the Open Science team in the university library won the Open Science Community Amsterdam Awards (OSCA). They received a grant of 400 euros. In the project, they studied the use of FAIR Implementation Profiles for making suggestions while researchers write their Data Management Plans.\nThe paper has been accepted for publication at the MTSR conference. A preprint is available here."
  },
  {
    "objectID": "OS-guidelines.html",
    "href": "OS-guidelines.html",
    "title": "Open Science",
    "section": "",
    "text": "What is a guide?\n\n\n\nThese guides help you find answers to questions that come up while doing research. They help guide you through various topics at once.\nMissing a guide? You can submit questions you are dealing with using the Contribution portal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat research resources are available for VU researchers for Open Science?\n\n\nA page that summarized all the links.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "guides/plan-and-design.html",
    "href": "guides/plan-and-design.html",
    "title": "How can you set up research data management from the start?",
    "section": "",
    "text": "Grant programmes from organisations like NWO, ZonMw and ERC require you to think about the method of data collection, the journey of the data in your research project and how to protect or share data during and after the research project. It is important to bear in mind the specific laws and regulations that apply to the kind of data that is collected. If a project involves data on individuals and organisations this impacts the design of the necessary IT infrastructure. A more detailed description of this will later be captured in the data management plan.\nWhen writing your research proposal the following items are important:\n\nFill in the Data Management Section if your funder requires this\nPlanning: One of the early deliverables will be a detailed Data Management Plan\nBudget: Take into account the costs (labour and material) for data storage during and data archiving after your project.\nWriting: Funders that distribute grants like to maximise the effectiveness of this investment. It is therefore highly recommended that the data will be made Findable, Accessible, Interoperable and Re-usable (FAIR Principles). This does not mean that the data have to be open: Laws, licenses and contracts regarding personal and sensitive data may limit the possibility to share the data publicly.\n\nThe [RDM Support Desk[(https://vu.nl/en/about-vu/more-about/rdm-support-desk) provides advice and help when writing a Data Management Section as part of the research proposal. Also make sure to reach out to VU Amsterdam Grants Office (IXA-GO) for advice and practical aid for your grant in general as early as possible.\n\n\nMany funders require researchers to include a section in their project proposal about Research Data Management, in which they explain whether existing data will be reused, whether new data will be collected or generated during the project, and how they plan to structure, archive and share their data. Depending on requirements of the funder, the paragraph can be short or more extensive.\nFunders may have different requirements for the data management section in the project proposal. Always check what your funder asks for. Below is a list of information on data management sections from main Dutch funding bodies.\n\nNWO\nZonMw\n\nWe recommend you to ask advice from the RDM Support Desk when writing your data management section."
  },
  {
    "objectID": "guides/plan-and-design.html#research-proposal",
    "href": "guides/plan-and-design.html#research-proposal",
    "title": "How can you set up research data management from the start?",
    "section": "",
    "text": "Grant programmes from organisations like NWO, ZonMw and ERC require you to think about the method of data collection, the journey of the data in your research project and how to protect or share data during and after the research project. It is important to bear in mind the specific laws and regulations that apply to the kind of data that is collected. If a project involves data on individuals and organisations this impacts the design of the necessary IT infrastructure. A more detailed description of this will later be captured in the data management plan.\nWhen writing your research proposal the following items are important:\n\nFill in the Data Management Section if your funder requires this\nPlanning: One of the early deliverables will be a detailed Data Management Plan\nBudget: Take into account the costs (labour and material) for data storage during and data archiving after your project.\nWriting: Funders that distribute grants like to maximise the effectiveness of this investment. It is therefore highly recommended that the data will be made Findable, Accessible, Interoperable and Re-usable (FAIR Principles). This does not mean that the data have to be open: Laws, licenses and contracts regarding personal and sensitive data may limit the possibility to share the data publicly.\n\nThe [RDM Support Desk[(https://vu.nl/en/about-vu/more-about/rdm-support-desk) provides advice and help when writing a Data Management Section as part of the research proposal. Also make sure to reach out to VU Amsterdam Grants Office (IXA-GO) for advice and practical aid for your grant in general as early as possible.\n\n\nMany funders require researchers to include a section in their project proposal about Research Data Management, in which they explain whether existing data will be reused, whether new data will be collected or generated during the project, and how they plan to structure, archive and share their data. Depending on requirements of the funder, the paragraph can be short or more extensive.\nFunders may have different requirements for the data management section in the project proposal. Always check what your funder asks for. Below is a list of information on data management sections from main Dutch funding bodies.\n\nNWO\nZonMw\n\nWe recommend you to ask advice from the RDM Support Desk when writing your data management section."
  },
  {
    "objectID": "guides/plan-and-design.html#rdm-costs",
    "href": "guides/plan-and-design.html#rdm-costs",
    "title": "How can you set up research data management from the start?",
    "section": "RDM Costs",
    "text": "RDM Costs\n\nCosts & Data Management\nMany research funders encourage applicants to include data management and sharing costs in research proposals. Some funders will provide advice on costs related to data management. Some remarks on costs are provided here:\n\nThe Data Management Plan should describe the activities that incur costs and provide justification for the allocation of resources (example: acquisition of a programmer who will write software needed to capture the data).\nNo expenditure can be ‘double funded’, i.e. a service that is centrally supported by indirect costs must not be included as a direct cost as well (example: computers that are already provided to employees and paid for by the university may not be included).\nThe budget and justification should broadly indicate where RDM costs will be incurred, where possible. E.g. data capture and cleaning, data curation and preservation, data sharing.\nInclude budget for long-term storage if data are expected to be deposited in a repository not funded by the university or external funders (VU repositories are: DataverseNL, Yoda). 🔒 VU has an internal breakdown of costs for storage and archiving for VU-managed storage and repositories.\n\nA practical costing tool is available from the UK Data Archive. Based on this costing tool, Utrecht University has developed a guide to calculate the costs of data management. You can use those guides as well to estimate the costs needed specifically for RDM.\nMost material costs of the storage solutions offered by VU Amsterdam are covered centrally (up to 500 GB), but if you need to specify the costs for your project, look at the 🔒 Research & Archiving Storage Cost Model\nExamples to put in a data management plan:\n\n\n\n\n\n\n\n\n\nData Stage\nDataset\nType of data\nCosts\n\n\n\n\nRaw data\nInterviews\nAudio files\nAudio equipment rental\n\n\n\n\n\nLocation rental costs\n\n\n\n\n\nData storage & backup\n\n\nProcessed data\nTranscription of interviews\nWord files\nPersonnel costs: hiring research assistants for manual entry\n\n\n\n\n\nData storage & backup\n\n\n\nAnalysis software\nR script\nPersonnel costs: programmer to write a programme to mine the data\n\n\nAnalysed data\nRegression graphic\nPhotoshop files\nSoftware costs\n\n\n\nProject Website\nHTML, Java\nHosting fee\n\n\n\n\n\nPersonnel to build initial website"
  },
  {
    "objectID": "guides/plan-and-design.html#rdm-requirements",
    "href": "guides/plan-and-design.html#rdm-requirements",
    "title": "How can you set up research data management from the start?",
    "section": "RDM Requirements",
    "text": "RDM Requirements\nIf you do research at VU Amsterdam, you may be subject to the requirements for Research Data Management formulated by various parties. Please check which requirements apply to your research project.\nMany funders have specific requirements for RDM. The exact requirements vary by funder. They usually include a Data Management Section in the project proposal and a Data Management Plan (DMP) after funding has been granted. As funding agencies invest financially in your research project, they often have demands concerning research integrity, data quality, data publication and reusability. As research output, data are often compared to a kind of public good that should be made available to the community for re-use if possible. Always check what demands are set by a funder before you apply.\n\nFunding agencies\n\nData management section in project proposal\nAt a grant application, some funders request a short data section in your project proposal or an outline of a Data Management Plan. Without these your proposal will not be eligible for review.\n\nNWO: Data management section\nZonMw: Orientation of data management in project proposal\n\n\n\nData Management Plan\nIn a Data Management Plan (DMP; see also the section Data Management Plan) you explain how you will handle your research data. Check with your funder at what stage a DMP has to be submitted and how it should be composed. VU has a DMP template that has been acknowledged by NWO, ZonMw and ERC. We recommend you to use this VU template. See the DMP page for more information and instructions on how to select this template in DMPonline.\nThe tool DMPonline can be used to access and fill in a DMP template. You can also write a DMP in collaboration and invite a third party to comment or give feedback on your DMP. You can use the button ‘Request feedback’ to ask for feedback from a data steward. In order to write a DMP, you need to create your own account.\n\n\nOverview of funders’ RDM requirements and DMP templates\nThe Consortium of European Social Science Data Archives (CESSDA) presents a comprehensive overview of data management requirements and templates of the main Dutch and European funding bodies. This is helpful if you want to quickly find more information. However, make sure you always check the details that you receive in the documentation of your actual funding agency, so that you are aware of all up-to-date requirements.\n\nNational: NWO, ZonMw\n\n\n\nPublishing your data and terms of use\nNormally a funder requires you to publish your data in a data repository at the end of the project (unless this is prohibited by legislation). For that reason, DMP templates usually include the following questions:\n\nwhere your dataset can be found\nwhether your dataset has a Persistent Identifier\nhow your data are documented\nwhether your data may be reused freely or not and which terms and conditions apply\n\nPlease consider your funder’s data publishing requirements, so that you can take the necessary steps before and during your research project. For example, if you are working with personal data and you want to publish them in a data repository, this needs to be included in the informed consent forms that your participants have to sign.\n\n\n\nLocal requirements from your university and faculty\nVU Amsterdam is committed to support research that meets the highest requirements of replicability and transparency. The FAIR data principles, the purpose of which is to render research data Findable, Accessible, Interoperable and Reusable, the General Data Protection Regulation (GDPR) and the principles of Open Science are at the foundation of the Research Data Management (RDM) policy of VU Amsterdam.\nIn addition to the central policy for RDM, faculties of VU Amsterdam also have developed their own implementation of this policy.\nPlease check the relevant local policies and Standard Operating Procedures relevant for your faculty or department before you start your research project. An overview of all available policy documents can be found in the section VU policies and regulations.\n\n\nConsortium partners\nPartner institutions in a consortium may also have research data management requirements, for example with respect to data security. They may ask for:\n\ncertification in relation to data security of VU Amsterdam’s infrastructure\nstatements from the IT department about the IT systems being used at VU Amsterdam\n\nThe RDM Support Desk or your faculty’s research support office can help you with this."
  },
  {
    "objectID": "guides/plan-and-design.html#collaboration",
    "href": "guides/plan-and-design.html#collaboration",
    "title": "How can you set up research data management from the start?",
    "section": "Collaboration",
    "text": "Collaboration\nSome research projects involve more than one partner organisation. Be sure to indicate exactly who is responsible for collecting and managing the data in each case, where, and how. If more than one organisation is involved, it may also be necessary to create a Consortium Agreement. Depending on the area or sector of each project and of the degree of technical complexity that is involved, the Consortium Agreement usually contains the following information:\n\nprovisions on the governance structure of the consortium;\ntechnical provisions (e.g. the tasks of each party and the project schedule, description of the data collection responsibilities);\nfinancial provisions (e.g. the distribution of funds among participants, the financial plan, etc).\n\nThe agreement can include a section on who is ultimately responsible for the data and whether the data will be shared afterwards or whether certain restrictions on re-use apply. These restrictions can also be related to copyright issues or pending patent requests. IXA can help you to draw up a consortium agreement. The RDM Support Desk at the University Library can also help with questions about legal matters.\nIf you are working with personal data, GDPR requires that all parties working with the data sign a joint controller agreement. You can ask your 🔒 Privacy Champion for advice about this. For multi-centre clinical research, a Clinical Trial Agreement is recommended.\nFor projects funded by the European Union, several sources are available:\n\nFor Horizon 2020 projects a document is available, called “Guidance How to draw up your consortium agreement”."
  },
  {
    "objectID": "guides/plan-and-design.html#data-security",
    "href": "guides/plan-and-design.html#data-security",
    "title": "How can you set up research data management from the start?",
    "section": "Data Security",
    "text": "Data Security\n\nData classification\n‘Security’ is often regarded as a fixed state. Therefore, people tend to think of security measures as fixed solutions in the form of technological measures. In reality, security is an assessment of the level of protection against a certain threat, that you consider to deal with that threat adequately enough. Whether or not security is accurate depends on the value of the data and the quality of protective measures.\nThe value of data or applications is established through classification in Confidentiality, Integrity and Availability (CIA) or in Dutch Beschikbaarheid, Integriteit en Vertrouwelijkheid (BIV).\nTraditionally, this classification assesses the value of an entity (data or application) to an organisation. For research data, however, the value to the University is in all cases the same. The value of each research project is the same. Does that mean that there is no need to classify research data? Referring back to the definition of security, it is the assessment of the level of protection against a certain threat and its accuracy depends on the value of (in this case) data. The reason to classify research data is that there is a huge variety in potential risks in case of data loss or theft.\nThe reason that VU and its reseachers need to classify data is to understand the variety in risk that exists in order to assess if security measures are accurate.\nData classification is about the level of sensitivity (low, medium or high) of your data assets so you can judge the risks to your research (group). This will help you when deciding what security and protection measures you need to take for handling the data or parts of the data.\n\nPolicy Classification of Research Data\nThe Policy Classification of Research Data addresses classification of research data in terms of availability, integrity and confidentiality, and how the classification process should be carried out. It is connected to the Research Data and Software Management Policy, because the latter states that data must be handled in a secure and reliable manner. The Research Data Classification Policy will determine what level of security measures are necessary to manage data securely.\n\n\nData classification criteria\nIn order to classify your data collection or data processing (in categories from low, to medium, or high), the following properties are considered.\n\nAvailability: what risks are associated with accessibility to data (i.e. how readily do the data need to be available for use and how damaging would it be to your research if data are lost), what measures should you take to prevent data loss?\nIntegrity: what do you do to prevent measurement or data entry errors, corruption of stored data or unauthorised changes to the stored data?\nConfidentiality: how securely do data need to be managed to prevent sharing of data with unauthorised individuals? The necessity for confidentiality depends on the sensitivity of the information, either as sensitive personal information or confidential business information, as well as the vulnerability of the subjects from whom the data is collected and the laws that apply to the data being collected and analysed. In some cases, confidentiality can be very high; when the confidentiality is high or very high, please contact the RDM Support Desk.\n\nFor all of these aspects, the damage impact should be considered, i.e. te risks to all parties involved (i.e. participants, but also VU Amsterdam as an institute, the researchers, any collaborators etc.). Untoward outcomes could be loss of privacy/secrecy, reputation damage, financial costs, fraud, mental, social or physical harm.\n\n\nExamples of Highly classified data\nYour data are classified as ‘high’ when you collect or process the following data:\n\npersonal data\nstate secrets\ncompetitive corporate information\nanimal-testing data\n\n\n\nPersonal data\nDo not confuse the risks of data loss with the need to comply to legal regulations. Data security is part of risk management and is aimed at balancing protection against productivity, investments against profit. The General Data Protection Regulation is a European Law in the legal area of Human Rights and concerns the use of personal data. Personal data are a type of data that is commonly processed in many fields of scientific research. You collect or process personal data when the data can be linked to a unique individual, either directly through direct identifiers such as name, address, IP-address etc., or indirectly through a combination of information. Personal data need to be protected. More information about personal data, data protection and the GDPR can be found in the section GDPR & Privacy.\n\n\nData Classification tool for researchers\nTo help you to determine the data classification for your research data assets, VU Amsterdam has developed a tool that will help you to assess and classify the availability, integrity and confidentiality risks of these assets. Based on your results from using the tool, you may need to seek further advice from VU Security and Privacy Experts (see below). Some basic security tips were compiled by the data steward of the Faculty of Behavioural and Movement Sciences.\n\n\nVU Security and Privacy experts\nVU Security and Privacy experts can help you with the details on these aspects.\n\nGeneral questions about information security: RDM Support Desk. If you need advice when determining the data classification of your data assets, you can contact them.\nReporting a (potential) data breach: IT Servicedesk. A data breach is an incident in which the possibility exists that the confidentiality, integrity or availability of information or data processing systems has been potentially threatened, for example attempts to gain unauthorised access to information or systems (hacking), the loss of a USB stick with sensitive information, data theft of hardware.\nTailored advice or support: The RDM Support Desk can assist researchers in the process of requesting capacity at IT for setting up and/or assessing of information security plans or paragraphs. An information security plan is particularly important in projects with a complex infrastructure (e.g. international collaboration, use of various data sources and databases), tailored solutions and requirements from funding agencies or external partners.\n\nRead more practical information about this below in the section Data Protection & Security, or the GDPR support section.\n\n\n\nData Protection & Security\nWhere sensitive information is collected, the researcher must consider the following:\n\nwho has access to the data during the study, and how the data will be made available after publication\nwhat security regimes apply to sensitive data, and how data are protected\nhow data access during and after the project will be managed\nhow to deal with sensitive information\nwhether informed consent is required and how the forms will be accessed and stored\n\nOn the 🔒 VU Intranet information is available on Security, data loss and reporting incidents. Legal experts also can help you if you have questions about working with personal data and/or if you have to perform a Data Protection Impact Assessment. On VU Amsterdam website you can find more information about 🔒 DPIAs at VU Amsterdam. The data steward for the Faculty of Behavioural and Movement Sciences has also created a guide about data encryption."
  },
  {
    "objectID": "guides/plan-and-design.html#gdpr-privacy",
    "href": "guides/plan-and-design.html#gdpr-privacy",
    "title": "How can you set up research data management from the start?",
    "section": "GDPR & Privacy",
    "text": "GDPR & Privacy\n\nDefinitions\n\nPersonal data refers to any information relating to an identified or identifiable natural person (‘data subject’). See also the definition of ’personal data’ according to the official text of the GDPR.\nData processing refers to any action performed on data, such as collecting, storing, modifying, distributing, deleting data. See also the definition of ‘processing’ according the official text of the GDPR.\nDirect and indirect identification: Some identifiers enable you to single out an indiviual directly, such as name, address, IP-address etc. Individuals can also be identifed indirectly through:\n\na combination of information that uniquely singles out an individual (e.g. a male with breast cancer in a breast cancer registry, a pregnant individual over 50 etc.), this includes information in one record and information across different data files or datasets\nunique information or patterns that are specific to an individual (e.g. genomic data, a very specific occupation, such as the president of a large company, repeated physical measurements or movement patterns that create a unique profile of an individual or measurements that are extreme and could be linked to subjects such as high-level athletes)\ndata that are linked to directly identifying information through a random identification code or number\n\nPseudonymous data: Data that are indirectly identifiable are generally considered to be pseudonymous; this means that they are NOT anonymous and still qualify as personal data. Therefore privacy laws, such as the GDPR, do in fact apply to these data. This is for example the case when direct identifiers are removed from the research data and put into a key file (or what is usually called a subject identification log in medical research) with which the direct identifiers can be mapped to the research data through unique codes, so that reidentification is possible. These data are therefore pseudonymous, and not anonymous. The LCRDM has made a reference card that illustrates the difference between pseudonymous and anonymous data.\n\n\n\nBackground information\n\nPrivacy in research - Privacy five-step plan\nWhere research requires the collection of personal data, the researcher has to follow the Privacy five-step plan to make sure to carry out the research in line with the GDPR.\n\n\nVSNU Code of Conduct for using personal data in research\nThe VSNU’s Code of Conduct for Research Integrity (Dutch, English, 2018) includes a reference to the GDPR and its Dutch implementation law UAVG. An updated Code of Conduct for Using Personal Data in Research which complies with GDPR is still work in progress.\n\n\n\nSupport within your faculty: Privacy Champions\nEach faculty has one or more Privacy Champions, who are the first point of contact for questions relating to privacy and the GDPR. The Privacy Champions can help you with completing a Data Protection Impact Assessment, registering your research in the record of processing activities, designing informed consent forms and other questions relating to the GDPR. The 🔒 list of Privacy Champions can be found on VU’s website. It is important that you make an overview of what data you are collecting. Your privacy champion can help you with this.\nAn important issue in informed consent forms, is the possible future (re-)use of the data. The Privacy Champion of the Faculty of Behavioural and Movement Sciences prepared a checklist for what to consider when creating an informed consent form. An important issue in informed consent forms, is the possible future (re-)use of the data. You should always ask your 🔒 Privacy Champion for advice when drawing up an informed consent form.\n\n\nComplete a Data Protection Impact Assessment (DPIA)\nWhen scientific research includes the processing of personal data, conducting a Data Protection Impact Assessment (DPIA) may be a legal requirement under the GDPR. If it is not a legal requirement, conducting a DPIA is always a helpful exercise to make sure that you address all legal aspects that need to be addressed. It is the best way to GDPR-proof your research.\n\nWhat is a DPIA?\nA DPIA is an assessment to identify the risks of processing personal data. It consists of a number of questions on the basis of which you determine whether the processing of personal data in your research project is legitimate and which measures should be taken to make sure this processing takes place within the boundaries of the GDPR. A DPIA doesn’t deliver an automatic report at the end, but it rather makes you think about all relevant topics you need to address before starting the processing of personal data. The outcome of a DPIA should be used to determine appropriate measures to mitigate the identified risks, such as data minimisation (not collecting more data than necessary), pseudonymising data, selecting appropriate tools for data storage and data sharing.\n\n\nWhen is a DPIA required?\nA DPIA is required when the processing of personal data is likely to result in a “high risk” for the participants of your research project. This is for example most likely the case when scientific research includes the processing of special categories of personal data, such as data concerning health, religious or philosophical beliefs, political opinions or criminal convictions and offences (see Privacy in Research - 10 key rules for more information about special categories of personal data).\nThere are two DPIA lists which describe situations in which a DPIA is required:\n\nThe Dutch data protection authority (Autoriteit Persoonsgegevens) has published a list of 17 “high risk” situations in which a DPIA is mandatory.\nThe European data protection authorities have together published a list of 9 criteria which can be used to determine whether there is a “high risk”.\n\nYou should consult your 🔒 Privacy Champion to determine whether a PreDPIA is required in your situation.\n\n\nHow can I complete a DPIA?\nVU Amsterdam has a DPIA template based on a form provided by the Dutch Government (see the original template if you wish to have more background information, only available in Dutch).\nYou should request the template from your 🔒 Privacy Champion.\nPlease complete a DPIA at least before you start collecting personal data. In some cases, it might be useful to have a look at the DPIA template at the stage of writing a research proposal.\nIf you are not sure whether it is required to conduct a DPIA or if you need help completing a DPIA, please contact your faculty’s 🔒 Privacy Champion. If needed they can contact the legal specialists of Institutional and Legal Affairs.\n\n\n\nData breach incident report\nFrom 2016 onwards, any data security breaches (particularly those that have, or are likely to have, serious adverse consequences to the protection of personal data) should be reported immediately to the IT Servicedesk. Read the 🔒 protocol reporting a data breach."
  },
  {
    "objectID": "guides/plan-and-design.html#policies-regulations",
    "href": "guides/plan-and-design.html#policies-regulations",
    "title": "How can you set up research data management from the start?",
    "section": "Policies & Regulations",
    "text": "Policies & Regulations\n\nVU General Policies and Regulations\n\nResearch Data and Software Management Policy\nVU Amsterdam considers the careful handling of research data and software to be very important. The university has therefore formulated a Research Data and Software Management Policy which articulates how to handle research data and software. The policy lists the responsibilities regarding research data and software management for researchers, department heads, faculty boards and the university as a whole.\n\nVU Research Data and Software Management Policy (2024) in English and in Dutch\n\nSince the VU Amsterdam policy for Research Data and Software Management is formulated in general terms, faculties have worked out more detailed policies and guidelines for their own faculty. These faculty-specific guidelines can be found below.\n\nACTA RDM policy, Academisch Centrum Tandheelkunde Amsterdam (2020, in Dutch)\nBeta RDM policy, Faculty of Science (2022)\nFGB RDM policy, Faculty of Behavioural and Movement Sciences (2023)\nFGW RDM policy , Faculty of Humanities (2023)\nFRT RDM policy, Faculty of Religion and Theology (2024)\n🔒 FSW RDM policy, Faculty of Social Sciences (2023)\nRCH RDM policy, Faculty of Law (2021)\nSBE RDM policy, School of Business and Economics (2023)\n\nFor RDM policies and guidelines at Amsterdam UMC, location VUmc, please get in touch with Research Data Management Support at Amsterdam UMC.\nIf you have questions about the VU-central Research Data and Software Management Policy, please contact the RDM Support Desk.\n\n\nDomain-specific guidelines and protocols\nSome faculties and departments have their own guidelines for RDM. You can find an overview of such guidelines below.\n\nAmsterdam Public Health Quality Handbook\nFGB: Code of Ethics for Research in the Social and Behavioural Sciences Involving Human Participants\n\n\n\n\nEthical Review\nIn cases where research involves human or animal participants, a research proposal may need to be reviewed by an ethics committee. VU Amsterdam and Amsterdam UMC (location VUmc), have several ethics committees, which are listed below. Please note that researchers at VU Amsterdam also have to go to the METc at VUmc if their research is subject to the WMO, which is not restricted to research at VUmc.\n\nEthics committees\n\nACTA: ACTA Ethics Review Board (ETC)\nBeta: Research ethics review committee Faculty of Science (BETHCIE)\nFGB: 🔒 Scientific and Ethical Review Board (VCWE)\nFGW: Ethische Toetsingscommissie Onderzoek (EtCO)\nFSW: 🔒 Research Ethics Review Committee (RERC)\nRCH (Faculty of Law): Ethics Committee\nSBE: Ethical Review Board (ERB)\nVUmc (Amsterdam UMC): Medical Ethical Review Committee (METc)\n\n\n\n\nAcademic Integrity\n\nNetherlands Code of Conduct for Research Integrity\nDutch scientists are required to comply with the Netherlands Code of Conduct for Research Integrity (VSNU, 2018). The principles of proper scientific and scholarly research, according to the Code of Conduct are:\n\nHonesty\nScrupulousness\nTransparency\nIndependence\nResponsibility\n\nThe principles of honesty and transparency state explicit guidelines for the way in which you treat your research data:\n\nHonesty: you should refrain from fabricating or falsifying data\nTransparency:\n\nYou should ensure that it is clear to others what data your research is based on, how the data were obtained, what the results are and how you got to these results\nAll steps in your research process must be verifiable (e.g. choice of research question, research design, methodology, sources used), so that it is clear to others how your research was conducted\n\n\nTo live up to these general principles, the Code of Conduct provides the following standards, which are addressed in a Data Management Plan (DMP), for good research practices related to data management:\n\nProvide a description of the way in which the collected research data are organised and classified, so that they can be verified and re-used (standard 3.2.10)\nMake research data public upon completion of your research project; if this is not possible, explain why (standards 3.2.11 and 3.4.45)\nDescribe the data you have collected and used in your research honestly, scrupulously and transparently (standard 3.3.23)\nManage your data carefully and store both the raw and processed versions for a period appropriate for your discipline (standard 3.3.24)\nContribute towards making data FAIR, where possible (standard 3.3.25)\nBe transparent about your methods and working procedures by using e.g. research protocols, logs, lab journals or reports to describe these processes (standard 3.4.35)\n\n\n\nAcademic integrity at VU Amsterdam\nTo protect academic integrity at VU Amsterdam and Amsterdam UMC (location VUmc) subscribe to the Netherlands Code of Conduct for Research Integrity. On the Academic Integrity page on the VU website, you can find more information about how these organisations implement the duties of care for institutions to uphold the principles of academic integrity.\n\nConfidential counsellors\nVU Amsterdam has a number of confidential counsellors who handle academic integrity issues.\n\n\nAcademic integrity complaints procedure\nVU Amsterdam and Amsterdam UMC, location VUmc employ a joint policy for the handling academic integrity complaints. This policy outlines the steps to be taken in the event of a complaint, the officers who play a role in this procedure, and what should be expected once a complaint has been lodged.\n\n\n\nRIOS: Center for Research Integrity and Open Science\nRIOS connects initiatives related to research integrity, research ethics, responsible research and innovation, open science, and research culture at VU Amsterdam and Amsterdam UMC. The mission of RIOS is to strengthen the position of VU Amsterdam and Amsterdam UMC regarding research integrity and open science.\n\n\n\nNWO Data Policy\nNWO aims to ensure that all the research it funds is openly accessible to everyone as part of it’s Open Science policy. Researchers are therefore expected to preserve the data resulting from their projects for at least ten years, unless legal provisions or discipline-specific guidelines dictate otherwise. As much as possible, research data should be made publicly available for re-use. As a minimum, NWO requires that the data underpinning research papers should be made available to other researchers at the time of the article’s publication, unless there are valid reasons not to do so.\nThe guiding principle here is ‘as open as possible, as closed as necessary.’ Due consideration is given to aspects such as privacy, public security, ethical limitations, property rights and commercial interests. In relation to research data, NWO recognizes that software (algorithms, scripts and code developed by researchers in the course of their work) may be necessary to access and interpret data. In such cases, the data management plan will be expected to address how information about such items will be made available alongside the data.\nMore information on Data Management is also available on the NWO website where a NWO Data Management Template is made available. The VU Data Management template in DMP Online is certified by both NWO and ZonMW and can also be used by VU researchers for projects funded by both organizations."
  },
  {
    "objectID": "guides/process-and-analyze.html",
    "href": "guides/process-and-analyze.html",
    "title": "How can you ensure data provenance and accurate data analysis?",
    "section": "",
    "text": "Provenance describes the origin of an object. Data provenance refers to the knowledge of where data originate, where they were collected, by whom, for what reason, and similar aspects that help to understand how the data were originally gathered, processed and altered. In daily use, the term “data provenance” refers to a record trail that accounts for the origin of a piece of data (in a database, document or repository) together with an explanation of how and why it got to the present place (Encyclopedia of Database Systems, pp 608-608). You can also call it the process of keeping records of changes in the data. The need for Data Provenance increases as the reuse of datasets becomes more common in research. The term was originally mostly used in relation to works of art, but is now used in similar senses in a wide range of fields (Wikipedia).\n\nResearchers regularly use a lab notebook or a journal to document their hypotheses, experiments and initial analysis or interpretation of these experiments. If you manually change data in a dataset, this should also be documented. Sometimes records of changes in data can be kept by adding notes to programmes or scripts that are used.\n\nElectronic Lab Journals or Electronic Lab Notebooks are used to meticulously describe and document the process of analysis. Mostly used used in a laboratory environment,; biolab, chemical lab, etc.\nFor computational analyses, Computational Notebooks like Jupyter notebook are used, where you can describe the analysis steps alongside the computer code in different languages like Python, R, Spark, etc. It is important to document steps and changes in your code by writing comments. This way, others and future you can understand how your code works.\nThe Open Science Framework connects different storage types you already use (for example, Dataverse) and logs automatically all changes of all the steps you make while you progress. With the fine grained history-log and version control system of OSF, you can see all steps you made. You can store and archive the whole provenance trail for citable reproducibility.\n\nFinally, when a dataset contains personal data, data provenance can help researchers to understand the specifics and the context in which the data were gathered, also to be able to assess whether or not the informed consent given for the first research, is applicable.\nFor every step of your data analysis, good Data Documentation is necessary."
  },
  {
    "objectID": "guides/process-and-analyze.html#data-provenance",
    "href": "guides/process-and-analyze.html#data-provenance",
    "title": "How can you ensure data provenance and accurate data analysis?",
    "section": "",
    "text": "Provenance describes the origin of an object. Data provenance refers to the knowledge of where data originate, where they were collected, by whom, for what reason, and similar aspects that help to understand how the data were originally gathered, processed and altered. In daily use, the term “data provenance” refers to a record trail that accounts for the origin of a piece of data (in a database, document or repository) together with an explanation of how and why it got to the present place (Encyclopedia of Database Systems, pp 608-608). You can also call it the process of keeping records of changes in the data. The need for Data Provenance increases as the reuse of datasets becomes more common in research. The term was originally mostly used in relation to works of art, but is now used in similar senses in a wide range of fields (Wikipedia).\n\nResearchers regularly use a lab notebook or a journal to document their hypotheses, experiments and initial analysis or interpretation of these experiments. If you manually change data in a dataset, this should also be documented. Sometimes records of changes in data can be kept by adding notes to programmes or scripts that are used.\n\nElectronic Lab Journals or Electronic Lab Notebooks are used to meticulously describe and document the process of analysis. Mostly used used in a laboratory environment,; biolab, chemical lab, etc.\nFor computational analyses, Computational Notebooks like Jupyter notebook are used, where you can describe the analysis steps alongside the computer code in different languages like Python, R, Spark, etc. It is important to document steps and changes in your code by writing comments. This way, others and future you can understand how your code works.\nThe Open Science Framework connects different storage types you already use (for example, Dataverse) and logs automatically all changes of all the steps you make while you progress. With the fine grained history-log and version control system of OSF, you can see all steps you made. You can store and archive the whole provenance trail for citable reproducibility.\n\nFinally, when a dataset contains personal data, data provenance can help researchers to understand the specifics and the context in which the data were gathered, also to be able to assess whether or not the informed consent given for the first research, is applicable.\nFor every step of your data analysis, good Data Documentation is necessary."
  },
  {
    "objectID": "guides/process-and-analyze.html#data-processing",
    "href": "guides/process-and-analyze.html#data-processing",
    "title": "How can you ensure data provenance and accurate data analysis?",
    "section": "Data processing",
    "text": "Data processing\n\nData cleaning\nThe process of detecting and correcting (or removing) corrupt or inaccurate information or records, is called data cleaning. In essence, it refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting this data (Wikipedia). Depending on the type of analysis that is done, different pieces of software can be used to do this data cleaning. More often than not, the same software can also be used to perform the analysis. Licensed software may sometimes also be installed on personal computers or laptops.\n\nSoftware especially designed to clean re-used data is OpenRefine. It cleans starting and trailing blank spaces in cell field, clusters values based on similarities (e.g. in free text fields: Alphen a/d Rhijn, alfen ad rijn, etc. can be easily clustered), normalise data fields into one standard, etc. See below for several tutorials.\nIn some cases, researchers write their own scripts (in programming languages such as Python, R or SQL) to clean data, in which case the process must be documented. Researchers should include their scripts when they archive the datasets to allow for replication and verification.\nExtra background information:\n\nEMGO Quality Handbook on data cleaning\nMaking sense of data I: a practical guide to exploratory data analysis and data mining / Glenn J. Myatt, Wayne P. Johnson, 2014 (eBook)\nOpen Refine\n\nData Carpentry Open Refine website\nTutorial by the Programming Historian\nIntroduction to Digital Humanities with Open Refine\n\n\nFor every step of your data cleaning, good documentation and clarifying the data provenance is necessary.\n\n\nData transcription\nIt is common in many fields to hold interviews, focus group sessions, or make other observations that were recorded - video or audio. If indeed you have done so, and you need to have the text transcribed, there are several ways to do this. One option is to do this by hand, although this is very time-consuming.\nAnother option is to pay a transcription service to make the transcription or to use specialised software. VU Amsterdam has drawn up processing agreements with one transcription service, Transcript Online, and one transcription software service, Amberscript.\nYou can find more information on the VU Library page on what these transcription options do, how they work, how much they cost, and how they can be used.\n\n\nAnonymisation/Pseudonymisation\nProcessing of personal data requires you as a researcher to make sure that any personal data collected from a human subject is according to the EU GDPR regulation. Anonymisation and Pseudonymisation are two ways to make personal data less easy to identify, in other words, it allows you to de-identify personal data.\nThere are various online tools that may help facilitate these processes. VU Amsterdam has therefore recommended Amnesia as one of the tools to assist in the anonysmisation/pseudonymistaion of data.\nVU Amsterdam is preparing a decision guide on anonymisation and pseudonymisation."
  },
  {
    "objectID": "guides/process-and-analyze.html#data-analysis",
    "href": "guides/process-and-analyze.html#data-analysis",
    "title": "How can you ensure data provenance and accurate data analysis?",
    "section": "Data analysis",
    "text": "Data analysis\n\nData Analysis\nAlthough data analysis is an ongoing process throughout the research project, this page focuses on the analysis of the data subsequent to its collection. To ensure that research is empirical and verifiable, it is crucial that researchers keep records (data documentation) of every step made during the data analysis.\nData analysis converts raw/processed data into information that is useful for understanding. Many steps may be required to gain useful information from raw data. The process of processing and analysing data may require computing power not readily available or specific storage and protection options. If multiple parties are involved in the analysis, data sharing may also be necessary.\nData analysis often requires the use of specialised software.The software offered and licensed by the university currently includes: Stata, SPSS, and Atlas.TI. For open software, see below.\nIn some cases researchers write their own scripts to analyse the data. At VU Amsterdam, most scripts are written in R, Python and SQL.\nIf you want to read up on data analysis you should check out what journal articles and books VU Amsterdam library has available on the subject:\n\nAll sources: Data analysis\nQuantitative data analysis\nQualitative data analysis\nBig data\nData mining\n\n\n\nOpen Software\nUsing open software increases the Accessiblity, Interoperability and Reusability of your data. For that reason, we recommend that you use open software as much as possible for your data analysis. This could be software, code or scripts that you have written yourself - where possible, please make this software public, so your analysis is reproducible. Examples of open software are R and Python, which can be used instead of proprietary, commercial software such as SPSS and Matlab.\nResearchers often write their software themselves. There are also organisations that specialise in writing research software, such as the eScience Center. The eScience Center offers the software they built for free use online. Their software is tagged with a DOI and stored in Zenodo as well as GitHub.\nIf you use software for analysing personal or otherwise sensitive data, you need a processing agreement with the developer if the software does not run locally. You can contact your 🔒 Privacy Champion if you are not sure if you need one, and for help to set up a processing agreement.\nThere are several ways in which to start using open software:\n\nFor Python: you should install Anaconda and launch the Jupyter Notebook from the Navigator.\nFor R: you should install Anaconda and launch R Studio from the Navigator.\nUse the Software Carpentries to learn the basics of programming in Python and R and version control with Git\nRead the recommendations for FAIR Software.\n\nVU Amsterdam has several research groups that offer their code online. You can find them here:\n\nThe Systems Bioinformatics research group, on GitHub\nThe Computational Lexicology & Terminology Lab, on GitHub\nThe course Python for Text Analysis, on GitHub\nVU RDM Tech IT group, on GitHub\nA list of RDM tools, on GitHub\n\n\n\nCompute services\n\nIf your pc or laptop takes too much time performing your analysis, it is time to scale up to a higher level. There are several options for employees and students who require more computing power than their own desktop or laptop can provide.\nSeveral options are detailed below. 🔒 Contact IT for Research for advice on which solution could best fit your workflow\n\nHigh Performance Computing (HPC)\n\n\n\nA set of servers in an undescript room\n\n\nRoughly speaking, you should try to get access to the HPC when you need to stick a post-it on your laptop or PC that says: “do not touch, analysis ongoing”. Or when you want to run analyses parallel to each other, because they take too long. It is important to consider such a situation at the very beginning of your research or when writing your Data Management Plan: is it conceivable that your dataset will become so large or your analysis so complicated that you will need HPC? Please note that this can occur for any discipline and any sort of data, qualitative and quantitative. If you may need HPC, you also need to reconsider your analysis methods. Programmes like SPSS and Excel do not run well on a HPC, and you would need to (learn to) write scripts in R or Python. If you want to know if using HPC may be necessary or useful for your project, you can contact IT for Research to ask for more information (select the “Onderzoek service domain”).\n\n\nSURF Snellius Compute Cluster\nSnellius is the Dutch National supercomputer hosted at SURF. The system facilitates scientific research carried out in many Universities, independent research institutes, governmental organizations, and private companies in the Netherlands.\nIt’s a service comprising a wide range of resources, compilers and, such as R statistics and MATLAB, and libraries. SURF continually adjusts the service to the needs of the user community. For example, Snellius Compute Cluster includes accelerators (very fast processors),high memory nodes and GPU nodes. \nYou can find more information on the SURF Snellius Wiki.\n\n\nBAZIS Compute Cluster\nIT for Research (ITvO) offers access to your own Linux computational cluster at VU Amsterdam. BAZIS is a managed service for high performance computing (HPC). Research groups can add their own compute server hardware to BAZIS, ITvO will take care of configuring and maintaining the software stack on your servers.\nBAZIS also has several “community” nodes for use by all VU researchers, sponsored by VU Amsterdam HPC Council.\nBAZIS is connected to SciStor  providing easy access to your research data and analysis result.\n\n\nVU JupyterHub for education\nIf you are not yet ready to take the leap to cluster computing and work with Python consider JupyterHub. VU IT has built a Jupyter Notebook environment meant mainly for Education purposes, but accessible for researchers as well on https://hub.compute.vu.nl/\n\n\n(Virtual) servers\nThere are also several options to run applications in a server environment. This is useful if for example you use software that does not work on HPC, you want to run a web service, you want to create a research environment for your project. There are several options available for researchers.\n\nSciCloud\nIT for Research (ITvO) offers a virtual server environment where you can run your own server (Linux or Windows). ITvO installs the basic operating system and you are free to install needed software. Web services can be made accessible on the internet. You can find more information and a request form on the 🔒 VU service portal\n\n\nSURF Research Cloud\nSURF also offers a virtual server environment. Several environments with pre-installed software can easily be installed from a catalog. Find more information on the SURF wiki.\n\n\nDedicated hardware\nSometimes your workload needs dedicated hardware. ITvO offers the option to host your own server hardware in our on-campus data center. Please 🔒 Contact IT for Research to discuss possibilities."
  },
  {
    "objectID": "guides/discover-and-initiate.html",
    "href": "guides/discover-and-initiate.html",
    "title": "How can you discover and reuse existing research data?",
    "section": "",
    "text": "Re-using Existing Data\nAnything that can be used for analysis can be considered “data(sets)”. Many national and international organisations provide access to large datasets free of charge: this is called Open Data.\nDatasets may contain different kinds of data files, e.g. raw or edited/cleaned data, and macro or micro data. Raw data refers to the data as they are primarily collected, and includes all data, even the missed or mismatched pieces in the data file. Edited or cleaned data refers to data that have been tidied up for analysis and publication. Macro data and statistics are results based on micro data units and provide a general overview of the micro data. Although datasets can contain data of varying type or aggregation level, and there may be overlap between these definitions, each element can contain very important information.\nWhen re-using research data, scientists must be familiar with the rules and regulations governing data copyright, intellectual property rights, and laws governing sensitive or personal information. SURF has compiled a report on the legal status of raw data including information on the types of consent required for the re-use of data. Your 🔒 Privacy Champion can answer questions about the use of personal data. IXA can provide legal help with the re-use of data.\nSee also the ZonMw explanation of different kinds of property rights in the Netherlands (text available in Dutch only).\n\n\nSources for Finding Existing Datasets\nThe number of datasets that are available grows rapidly. Datasets are made available in many formats, by many people or organizations. Some datasets are raw files and some are specifically organised and formatted as databases that require a licence or subscription to use them. The library of VU Amsterdam has collected links to some of the data repositories used and has licensed several databases.\n\nPopular Free and Licensed Databases: These can be found with LibSearch Advanced.\n\nIf you need help finding & using free or licensed sources you can contact the Research Data Services Helpdesk. For students and personnel in the fields of economics, finance, or organisation science a separate LibGuide has been created to help them find and use/re-use data.\nYou can also start looking for data in these four places:\n\nThe literature. Research articles may point you to the data that they are based on. Sometimes, (part of) the data are added to the article as supplementary files, and sometimes the data are published separately in a data repository. In the latter case, the article usually provides a clear reference to the published dataset. Some datasets may even be specifically published in Data Journals.\nScientific data repositories. Data repositories are platforms used to access and archive research data. Universities often provide a repository for data archiving, but other platforms arranged by discipline or by country also exist. Some repositories are only accessible to consortium members, whereas others are free of charge. Many universities in the Netherlands use DataverseNL to archive datasets for the mid-term. Long-term archiving is provided by the national research data archives DANS and 4TU.Research Data. In Europe, B2SHARE and Zenodo are platforms used to access research data. Data repositories can be accessed by searching by topic or country using Re3data, a data repository registry. VU Amsterdam has its own research portal, PURE, where researchers register their datasets. You can find instructions on how to register your own dataset in PURE on the Dataset Registration page of this LibGuide.\nData search engines. Search engines allow you to quickly browse data sets and supplementary data files published by researchers. They cover data sets from many sources. This makes them useful for quick orientation on a topic. Example of a search engines are: DataCite, Google DataSet Search.\nData portals of (governmental) organisations. Organisations that regularly collect (statistical) data sometimes offer these data through their own portal. An example is Eurostat, which collects and disseminates statistics at the European level, by country and by theme. Some of these websites have been linked in the Finding data LibGuide.\n\n\n\nData Sources for VU Researchers\nResearchers from VU Amsterdam have also developed some databases containing data collected during research. See here for some examples:\n\nNederlands Tweelingenregister (Netherlands Twin Register) The database contains data on twins and their families and was created to do research on the relationship between genetics and growth, development, personality, behaviour, diseases, mental health and all kinds of risks.\nGeoplaza VU - the portal for all matters related to GIS (Geographical Information Systems) and geodata at VU Amsterdam. It offers students and employers a platform to exchange, examine and download digital map material.\nDutch monasteries - database with information about Dutch monasteries of the Middle Ages.\nSlave owners in Amsterdam 1863 - the place of living of owners of slaves in Amsterdam in 1863, visualized in GeoPlaza.\nDeaths at the Borders Database - collection of official, state-produced evidence on people who died while attempting to reach southern EU countries from the Balkans, the Middle East, and North & West Africa, and whose bodies were found in or brought to Europe.\nDatasets published by VU Researchers can be found at the VU Research Portal.\n\n\n\nCitation Elements\nCiting data is not different from citing a journal publication. Similar to citing a journal publication, it helps to give and receive credit, and show the impact of the original source.\nMake sure to check the rules of the journal to know how you should cite when writing an article for a specific academic journal. For all of the journals, however, the minimum compulsory elements in a data citation include:\n\nAuthor(s): Name of the author (creator) of the dataset\nTitle: Name of the dataset\nDate of publication\nPublisher: Archive where dataset is stored\nPersistent Identifier: Unique identifier, most common is the DOI (see section Persistent Identifier).\n\nOptional elements that may be included in the reference are:\n\nFile Type: Codebook, movie, software\nVersion: Version number of the edition\nCreation Date\nDate of Consultation (last)\n\n\nExample data citation\nStephens, William, 2020, “Resiliences to Radicalisation - QSort Data”, https://doi.org/10.34894/35MTMN, DataverseNL, V1.\n\nFor more information, see the following guidelines:\n\nDataverse\nDataCite\nDCC UK\nData Citation Synthesis Group (2014). Joint Declaration of Data Citation Principles. Martone M. (ed.) San Diego CA: FORCE11\n\nRelevant is also the Citation File Format (CFF)."
  },
  {
    "objectID": "guides/publishing-fair-software.html",
    "href": "guides/publishing-fair-software.html",
    "title": "How can you publish FAIR software",
    "section": "",
    "text": "This document provides some pointers that can help to set you up with a coding repository that follows the FAIR guiding principles, meaning Findability, Accessibility, Interoperability, and Reuse of digital assets. It is not meant to be an exhaustive guide for every step, but rather acts as a starting point and links to more exhaustive sources."
  },
  {
    "objectID": "guides/publishing-fair-software.html#introduction",
    "href": "guides/publishing-fair-software.html#introduction",
    "title": "How can you publish FAIR software",
    "section": "",
    "text": "This document provides some pointers that can help to set you up with a coding repository that follows the FAIR guiding principles, meaning Findability, Accessibility, Interoperability, and Reuse of digital assets. It is not meant to be an exhaustive guide for every step, but rather acts as a starting point and links to more exhaustive sources."
  },
  {
    "objectID": "guides/publishing-fair-software.html#publishing-online",
    "href": "guides/publishing-fair-software.html#publishing-online",
    "title": "How can you publish FAIR software",
    "section": "Publishing online",
    "text": "Publishing online\nResearch code (or other code) is best stored on a git repostory, like GitHub or GitLab. Both platforms are is used by millions of programmers and researchers around the world. To upload your code to GitHub/GitLab, you first need to make an account here. Once you have an account, you can create a repository that hosts your code.\nGitHub: You can create a free account. In addition, as a university employee, you can use your university email address to get a free “Pro” account, which gives you access to some additional features. You can find more information at the GitHub Education platform. GitLab: As VU employee, you can access GitLab using your VU credentials (VUnetID) by logging in through the VU portal.\n\nCreating a repository\nGitHub: After logging in, click your profile picture on the top right -&gt; “Your repositories” -&gt; “New”. Choose a name and set the visibility (do you want everyone to see your code already or wait a bit before sharing with the world?). It is common practice to immediately add a “README” file and add a licence (see next section). You can update the visibility of your repository later under the repository settings.\nGitLab: After logging, click on “Projects” in the left menu, and then on “Create project”. Choose a name and set the visibility (do you want everyone to see your code already or wait a bit before sharing with the world?). It is common practice to immediately add a “README” file and add a licence (see next section). You can update the visibility of your repository later under the repository settings.\n\n\nAdding code to your repository\nGitHub: You can create a new file using the “Add file” or “+”-button.\nGitLab: You can create a new file using the “+”-button and click “New file”.\nOnce you have uploaded your files or written your code, you need to write a “commit” message. This is basically a description of the changes you made between the previous version of the code and the current version. Since this is the first version of the files (that is available online) you can write something like “initial”.\nNote: never put sentitive information (like passwords or API keys) in your code.\n\n\nUsing Git locally\nWhen you plan to use GitHub/GitLab more often, adding files through the web interface can become cumbersome. In that case, it is useful to consider using GitHub Desktop or a git manager which is integrated in your IDE (integrated development environment), like Visual Studio Code. Git can also be used on the command line, for example, when using git from a server. The course Learn Git & GitHub provides a useful tutorial on using git from the command line.\nWell done! Your research code is not sitting on your own computer (or worse – deleted after publication*), but is available online for others to find. This is step one in following the FAIR principles. In the remainder of this guide, you will find steps that will guide you through all steps to release a “perfect” code repository. The first sections are most important, further sections provide room for further improvement, so please use this guide at your own discretion.\n*VU Amsterdam requires research data and software to be preserved for at least 10 years, unless legal provisions or discipline-specific guidelines dictate otherwise, as per the Research Data and Software Management Policy. Note that funding organisations may have specific requirements for preserving code as well. If you receive external funding for your research, please make sure to familiarise yourself with such requirements."
  },
  {
    "objectID": "guides/publishing-fair-software.html#licence",
    "href": "guides/publishing-fair-software.html#licence",
    "title": "How can you publish FAIR software",
    "section": "Licence",
    "text": "Licence\n\nLicensing software\nPublishing research software under an appropriate licence is crucial for its accessibility, usability, and further integration into research. Choosing a licence usually happens right when you start developing the software or when you put it in a public repository, rather than when the software is finished and fully baked.\nA software licence states how other people may re-use your code and under which circumstances. For research software, it is recommended (and often required by funders) that licences are as permissible as possible.\nThere are many licences out there; below we list some very frequently used licences in research software. However, if none of these licences fit your case, there are several tools that can help you to choose a suitable software licence. If you need guidance in choosing a licence for your software, get in touch with the RDM Support Desk.\n\n\nMIT License\nThe MIT License is a popular choice, due to its readability and permissiveness. It allows users to reuse the software for any purpose, including using, copying, modifying, and distributing it, provided they include the original copyright notice and licence text.\nHowever, its permissiveness means that derivative works can be closed-source and do not need to mention that they use your code, which might not align with all scientific openness goals or general.\n\n\nGNU GPLv3\nThe GNU General Public License (GPLv3) is another option, designed to ensure that the software and any derivatives remain open-source.\nThis encourages collaborative improvement of software. Any software that includes GPL-licensed code must also be open-source under the GPLpotentially deterring commercial use or integration with proprietary software. In conclusion, when you want your code to be used by others, but only the code that uses your code is also open source, this is the way to go.\n\n\nApache License 2.0\nThe Apache License 2.0 allows for modification and distribution of the software and its derivative works, with the requirement that changes to the original code are documented.\nIt is a more complex licence than the MIT License and can be incompatible with GPL-licensed software. The specifics of this go beyond the scope of the handbook.\n\n\nAdding a licence to GitHub\nOn GitHub you add a licence on creating a new repository, by selecting the licence from the drop-down menu. If your repository already exists, add a new file called “LICENSE” using the “+”-button on top of the repository (see below).\n\n\n\nLocation of file creation button\n\n\nOne the next page, start to type LICENSE as the file name, and a button to “Choose a license template” should automatically pop up. Follow the steps provided by GitHub to finish adding the licence to the repository.\nYou should now see your licence shown on the main page of your repository.\n\n\nFurther considerations\n\nIf you are reusing software or libraries written by someone else, you must stick to the clauses of the licence given to the original software/library;\nWhen choosing a licence, do not just think about what others may do with the software, but also what you might want to do with the software in the future."
  },
  {
    "objectID": "guides/publishing-fair-software.html#persistent-identifier",
    "href": "guides/publishing-fair-software.html#persistent-identifier",
    "title": "How can you publish FAIR software",
    "section": "Persistent Identifier",
    "text": "Persistent Identifier\nA persistent identifier is a durable reference to a digital dataset, document, website or other object. A Digital Object Identifier (DOI) is a widely used Persistent Identifier in the research domain and hence for research software as well. There are two ways to generate a DOI for your code. Depending on how often you intend to update your code, one or the other may be simpler.\n\nIf you do not intend to update your code often, it is sufficient to upload your code separately to Zenodo (or similar repository). This will then automatically generate a DOI for you, which can be included in a publication.\nIf however, you intend to update your code frequently, it may be easier to set up an automatic link between GitHub and Zenodo, so that a new version of the code is released on Zenodo on publication of a new version on GitHub. You can find instructions for this in this guide on referencing and citing content."
  },
  {
    "objectID": "guides/publishing-fair-software.html#readme-commenting-code-formatting",
    "href": "guides/publishing-fair-software.html#readme-commenting-code-formatting",
    "title": "How can you publish FAIR software",
    "section": "Readme, commenting, code formatting",
    "text": "Readme, commenting, code formatting\nTo allow others to understand and use your code effectively it is important to include a “README” file, and to comment your code.\n\nReadme file\nThe README file is the general introduction to a code repository. A good readme includes the following components (but may include other sections depending on the project):\n\nProject Title\nProject description\nInstallation Instructions: Provide step-by-step guidelines to get the project running.\nUsage Examples: Include examples of how to use the code, which can be particularly beneficial for libraries or APIs.\nDependencies: List any libraries or other software required to run the project.\nLicense: Specify the licensing under which the code is released (see above).\nCitation: Collect more citations 😉 by providing researchers a way to easily cite your paper.\n[if applicable] Contributing Guidelines: Explain how others can contribute to the project.\n\nOn GitHub, the README file should ideally be named “README.md”. GitHub automatically renders this file and displays it on the home page of your repository. You can find an example of a README file in the numpy repository.\n\n\nCode commenting\nCode commenting serves several essential purposes, such as enhancing readability, maintainability, and usability for original authors, future contributors and others interested in your code. Comments provide context or explanations for complex logic, variables, and algorithms, making the codebase accessible and understandable. Good practices include describing the purpose of functions, explaining the rationale behind decisions, and highlighting potential side effects.\nA huge part of commenting your code is variable naming. Good variable naming can go a long way in making your code “self-documenting”. In general, do not use abbreviations or very short variable names. This may save a couple of keystrokes when writing your code, but this time is easily recovered when looking at the code again months later. Good variable naming will help your colleagues or other interested people even more. Modern integrated development environments also usually include autocompletion.\n\n\nCode formatting\nConsistency in code formatting, and adherence to standards can be highly beneficial, allowing other people and yourself to more quickly grasp your code. Each language has different conventions. For example, Python uses PEP8, for which some examples are given below:\n\nUse 4 spaces as indentation\nlocal variable_names are all lowercase\nClassNames have each word starting with a Capital letter\nGLOBAL_VARIABLES are all uppercase\n\nOther examples are Google’s R Style Guide and Google’s C++ Style Guide.\n\n\nCode formatting tools\nYou can also configure Visual Studio Code to automatically help you formatting your code. You can find more information in the Visual Studio code formatting manual. Even more strict formatting can be done with ruff, which is PEP8-compliant but introduces additional rules. ruff can also format your code in place, running ruff format {source_file_or_directory}.\nYou can also use GitHub Actions to automatically check and format your code when you push new commits to your repository. For example for Python, ruff publishes GitHub actions that can be used to automatically check and format your code.\nIf you follow the steps above, your code is now following the FAIR principles already! However, there is always room for improvement. Further steps are explained below."
  },
  {
    "objectID": "guides/publishing-fair-software.html#documentation",
    "href": "guides/publishing-fair-software.html#documentation",
    "title": "How can you publish FAIR software",
    "section": "Documentation",
    "text": "Documentation\nExtensive documentation can help users of your code re-use your code effectively. There are some great tools out there to help you automatically build documentation from your code comments, which can be supplemented with general documentation. Sphinx is a great way to do this, and can be nicely integrated with your existing GitHub repository. An example of code documentation can be found in the ReadTheDocs documentation, which uses Sphinx. This guide is not meant to be a full guide on how to use Sphinx as many useful resources can be found on the internet. An example of a great resource is this blog post.\n\nInstalling Sphinx\nTo use Sphinx for automatic documentation generation in a GitHub repository, start by installing Sphinx using pip (pip install sphinx). Next, run sphinx-quickstart in your project’s root directory to generate the basic configuration (conf.py) and structure for your documentation.\n\n\nAutomatic documentation building\nDocumentation can be automatically updated when you push new commits to your GitHub repository. To do so, you can set up a continuous integration (CI) workflow using GitHub Actions. In a workflow file, you specify the steps to install Sphinx, build the documentation using the sphinx-build command, and then push the generated HTML files to the gh-pages branch or another branch designated for hosting your documentation. A guide on how to set this up can be found in this Sphinx manual.\nThis guide is not meant to be a full guide on how to use Sphinx, as many useful resources can be found on the internet. However, some useful resources (here, and here) are listed, and pointers are given.\n\n\nAutomatically documenting your code\nTo document a Python function using autodoc, ensure that the functions in your code have a properly formatted docstring. For example:\ndef add_numbers(a, b):\n    \"\"\"\n    Adds two numbers together.\n\n    :param a: first number\n    :type a: int or float\n    :param b: second number\n    :type b: int or float\n    :return: The sum of `a` and `b`\n    :rtype: int or float\n    \"\"\"\n    return a + b\nIn the conf.py file, enable the autodoc extension by adding 'sphinx.ext.autodoc' to the extensions list. This extension allows Sphinx to generate documentation directly from your source code’s docstrings. Then, in your Sphinx documentation source directory (usually docs/source), create a .rst file where you want this function’s documentation to appear. Use the autofunction directive to automatically include the function’s documentation:\n.. autofunction:: path.to.module.add_numbers\nReplace path.to.module with the actual Python import path to your function. Sphinx will extract the docstring from the function and incorporate it into the generated documentation, complete with the parameter descriptions and types."
  },
  {
    "objectID": "guides/publishing-fair-software.html#released-as-a-package",
    "href": "guides/publishing-fair-software.html#released-as-a-package",
    "title": "How can you publish FAIR software",
    "section": "Released as a package",
    "text": "Released as a package\nCreating a Python package allows you to share your code with a broader audience, promoting collaboration, and ensuring reproducibility. There are two “levels” of publishing your code. First of all, you can ensure that your code is directly installable from the GitHub repository. To do so, you can follow the steps explained in this Python tutorial, but only up to and including the section “Configuring metadata”. Here, we assume you already created a README.md and added a LICENCE as explained above.\nIn brief, you need to take the following steps, which are explained in full below:\n\nStructure your code as a package\nCreate a metadata file\n\nThen, once this is added to GitHub, you can install the package using the following command (of course adjusted to point to your own repository):\npip install git+https://github.com/your_username/your_repository.git\n\nPyPi\nIf this works, you can go on to the next step and publish your package on PyPi. When your package is published here, it is possible to directly install your code from pip, as such:\npip install your_package\nFor a full explanation of how to do so, follow the remaining steps explained in this Python tutorial.\n\n\nAutomatic publishing versions\nIf you publish new versions frequently, it may be useful to automatically release these versions to PyPi, directly from GitHub without taking manual steps. To do so, you can follow the guide in this repository on PyPI publish GitHub Action."
  },
  {
    "objectID": "guides/publishing-fair-software.html#testing",
    "href": "guides/publishing-fair-software.html#testing",
    "title": "How can you publish FAIR software",
    "section": "Testing",
    "text": "Testing\nTesting your code is a crucial aspect of software development, ensuring that your application behaves as expected and maintains a high level of quality. You can usually catch bugs much earlier, although it also requires some investment, especially in the beginning. Apart from catching bugs, testing can also focus on syntax use.\n\nCode testing\nOne of the most frequently used Python packages for software testing is pytest. Here are some quick steps to set up pytest in your repository:\n\nPython\n\nInstall pytest:\npip install pytest\nCreate a tests directory in your repository’s main folder.\nAssuming you have a function called add_one in the file my_package/math_functions.py, you can start by creating a test file within the tests directory to test this function:\n# my_package/math_functions.py\ndef add_one(x):\n    return x + 1\nCreate a test file named test_math_functions.py inside the tests directory. This file will contain the tests for your add_one function:\n# tests/test_math_functions.py\nfrom my_package.math_functions import add_one\n\ndef test_add_one():\n    assert add_one(1) == 2\n    assert add_one(0) == 1\n    assert add_one(-1) == 0\n    assert add_one(100) == 101\nRun the tests by executing pytest from the command line. Navigate to your project’s root directory and run:\npytest\n\n\n\nR\nFor R, the most frequently used package for software testing is testthat, more information can be found in the testthat repository.\n\n\nC++\nFor C++, there are a lot of different testing frameworks available, but one of the most frequently used are Catch2 and Google Test.\n\n\n\nTesting tools\n\nThe Visual Studio Code Python extension has really good support for testing, saving you lots of time.\nOn GitHub, you can use GitHub Actions to automatically run your tests when you push new commits to your repository. For example for Python, pytest publishes GitHub actions that can be used to automatically run your tests."
  },
  {
    "objectID": "guides/publishing-fair-software.html#updating",
    "href": "guides/publishing-fair-software.html#updating",
    "title": "How can you publish FAIR software",
    "section": "Updating",
    "text": "Updating\nRegularly updating your repository and engaging with users can help build a community around your software. For example, users can report bugs to your repository or even contribute to new features (or fix those bugs).\n\nGitHub Issues\nGitHub Issues is a feature that allows project maintainers and contributors to track tasks, enhancements, and bugs for their projects. It can be found by clicking on “Issues” for most repositories (unless explicitly disabled). For example, issues can be used to:\n\nReport Bugs: Users and developers can report bugs they encounter, including descriptions, steps to reproduce, and screenshots.\nRequest Features: Suggestions for new features or improvements can be tracked as issues, allowing maintainers to prioritize and discuss them."
  },
  {
    "objectID": "guides/publishing-fair-software.html#publication",
    "href": "guides/publishing-fair-software.html#publication",
    "title": "How can you publish FAIR software",
    "section": "Publication",
    "text": "Publication\nFinally, publishing your code alongside a scientific publication can help build trust in the software you developed. This can, of course, be done in a traditional journal alongside a journal article. However, in some cases, it may be useful to publish your code in a journal specifically focused on software development. Here, we recommend JOSS (Journal of Open Source Software).\nIncreasingly, traditional scientific publications also include a section that describes where the code can be found. This can be a DOI, a link to a GitHub repository, or a link to a Zenodo repository. This allows other researchers to reliably cite your software, which also improves the findability. An example of such a section can be found here:\nCode for data cleaning and analysis is provided as part of the replication package, written in R. The specific code that was used for this article is available at https://doi.org/10.xxxx/path/to/journal/archive, while further updates are released at https://github.com/repository/your_code."
  },
  {
    "objectID": "group-guidelines/UCDS.html",
    "href": "group-guidelines/UCDS.html",
    "title": "User-centric Data Science (UCDS)",
    "section": "",
    "text": "The UCDS is a good group!\nShuai Wang is the RDM contact person."
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News",
    "section": "",
    "text": "Shuai Wang and colleagues won the Open Science Community Amsterdam Award (OSCA)!\n\n\n\n\n\n\n\n\n\n\n\nJun 4, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "group-guidelines.html",
    "href": "group-guidelines.html",
    "title": "Group-specific Guidelines",
    "section": "",
    "text": "What is this page about?\n\n\n\nThe CS department is one of the largest departments of the VU featuring research of all kinds. Here you can find group-specific guidelines that the dept. data stewards wrote in collabration with the RDM contact person of each group.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUser-centric Data Science (UCDS)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "topics.html",
    "href": "topics.html",
    "title": "Topics",
    "section": "",
    "text": "What is a topic?\n\n\n\nA topic is a specific subject that can be helpful to know about in your daily research. Each page can be read on its own. These pages are a quick way to learn about specific things.\nMissing a topic? You can submit suggestion using the Contribution portal.\n\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\nADA HPC\n\n\n4 min\n\n\n\n\nAcademic Integrity\n\n\n3 min\n\n\n\n\nCitation File Format (CFF)\n\n\n1 min\n\n\n\n\nData Archiving\n\n\n2 min\n\n\n\n\nData Backup\n\n\n2 min\n\n\n\n\nData Citation\n\n\n1 min\n\n\n\n\nData Collection\n\n\n6 min\n\n\n\n\nData Documentation\n\n\n3 min\n\n\n\n\nData Licensing\n\n\n3 min\n\n\n\n\nData Management Plan (DMP)\n\n\n11 min\n\n\n\n\nData Management Section\n\n\n1 min\n\n\n\n\nData Protection\n\n\n5 min\n\n\n\n\nData Publishing\n\n\n4 min\n\n\n\n\nData Storage\n\n\n5 min\n\n\n\n\nDataset and Software Registration in PURE\n\n\n3 min\n\n\n\n\nEthical Review\n\n\n1 min\n\n\n\n\nFAIR Principles\n\n\n4 min\n\n\n\n\nFinding Existing Data\n\n\n5 min\n\n\n\n\nFinding Existing Research Software\n\n\n4 min\n\n\n\n\nGeneral Data Protection Regulation\n\n\n3 min\n\n\n\n\nMetadata\n\n\n4 min\n\n\n\n\nOpen Science\n\n\n2 min\n\n\n\n\nPersistent Identifier\n\n\n3 min\n\n\n\n\nQualtrics\n\n\n5 min\n\n\n\n\nResearch Data Management (RDM)\n\n\n1 min\n\n\n\n\nResearch Data and Software Management Policy\n\n\n2 min\n\n\n\n\nResearch Drive\n\n\n4 min\n\n\n\n\nResearch Software\n\n\n2 min\n\n\n\n\nSURF Research Cloud\n\n\n3 min\n\n\n\n\nSafe Data Transportation and Transfer\n\n\n4 min\n\n\n\n\nSciCloud\n\n\n3 min\n\n\n\n\nSciStor\n\n\n7 min\n\n\n\n\nSnellius\n\n\n3 min\n\n\n\n\nSoftware Licensing\n\n\n3 min\n\n\n\n\nStoring vs. Archiving Data\n\n\n5 min\n\n\n\n\nTrainings\n\n\n7 min\n\n\n\n\nVU Compute Hub\n\n\n2 min\n\n\n\n\nYoda\n\n\n5 min\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The Open Handbook is a project started by Research Data Support in early 2024. After planning and design phases, we launched the initial version of the resource at the Research Support Days in May 2024.\nThe Open Handbook centralizes resources that VU researchers need to do their work. The Open Handbook also provides everyone with direct guides to change resources in case anything has become outdated.\nPreviously such resources were spread out across many different pages at VU and were hard to update. The Open Handbook is curated by us all, and reviewed by specialists. This way we can help each other.\n\n\nThe Open Handbook was initiated by Lena Karvovskaya, Jessica Hrudey, Elisa, and Jolien Scholten. The initial infrastructure for the Open Handbook was built by Liberate Science. Guide images are by Bres and Bittner (2024).\nWe want to specifically call out the following folk who contributed outside of GitHub:\n\nDiogenes Cruz de Arcelino\nJochem Lybaart\nJochem Nijs\nRebecca Silva dos Santos\n\n\n\n\n\n\nAll contributions to this project are gratefully acknowledged using the allcontributors package following the allcontributors specification. Contributions of any kind are welcome!\n\n\n\n   Alex-van-der-Jagt\n\n\n   chartgerink\n\n\n   Dimitri-Unger\n\n\n   Elisa-on-GitHub\n\n\n   imartorelli\n\n\n   jensdebruijn\n\n\n   jhrudey\n\n\n\n\n   Jolien-S\n\n\n   Karvovskaya\n\n\n   KirianneG\n\n\n   meronvermaas\n\n\n   peer35\n\n\n   Sergi095\n\n\n   TMHofstra\n\n\n\n\n   vansteph\n\n\n   ELNijland\n\n\n   gus-mxx\n\n\n   emilybarabas-vu\n\n\n   timveken\n\n\n   reinout538\n\n\n   MarcelRas-391\n\n\n\n\n   CMOGUZ\n\n\n   tmunker\n\n\n   Kostusas"
  },
  {
    "objectID": "about.html#contributors",
    "href": "about.html#contributors",
    "title": "About",
    "section": "",
    "text": "The Open Handbook was initiated by Lena Karvovskaya, Jessica Hrudey, Elisa, and Jolien Scholten. The initial infrastructure for the Open Handbook was built by Liberate Science. Guide images are by Bres and Bittner (2024).\nWe want to specifically call out the following folk who contributed outside of GitHub:\n\nDiogenes Cruz de Arcelino\nJochem Lybaart\nJochem Nijs\nRebecca Silva dos Santos\n\n\n\n\n\n\nAll contributions to this project are gratefully acknowledged using the allcontributors package following the allcontributors specification. Contributions of any kind are welcome!\n\n\n\n   Alex-van-der-Jagt\n\n\n   chartgerink\n\n\n   Dimitri-Unger\n\n\n   Elisa-on-GitHub\n\n\n   imartorelli\n\n\n   jensdebruijn\n\n\n   jhrudey\n\n\n\n\n   Jolien-S\n\n\n   Karvovskaya\n\n\n   KirianneG\n\n\n   meronvermaas\n\n\n   peer35\n\n\n   Sergi095\n\n\n   TMHofstra\n\n\n\n\n   vansteph\n\n\n   ELNijland\n\n\n   gus-mxx\n\n\n   emilybarabas-vu\n\n\n   timveken\n\n\n   reinout538\n\n\n   MarcelRas-391\n\n\n\n\n   CMOGUZ\n\n\n   tmunker\n\n\n   Kostusas"
  },
  {
    "objectID": "downloads.html",
    "href": "downloads.html",
    "title": "Downloads",
    "section": "",
    "text": "Files to download for your research.\n\n\n\nOn this page you can find documents, templates and examples while writing your research proposals and doing your research.\nMissing a document? You can report the missing documents using the Contribution portal.\n\n\nVU’s DMP template (latest version) download\nInfomed Consent Form (template) download"
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html",
    "href": "guides/policies-supporting-vision-open-science.html",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "",
    "text": "Vrije Universiteit Amsterdam is strongly committed to the accessibility of research output, namely publications, data and software. They are important to the visibility, verifiability and reusability of research. To turn accessible research output into reality, VU Amsterdam has developed a Research Data and Software Management Policy. This policy is based on a set of VU-internal, national and international policies, principles and regulations. This guide provides references and short explanations of these documents."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#research-data-and-software-management-policy",
    "href": "guides/policies-supporting-vision-open-science.html#research-data-and-software-management-policy",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "Research Data and Software Management Policy",
    "text": "Research Data and Software Management Policy\nVU Amsterdam considers the careful handling of research data and software to be very important. The university has therefore formulated a Research Data and Software Management Policy which articulates how to handle research data and software. The policy lists the responsibilities regarding research data and software management for researchers, department heads, faculty boards and the university as a whole.\n\nVU Research Data and Software Management Policy (2024) in English and in Dutch\n\nSince the VU Amsterdam policy for Research Data and Software Management is formulated in general terms, faculties have worked out more detailed policies and guidelines for their own faculty. These faculty-specific guidelines can be found below.\n\nACTA RDM policy, Academisch Centrum Tandheelkunde Amsterdam (2020, in Dutch)\nBeta RDM policy, Faculty of Science (2022)\nFGB RDM policy, Faculty of Behavioural and Movement Sciences (2023)\nFGW RDM policy , Faculty of Humanities (2023)\nFRT RDM policy, Faculty of Religion and Theology (2024)\n🔒 FSW RDM policy, Faculty of Social Sciences (2023)\nRCH RDM policy, Faculty of Law (2021)\nSBE RDM policy, School of Business and Economics (2023)\n\nFor RDM policies and guidelines at Amsterdam UMC, location VUmc, please get in touch with Research Data Management Support at Amsterdam UMC.\nIf you have questions about the VU-central Research Data and Software Management Policy, please contact the RDM Support Desk."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#policy-classification-of-research-data",
    "href": "guides/policies-supporting-vision-open-science.html#policy-classification-of-research-data",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "Policy Classification of Research Data",
    "text": "Policy Classification of Research Data\nThe Policy Classification of Research Data addresses classification of research data in terms of availability, integrity and confidentiality, and how the classification process should be carried out. It is connected to the Research Data and Software Management Policy, because the latter states that data must be handled in a secure and reliable manner. The Research Data Classification Policy will determine what level of security measures are necessary to manage data securely."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#vu-strategy-2020-2025",
    "href": "guides/policies-supporting-vision-open-science.html#vu-strategy-2020-2025",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "VU Strategy 2020-2025",
    "text": "VU Strategy 2020-2025\nThe Research Data and Software Management Policy follows the VU Strategy, in which VU Amsterdam endorses Open Science and FAIR data (see Section 5.1). More information relating to the VU Strategy can be found on the Strategy page."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#netherlands-code-of-conduct-for-research-integrity",
    "href": "guides/policies-supporting-vision-open-science.html#netherlands-code-of-conduct-for-research-integrity",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "Netherlands Code of Conduct for Research Integrity",
    "text": "Netherlands Code of Conduct for Research Integrity\nDutch scientists are required to comply with the Netherlands Code of Conduct for Research Integrity. More information about this code of conduct and procedures for violations of academic integrity at VU Amsterdam is available on the VU page about Academic Integrity."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#fair-principles",
    "href": "guides/policies-supporting-vision-open-science.html#fair-principles",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "FAIR Principles",
    "text": "FAIR Principles\nThe aim of the FAIR Principles is to guide researchers to make their data Findable, Accessible, Interoperable and Reusable."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#research-assessment-criteria",
    "href": "guides/policies-supporting-vision-open-science.html#research-assessment-criteria",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "Research assessment criteria",
    "text": "Research assessment criteria\n\nStrategy Evaluation Protocol (SEP)\nIn the Netherlands, research institutes and departments are being evaluated by the Strategy Evaluation Protocol (SEP). One of the aspects that need to be addressed in every evaluation, is Open Science. The extent to which a research institute works openly, is evaluated based on:\n\nto which extent the research unit opens up its work to other researchers and societal stakeholders;\nwhether the research unit reuses data;\nhow it stores the research data according to the FAIR principles;\nhow it makes its research data, methods and materials available.\n\n\n\nSan Francisco Declaration on Research Assessment (DORA)\nThe San Francisco Declaration on Research Assessment (DORA) contains a list of recommendations to improve the way in which research output is assessed. What is relevant for the VU Research Data and Software Management Policy, is that DORA recommends to evaluate the value and impact of all research output, including research data and research software.\n\n\nCoalition for Advancing Research Assessment (CoARA)\nThe Coalition for Advancing Research Assessment (CoARA) states that all research output has to be included in research evaluations, including research data and research software. It also recommends to recognise and reward researchers who make their research output available to others at an early stage in their research, and to recognise and reward open collaboration."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#barcelona-declaration-on-open-research-information",
    "href": "guides/policies-supporting-vision-open-science.html#barcelona-declaration-on-open-research-information",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "Barcelona Declaration on Open Research Information",
    "text": "Barcelona Declaration on Open Research Information\nThe Barcelona Declaration on Open Research Information aims to transform the way research information is used and produced. The declaration strives to make openness of information about the conduct and communication of research the new norm."
  },
  {
    "objectID": "guides/policies-supporting-vision-open-science.html#legislation-and-regulations",
    "href": "guides/policies-supporting-vision-open-science.html#legislation-and-regulations",
    "title": "What policies and regulations support VU’s vision on Open Science?",
    "section": "Legislation and regulations",
    "text": "Legislation and regulations\nReseach activities must comply with all legislation and regulations where applicable, for example:\n\nGeneral Data Protection Regulation (GDPR) and Dutch Implementation Act for the GDPR (UAVG): This Regulation lays down rules relating to the protection of natural persons with regard to the processing of personal data. The UAVG contains describes implementation of the GDPR for the Netherlands. On the VU page Working with personal data, you can find more information about how VU Amsterdam protects personal data.\nMedical Research Involving Human Subjects Act (WMO): WMO is a legal framework for medical scientific research. Research is subject to the WMO if it (i) concerns medical scientific research and (ii) participants are subject to procedures or are required to follow rules of behaviour. If a study is subject to the WMO, it must undergo a review by an accredited Medical Research Ethics Committee (or the Central Committee on Research Involving Human Subjects). In the case of VU Amsterdam, such reviews need to be carried out by the METC Amterdam UMC. See also the page about Ethical Review.\nDutch Medical Treatment Contracts Act (in Dutch: Wet geneeskundige behandelingsovereenkomst, WGBO): The WGBO is a legal framework that regulates the relationship between patients and care providers and specifies the rights and duties of patients. You can read more about how the WGBO relates to the WMO on the website of the CCMO (Central Committee on Research Involving Human Subjects).\nCode of Conduct for Health Research: Code of Conduct provided by COREON (Committee on Regulation of Health Research), which contains a manual in Dutch for the responsible handling of (personal) data and human tissue in health research.\nExperiments on Animals Act: This legislation describes the purposes for which animal tests may be carried out. For more information about animal testing at VU Amsterdam, see the pages on the Animal Welfare Body of VU Amsterdam-VUmc and the Amsterdam Division for Laboratory Animal Sciences (ADLAS)."
  },
  {
    "objectID": "guides/collect-and-store.html",
    "href": "guides/collect-and-store.html",
    "title": "How can you ensure data protection and security during collection, storage, and transfer?",
    "section": "",
    "text": "Data collection may consist of the re-use of existing data and/or the generation of new data.\nFor data to be considered valid and reliable, data collection should occur consistently and systematically throughout the course of the research project. Within disciplines, there are established methodologies, procedures and techniques that help researchers ensure high quality of collected data. In general, important aspects of data collection include:\n\nStandardisation: codebooks & protocols\nStructure / organisation of the data\nData quality assurance methods\nDocumentation & metadata\nStorage & protection\n\nSystematic data collection is essential for ensuring the reproducibility of research. When data is collected in a consistent and organized manner, it improves the quality and reliability of the research, making the data easier to share and reproduce by others. High-quality data also contributes to making data FAIR (Findable, Accessible, Interoperable, and Reusable), as well-organized and well-documented data is more likely to be reused effectively. The principles of making data FAIR are discussed in detail under the topic FAIR Principles.\n\nData Collection Tools\nThe tools being used in research to collect data are immensely diverse. For that reason, we will not provide an exhaustive overview here. What is important for data collection tools in relation to RDM is where such tools store the data that you collect and in which format. The storage location is particularly important when you are working with personal data. For example, the privacy legislation in the United States is very different from the European General Data Protection Regulation (GDPR). Hence, personal data collected in a Dutch research institute may not be stored on American servers. It is important to keep that in mind when you are contemplating which tool to use for your data collection.\nIf you are collecting personal data and you decide to use a tool for which no contract exists between VU Amsterdam and the provider of the software or tool, a service agreement and a processing agreement must be drawn up. Contact the 🔒 privacy champion of your faculty for more information and a model processing agreement.\n\nQuestionnaire tools\nThe Faculty of Behavioural and Movement Sciences has developed a document with tips for safe use of the questionnaire tools Qualtrics and Survalyzer. The document was made for FGB researchers specifically but can also be helpful for others. Consult this document if you need a questionnaire tool to collect your data.\n\n\n\nData Collection in Collaboration\nSome research projects involve the participation of multiple organisations or institutes and may include even cross-border co-operation. When data is collected by several organisations, a Data Management Plan should provide information on who is responsible for which part of the data collection and storage. It should also provide information on how specific data collections are related to which part(s) of the research goal(s). Describing this precisely will help you to determine if a consortium agreement or joint controller agreement is necessary. You see a general example of such a specification in the table below:\n\n\n\n\n\n\n\n\n\n\nData Stage\nDataset description\nResponsible organization for collection\nData origin\nData purpose\n\n\n\n\nRaw data\nCommunity level surveys\nVU Amsterdam\nAmsterdam, The Hague, Rotterdam\nIdentifying perceived problems, System responsiveness\n\n\nRaw data\nTrials & Focus Group Interviews\nLondon School of Hygiene and Tropical Medicine (LSHTM)\nGermany, Switzerland\nTrials to evaluate programs on . . ., Focus Group interviews to identify barriers to . . .\n\n\nRaw data\nPollution measurements using fish\nOceanographic Institute of Sweden\nCoastal waters, Northeast Spain\nEstablish pollution levels of plastic\n\n\n\n\n\nData Collection Protocols\nRegardless of the field of study or preference for defining data (quantitative, qualitative), accurate data collection is essential to maintaining the integrity (structure) of research. Both the selection of appropriate data collection instruments (existing, modified, or newly developed) and clearly delineated instructions for their correct use reduce the likelihood of errors.\nThere are two approaches for reducing and/or detecting errors in data which can help to preserve the integrity of your data and ensure scientific validity. These are:\n\nQuality assurance - activities that take place before data collection begins\nQuality control - activities that take place during and after data collection\n\nQuality assurance precedes data collection and its main focus is ‘prevention’ (i.e., forestalling problems with data collection). Prevention is the most cost-effective activity to ensure the integrity of data collection. This proactive measure is best demonstrated by the standardization of protocol developed in a comprehensive and detailed procedures manual for data collection.\nWhile quality control activities (detection/monitoring and action) occur during and after data collection, the details should be carefully documented in the procedures manual. A clearly defined communication structure is a necessary pre-condition for monitoring and tracking down errors. Quality control also identifies the required responses, or ‘actions’ necessary to correct faulty data collection practices and also minimise future occurrences.\nSome sources for protocols:\n\nHANDS Handbook for Adequate Natural Data Stewardship by the Federation of Dutch University Medical Centers (UMCs)\nProtocols.io - an open access repository of protocols\nProtocols Online - website with protocols available on the internet, sorted by discipline.\nSpringer Protocols - free and subscribed protocols collected by Springer.\n\n\n\nStorage During Research\nVU Amsterdam offers several options to store your research data. The choice for a specific option may depend on factors such as:\n\nDoes a project involve multiple organisations or departments?\nThe sensitivity of the data: does it involve personal data or copyrighted / commercial data?\nAre there any research partners with whom data need to be shared?\nAre any commercial parties involved?\nDoes the research project involve multiple locations (inside or maybe even outside the EU)?\nWill there be (lab) devices producing data that need to be stored as well?\nWhat will be the volume of the data?\nWill there be lots of interactions with the data (using software/tools)?\n\nStorage options may take several forms, for example:\n\nLocal storage on computers, networks or servers;\nCloud storage offered by VU Amsterdam;\nLocations where physical data samples are stored (fridges, lockers, etc.).\n\nResearchers, including PhD candidates, have multiple options that can be used, some of which are listed below. More information about these storage options is available behind their respective links. The Storage finder is a tool that will give you a number of storage options suitable for your research. For more individual guidance, please get in touch with the Research Data Management Support Desk for advice, particularly when you are working with commercial, personal or otherwise sensitive data, or when you have a complex IT setup.\n\n\nStandard services offered by VU Amsterdam\nVU IT offers several services for employees to store their files. Examples are:\n\n🔒 OneDrive: personal storage for all VU employees and part of the Microsoft 365 platform. OneDrive allows you to store files locally and in the Microsoft cloud, and share folders and documents with colleagues. Since this is personal storage, tied to someone’s personal VU account, we don’t usually recommend storing research data in OneDrive: if the account holder leaves VU Amsterdam, the account and all the data on it, disappear.\n🔒 Teams. Faculties, divisions and departments have their own Team - part of the Microsoft 365 platform - where they store shared documents and where they can interact and chat. Projects may also request a project team. But note that Teams is not always the best location to store your research data and has several limitations, especially when it comes to working with non-Microsoft file formats, large volumes of data, interacting with data, and collaborating with partners outside of VU Amsterdam. Contact the RDM Support Desk to find out more about the suitability of Teams for your project.\n\n\n\nResearch data-specific storage options\nThe options above are standard data storage options at VU Amsterdam to which all employees have access. But VU Amsterdam also offers storage specifically for research data. Some of them are hosted locally at VU Amsterdam, while others are SURF cloud services. When selecting a cloud-based service it is important to remember to check where the data will be hosted. If the research project involves sensitive data it may be necessary to choose cloud-based options that guarantee that the data will stay in the EEA or on servers based in the EEA.\n\n🔒 SciStor (short for ‘Storage for Scientists’): This is storage hosted by IT for Research (ITvO) and allows for inexpensive storage of large volumes of data. There are various levels of security possible and various ways to get access to the files. SciStor is only intended for ongoing research, not for archiving.\nYoda (short for Your Data) is a cloud storage at SURF and is suitable for storing large-scale and sensitive datasets. Yoda also supports collaborating on projects in and outside VU Amsterdam and adding contextual information (metadata) about your dataset as you go. Yoda is usually the best choice if your research data are very sensitive.\n🔒 Research Drive is a cloud storage at SURF for research projects and is suitable for collaboration in and outside VU Amsterdam, for storing sensitive data and large-scale research projects. You are able to request storage space in Research Drive via a 🔒 web form in the selfservice portal (VU employees only). Research Drive is the best choice if you need to manage access rights on a folder level. SURF has general information about Research Drive, and you can find tutorials on the wiki pages.\n\nThere are differences between Research Drive and Yoda and each one may support certain projects better than others. The storage finder can help you to get an idea of what would be the best choice for your project, but get in touch with the RDM Support Desk for more details.\n\n\nSending research data to partners\nSome projects may require data sharing with partners. Although Research Drive and Yoda support sharing data all through the project, it may also be the case that some data only need to be sent to a partner once. There are some secure options to send data to research partners:\n\n🔒 Surf Filesender: cloud service that allows you to send files of 1 Terabyte to other researchers and encrypted files of up to 250 GB.\n🔒 Zivver: All employees of VU Amsterdam can use Zivver, the encryption programme that allows you to send email or data (sensitive or otherwise) securely by email. Attachments will also be encrypted and can be several Terabytes in size (max = 5 TB). Specific information on how to get and use Zivver are available on the selfservice portal. General explanations on how to use it are available at the Zivver website.\n\n\n\nWhat is Data Protection?\nProtection from what? From whom? When, and why? Before we talk about data protection, let us consider security first. More often than not, ‘security’ is regarded as a fixed state. In reality, security is an assessment of the level of protection against a certain threat, that you consider to deal with that threat adequately enough. Whether or not security is accurate depends on the value of the data and the quality of protective measures.\nThe question for you as a researcher is ‘when are the measures that you take secure enough?’. In order to answer this, please be aware that there are three entities that have an opinion about what is ‘secure enough’, namely: the law, the University, and you yourself as the data processor.\nThe University has a Security Baseline that sets a norm for levels of protection for every application it uses. The Baseline is based on international standards. For each of these applications, the University is considering for which means the security of these applications are adequate enough.\nThe legal requirements for the processing of personal data can be found in the section ‘GDPR and Privacy’ under Plan & Design There are additional laws and regulations as well. The assumption is that you are familiar with these, especially with laws regulating medical and criminal research.\nWhat you personally consider to be secure might be very different from what your colleagues, the Faculty or the University considers to be secure enough and the norms will vary with the variety of data that is being processed by different researchers and Faculties of VU Amsterdam. Very generally speaking, there are three points of protection to consider:\n\nProtection against data loss, for which you need a back up periodically.\nProtection against data leakage, for which you need to consider all storage places and their access points.\nProtection of data integrity, for which you need version control and synchronisation management.\n\nThe security of your protection measures depends on the threat you face. We often think of threats as active, and motivated by bad intentions. But most common forms of data loss are accidental and most leakage is caused by trusting others. In reality, devices just get lost or break down, people download malware by accident, and each one of us forgets to save a document at times or gets confused about which version was last updated.\nIn all cases, protection starts with oversight on where your data is stored and processed. If you forget that you temporarily stored it in a certain place, you have then lost oversight of where that data is. The opposite is also true: if you know where you data is, you have insight in the level of security of the space in which you store it. As you can see, protection begins with organising your work in a reliable manner and thinking through your steps.\nFor example, if you data is on your laptop and synchronised with your phone, then it is stored in two places. Perhaps this is enough back up, perhaps not. If you put both you devices in the same bag and you lose your bag, you have no backup. A backup to an online storage might be a good solution, but might also mean your data leaks via the internet of via the storage provider who sells the data and your behavioural data for profit. Most importantly, there is no absolute security. It is best if you consider your personal behaviour and then think of scenarios that are more or less likely to happen and what would impact you most. If you frequently work in public places you should make it a habit to lock your device each time you leave it. If you eat and drink behind your desk often, better work with a remote keyboard to protect your laptop from the unavoidable coffee shower. Do you save your respondents’ contact details on your personal phone? Then protect it with a pin.\nHere are some basic protection guidelines:\n\nData are very difficult to erase. You have probably never done it.\nDecide how to back up data and test it before you rely on it.\nDo not give others your log-in credentials. If you have done so and your family members use your work device, then change it.\nDo not use passwords twice, do not use your birthday, initials, streetname, hobby.\nEncryption sounds secure, but it fails completely without good password management.\n\n\n\nData Protection\nThere can be many reasons why the data of a project needs to be kept protected:\n\nSensitivity of the data collected\nProtection of the research data from competition\nCommercial reasons / Intellectual property\nEtc.\n\n\n\n\nAn image of a lock composed of code in a matrix green style.\n\n\nThere are also many levels of security that may be implemented, depending on the needs. Sometimes it will be enough to use a password-protected cloud-based server. In extreme cases encryption may be needed and also when data is transmitted between researchers or organisations. You should contact the RDM Support Desk to discuss available options, who may connect you to legal experts where sensitive data is concerned. Check the Data Storage topic for links to find out more on campus solutions and cloud-based options.\n\nSee also the Safe Data Transfer topic for more information on how to transport and transfer data.\n\nIt is important to protect your data during the entire data life cycle. To find out whether your data are secure during all stages of your research, think about your data flow: where do your data originate and where do they go to? If data need to be transported from one physical place to the other, or need to be transferred from one device to another, these actions should happen in a secure way.\n\nTransferring digital data\n\nOnline connection on campus\nIf data collection takes place through a certain measurement device (e.g. MRI scanner, EEG scanner, eye tracker), the data need to be transferred from the measurement device to the storage location that you will use during your research project. Make sure that this transfer takes place in a secure way and also make a plan for the data on the measurement device; find out whether they need to be destroyed or can remain there.\n\n\nOnline connection outside campus (with and without VUnetID)\nIf you are doing fieldwork outside the campus and you have reliable and secure internet access, it is a good idea to upload the data to a storage location that is regularly backed up and secure, in order to prevent data loss. If you have a VUnetID, you can for example use:\n\nResearch Drive to securely and easily store and share research data.\nSURFfilesender to send you data to a colleague or consortium partner, who can store your data in an appropriate place\n\nYou can find more information about each of these storage options in the Data Storage topic.\nIf you need to receive data from colleagues in your project who don’t have access to these tools (e.g. because they are students, don’t work for a Dutch educational institution, or have no VUnetID), Research Drive, Yoda, SURFfilesender and secure emailing with Zivver can also be used:\n\nResearch Drive: This cloud storage service provided by SURF enables researchers from VU and external researchers to manage files and folders in a shared storage location.\nSURFfilesender: as a SURFfilesender user, you can send a voucher to someone who doesn’t have access to this tool. This person can use this voucher to send documents to you. These files can be encrypted.\nYoda: This cloud storage service provided by SURF enables researchers from VU and external researchers to manage files and folders in a shared storage location.\n🔒 Zivver is an email plugin with which you can encrypt emails and attachments.\n\n\n\nOffline data outside campus\nIf you are doing fieldwork in an area with limited internet access, you might use a portable device to initially store your data during the phase of data collection, such as a USB drive or an external hard drive. These data can be transferred to a storage location that is connected to the internet (e.g. Research Drive, Yoda) later. Please make sure that the data on such portable devices are secured, by using encryption (and by transporting them safely by using a lockable briefcase or backpack).\n\n\n\nTransporting physical data\nIf physical objects need to be transported, you should check with the data manager at your department (if available) what options are available. Special briefcases that can be locked or secure backpacks may need to be used to keep informed consent forms or other sensitive data objects (USB drives etc.) secure during transport. A checklist may help to ensure all objects will be taken along.\n\n\nData transportation and transfer across borders\nSome countries have rules to control the movement of encryption technology that enter or exit their borders. If you need to travel with an encrypted laptop to secure your data, for example during fieldwork abroad, please keep this in mind. If you need to transfer data in and out of such countries, please get advice on encryption and secure transportation at the IT Service Desk.\n\n\nSupport\nIf you have general questions about how to protect your data when transporting or transferring them, you can contact the IT Service Desk. In case of complex situations for which you need tailored support, you can consult the IT Relationship Manager representing the research domain, who can request capacity at IT for setting up an information security plan. Such a plan is usually based on documents which need to be completed beforehand, like a Data Protection Impact Assessment and a Data Classification."
  },
  {
    "objectID": "guides/document-and-preserve.html",
    "href": "guides/document-and-preserve.html",
    "title": "How can you ensure research data is FAIR?",
    "section": "",
    "text": "There is a difference between storing and archiving data. Storing refers to putting the data in a safe location while the research is ongoing. Because you are still working on the data, the data still change from time to time: they are cleaned, and analysed, and this analysis generates output. As the image below illustrates, storing could be like cooking a dish: you are cleaning and combining ingredients.\nArchiving, on the other hand, refers to putting the data in a safe place after the research is finished. The data are in a fixed state, they don’t change anymore. Archiving is done for verification purposes: so others can check that your research is sound. Or: it is done so that others can reuse the resulting dataset. There is also a difference between archiving and publishing, but in essence, archiving and publishing happen at a similar moment and for both, data do not change anymore.\n\n\n\nA Scriberia illustration showing storage on the left, in a kitchen space with storage making things available, and archiving on the right, in a museum where it is available for viewing.\n\n\nThis illustration is created by Scriberia with The Turing Way community. Used under a CC-BY 4.0 licence. DOI: 10.5281/zenodo.3332807\n\nSelecting Data for Archiving\nThere are various reasons to archive your data: replication, longitudinal research, data being unique or expensive to collect, re-usability and acceleration of research inside or outside your own discipline. It is VU policy to archive your data for (at least) 10 years after the last publication based on the dataset. Part of preparing your dataset for archiving is appraising and selecting your data.\n\nMake a selection before archiving your data\nDuring your research you may accumulate a lot of data, some of which will be eligible for archiving. It is impossible to preserve all data infinitely. Archiving all digital data leads to high costs for storage itself and for maintaining and managing this ever-growing volume of data and their metadata; it may also lead to decline in discoverability (see the website of the Digital Curation Centre). For those reasons, it is crucial that you make a selection.\n\n\nRemove redundant and sensitive data\nSelecting data means making choices about what to keep for the long term, and what data to archive securely and what data to publish openly. This means that you have to decide whether your dataset contains data that need to be removed or separated. Reasons to exclude data from publishing include (but are not limited to):\n\ndata are redundant\ndata concern temporary byproducts which are irrelevant for future use\ndata contain material that is sensitive, for example personal data in the sense of the GDPR, like consent forms, voice recordings, DNA data; state secrets; data that are sensitive to competition in a commercial sense. These data need to be separated from other data and archived securely\npreserving data for the long term is in breach of contractual arrangements with your consortium partners or other parties involved\n\nIn preparing your dataset for archiving, the first step is to determine which parts of your data are sensitive, which can then be separated from the other data. Redundant data can be removed altogether.\n\n\nDifferent forms of datasets for different purposes\nOnce you have separated the sensitive data from the rest of your dataset, you have to think about what to do with these sensitive materials. In some cases they may be destroyed, but you may also opt for archiving multiple datasets. For example, you may want to archive your dataset in more than one form depending on the purpose. For example:\n\nOne for reusability to share\nA second one that contains the sensitive data, and needs to be handled differently.\n\nFor the first, the non-sensitive data can be stored in an archive under restricted or open access conditions, so that you can share it and link it to publications. For the second, you need to make a separate selection, so the sensitive part can be stored safely in a secure archive (a so-called offline or dark archive). In the metadata of both archives you can create stable links between the two datasets using persistent identifiers.\n\n\nWhat to appraise for archiving\nThere are several factors that determine what data to select for archiving. For example, whether data are unique, expensive to reproduce, or if your funder requires that you make your data publicly available. This might also help you or your department to think about a standard policy or procedures for what needs to be kept, what is vital for reproducing research or reuse in future research projects.\nMore information on selecting data:\n\nTjalsma, H. & Rombouts, J. (2011). Selection of research data: Guidelines for appraising and selecting research data. Data Archiving and Networked Services (DANS).\nDigital Curation Centre (DCC): Whyte, A. & Wilson, A. (2010). How to appraise and select research data for curation. DCC How-to Guides. Edinburgh: Digital Curation Centre.\nResearch Data Netherlands: Data selection.\n\n\n\n\nData Set Packaging: Which Files should be Part of my Dataset?\nA dataset consists of the following documents:\n\nRaw or cleaned data (if the cleaned data has been archived, the provenance documentation is also required)\nProject documentation\nCodebook or protocol\nLogbook or lab journal (when available, dependent on the discipline)\nSoftware (& version) needed to open the files when no preferred formats for the data can be provided\n\nSee the topic Metadata for more information about documenting your data.\nDepending on the research project it may be that more than one dataset is stored in more than one repository. Make sure that each consortium partner that collects data also stores all necessary data that is required for transparency and verification. A Consortium Agreement and Data Management Plan will include information on who is responsible for archiving the data.\nBy creating documentation about your research data you can make it easier for yourself or for others to manage, find, assess and use your data. The process of documenting means to describe your data and the methods by which they were collected, processed and analysed. The documentation or descriptions are also referred to as metadata, i.e. data about data. These metadata can take various forms and can describe data on different levels.\nAn example that is frequently used to illustrate the importance of metadata is the use of the label on a can of soup. The label tells you what kind of soup the can contains, what ingredients are used, who made it, when it expires and how you should prepare the soup for consumption.\nWhen you are documenting data, you should take into account that there are different kinds of metadata and that these metadata are governed by various standards. These include, but are not limited to:\n\nFAIR data principles: a set of principles to make data Findable, Accessible, Interoperable and Reusable.\nGuidelines for unstructured metadata: mostly research domain-specific guidelines on how to create READMEs or Codebooks to describe data.\nStandards for structured metadata: generic or research domain-specific standards to describe data.\n\nThe CESSDA has made very detailed guidance available for creating documentation and metadata for your data.\n\n\n\nA layered diagram with the FAIR principles as the outermost layer, followed by an inner layer for Metadata. Within Metadata there are two separate cores, one for unstructured and one for structured metadata. Unstructured metadata contains README and codebook; Structured metadata contains Generic and Specific.\n\n\n\n\nFAIR data principles\nThe FAIR data principles provide guidelines to improve the Findability, Accessibility, Interoperability, and Reuse of digital assets. The principles emphasise machine-actionability, i.e., the capacity of computational systems to find, access, interoperate, and reuse data with none or minimal human intervention.\nMore information can be found in the section about the FAIR data principles.\n\n\nUnstructured metadata\nMost data documentation is an example of unstructured metadata. Unstructured metadata are mainly intended to provide more detailed information about the data and is primarily readable for humans. The type of research and the nature of the data influence what kind of unstructured metadata is necessary. Unstructured metadata are attached to the data in a file. The format of the file is chosen by the researcher. More explanation about structured metadata can be found on the metadata page.\n\nREADME\nA README file provides information about data and is intended to ensure that data can be correctly interpreted, by yourself or by others. A README file is required whenever you are archiving or publishing data.\nExample of READMEs\n\nGuidelines for creating a README file – 4TU.ResearchData\nGuide to writing “readme”-style metatada - Cornell Data Services\nGuidelines for researchers of VU Amsterdam Faculty of Behavioural and Movement Sciences on what a README file should contain\n\n\n\nCodebook\nA Codebook is another way to describe the contents, structure and layout of the data. A well documented codebook is intended to be complete and self-explanatory and contains information about each variable in a data file. A codebook must be submitted along with the data.\nThere are several guides for creating a codebook available:\n\nCreating a codebook - Kent State University\nCreating a codebook - for researchers at VU Amsterdam Faculty for Behavioural and Movement Sciences\nCodebook - Amsterdam Public Health\nDDI-Codebook - Data Documentation Initiative Alliance\n\nMetadata provide information about your data. Structured metadata are intended to provide this information in a standardised way. The structured metadata are readable for both humans and machines. It can be used by data catalogues, for example DataCite Commons.\nThe standardisation of metadata involves the following aspects:\n\nElements: rules about the fields that must be used to describe an object, for example the title, author and publicationDate.\nValues: rules about the values that must be used within specific elements. Controlled vocabularies, classifications and Persistent Identifiers are used to reduce ambiguity and ensure consistency, for example by using a term from a controlled vocabulary like the Medical Subject HEadings (MeSH) as a subject and an Persistent Identifier such as an ORCID to identify a person.\nFormats: rules about the formats used to exchange metadata, for example JSON or XML.\n\n\n\n\nMetadata standards\nMetadata standards allow for easier exchange of metadata and harvesting of the metadata by search engines. Many certified archives use a metadata standard for the descriptions. If you choose a data repository or registry, you should find out which metadata standard they use. At VU Amsterdam the following standards are used:\n\nYoda uses the DataCite metadata standard\nDataverseNL uses the Dublin Core metadata standard\nVU Amsterdam Research Information System PURE uses the CERIF metadata standard\n\nMany archives implement or make use of specific metadata standards. The UK Digital Curation Centre (DCC) provides an overview of metadata standards for different disciplines. The list is a great and useful resource in establishing and carrying out your research methodology.\n\n\nControlled Vocabularies & Classifications\nControlled vocabularies are lists of terms created by domain experts to refer to a specific phenomenon or event. Controlled vocabularies are intended to reduce ambiguity that is inherent in normal human languages where the same concept can be given different names and to ensure consistency. Controlled vocabularies are used in subject indexing schemes, subject headings, thesauri, taxonomies and other knowledge organisation systems. Some vocabularies are very internationally accepted and standardised and may even become an ISO standard or a regional standard/classification. Controlled vocabularies can be broad in scope or very limited to a specific field. When a Data Management Plan template includes a question on the used ontology (if any), what is usually meant is: is there a specific vocabulary or classification system used? The National Bioinformatics Infrastructure Sweden gives some more explanation about controlled vocabularies and ontologies here. In short, an ontology does not only describe terms, but also indicates relationships between these terms.\nExamples of controlled vocabularies are:\n\nCDWA (Categories for the Description of Works of Art)\nGetty Thesaurus of Geographic names\nNUTS (Nomenclature of territorial units for statistics)\nMedical Subject HEadings (MeSH)\nThe Environment Ontology (EnvO)\n\nMany examples of vocabularies and classification systems can be found at the FAIRsharing.org website. It has a large list for multiple disciplines. If you are working on new concepts or new ideas and are using or creating your own ontology/terminology, be sure to include them as part of the metadata documentation in your dataset (for example as part of your codebook).\n\n\nMetadata levels\nFinally a distinction can be made on the level of description. Metadata can be about the data as a whole or about part of the data. It can depend on the research domain and the tools that are used on how many levels the data can be described. In repositories like Yoda and DataverseNL it is common practice to only create structured metadata on the level of the data as a whole. The Consortium of European Social Science Data Archives (CESSDA) explains this distinction for several types of data in their Data Management Expert Guide.\n\n\n\nFlowchart indicating a project with a Folder a and Folder b, where Folder a has File 1 and File 2. The project, Folder a, and File 1, have linked metadata to them.\n\n\n\n\nDataset registration\nWhen you want to make sure that your dataset is findable it is recommended that the elements of the description of your dataset are made according to a certain metadata standard that allows for easier exchange of metadata and harvesting of the metadata by search engines. Many certified archives use a metadata standard for the descriptions. If you choose a data repository or registry, you should find out which metadata standard they use. At VU Amsterdam the following standards are used:\n\nDataverseNL and DANS use the Dublin Core metadata standard\nVU Amsterdam Research Portal PURE uses the CERIF metadata standard\n\nMany archives implement or make use of specific metadata standards. The UK Digital Curation Centre (DCC) provides an overview of metadata standards for different disciplines. The list is a great and useful resource in establishing and carrying out your research methodology. Go to the overview of metadata standards. More important tips are available at Dataset & Publication."
  },
  {
    "objectID": "guides/data-lifecycle.html#support",
    "href": "guides/data-lifecycle.html#support",
    "title": "What research data services and support are available for VU researchers?",
    "section": "Support",
    "text": "Support\n\nResearch Data Services\n\n\n\nImage showing the relations between VU Research Data Support Offices, at the center with grants, legal, library, security, IT for Research, and IXA around it.\n\n\nResearch Data Management is supported by various departments at VU Amsterdam. These departments will help all VU researchers. There are also faculty specific support departments for research data support; they support their own faculty members.\nHere you find references to other organisational units and departments that can help you with matters related to collecting and managing data.\nVU research data support (for all researchers)*\n\nGrant office\nLibrary\nLegal\n🔒 IT for Research\nIXA\n\nUse this detailed research process overview to get more information about steps that may occur during the research process and the support offered at the VU for these steps. This overview is very detailed and starts at the earliest stages of identifying research and funding opportunities, and ends at the point of preparing communication about your research. We recommend to read the README and Instructions tabs first before you dive in. For questions, you can also reach the RDM Support Desk\nGeneral Faculty research support and management guidelines are available in the section Policies & Regulations.\n\n\nThis website\nQuestions regarding your data or the information on this website?\nThe RDM Support team can help you with all your questions on data management plans, data storage, data archiving and publishing, and data protection.\n\n\nVU IT for Research\nVU Amsterdam has an IT team specifically devoted to research: ITvO (from ‘IT voor Onderzoek’ in Dutch). They provide the following services:\n\n🔒 Bazis HPC cluster computing: access to your own linux computational cluster at VU Amsterdam\n🔒 SciCloud: a service with which you lease virtual server capacity for research purposes\n🔒 SciStor: inexpensively store large sets with research data\nAdvice/consultancy: ITvO will help you to find a suitable technical solution or support for your research group or project\nHousing: rack space in the server room for (remotely managed) equipment of research groups\n\nRead more about and get in touch with 🔒 IT for Research\n\n\nExternal sources\n\n Research Data Netherlands\n\nResearch Data Netherlands is an alliance between 4TU.Centre for Research Data, Data Archiving and Networked Services (DANS) and SURFsara. With this coalition, which is also open to other parties, the three data archives join forces in the area of long-term data archiving.\n\n Landelijk Coördinatiepunt Research Data Management\n\nThe foundation of co-operating Dutch universities (VSNU) pointed out a need for a co-ordinated and decisive approach to Research Data Management through a dedicated Centre at SURF. The SURF Foundation is an organisation that facilitates education and research in the Netherlands.\n\nThe LCRDM aims to support the preparation, development and monitoring of Research Data Management policies for scientific research in the Netherlands. Important elements of this central approach are close co-operation with researchers in the field and the exchange of knowledge and experience.\n\n The Netherlands eScience Center\n\nThe eScience Center develops software for academic research specifically. Their software and tools enhance the use of digital methods in scientific research across all disciplines. Researchers - including those at VU Amsterdam - can choose to collaborate on projects funded by the NWO or, if they already have funding, ask the eScience Center to collaborate with them.\n\n CESSDA\n\nThe Data Management Expert Guide of the Consortium of European Social Science Data Archives is a practical guide for researchers, addressing many issues they may have"
  },
  {
    "objectID": "guides/data-lifecycle.html#surfsara",
    "href": "guides/data-lifecycle.html#surfsara",
    "title": "What research data services and support are available for VU researchers?",
    "section": "SURFsara",
    "text": "SURFsara\n\n\n\nSURFsara logo\n\n\nSURF is the collaborative organisation for ICT in Dutch education and research. SURF offers advanced ICT services specifically for researchers. You can start using some of these services right away with your VU credentials. For others you have to get in touch with SURF yourself. Please check SURF’s website and the pages about the specific services below for more information.\nSURF’s services are listed on this page.\n\nData services\nSURF offers a wide range of services for different phases in the life cycle of your research data. Everything for the secure storage, management, sharing and reuse of data.\n\nResearch Drive: securely and easily store and share research data.\n\nDoes your research team need large storage quotas, a secure environment to store personal and/or sensitive data, and work collaboratively with other educational and governmental institutions or external private parties? Research Drive is a cloud-based shared-storage environment specifically designed for these requirements.\n\nSURFfilesender: send large files securely and encrypted.\n\nWant to send and receive files quickly, securely and easily? With SURFfilesender, you can send large files, such as research data. The files are stored in the Netherlands. Encryption provides added security.\n\nSecure, long-term storage with Data Archive.\n\nThe Data Archive is the centralised location for data archiving and (long-term) storage. You can securely store research data there, even in volumes running into the petabytes. The archive provides quick access to SURFsara’s computing facilities.\n\nData Persistent Identifier: data always findable by permanent references.\n\nPersistent identifiers (PIDs) ensure the findability of your data, now and always. PIDs are comparable to the ISBN numbers assigned to books. Even if the location or underlying infrastructure changes, the reference path remains intact. SURFsara offers the PID service in cooperation with the European Persistent Identifier Consortium (EPIC).\n\n\n\n\nData processing and analysis (see also ‘Computing’)\n\nJupyter Notebook: accessible and interactive data analysis for research and education.\n\nA Jupyter Notebook is an interactive web application that you can use to create documents, known as notebooks, that contain computer code, formatted text, comparisons and visualisations. The code can be executed in the environment and you can even create streaming applications and dashboards.\n\n\n\n\nComputing\nDo you encounter limitations with your own systems? SURF offers researchers a wide range of services in the field of high performance computing (HPC): thousands of times faster than your PC.\n\nSnellius: National Super Computer.\n\nIt is the most comprehensive system in the field of capability computing in the Netherlands. Snellius is especially in high demand for its combination of fast processors and internal network, large storage capacity and the ability to process large datasets.\n\nSURF Research Cloud: your flexible compute infrastructure.\n\nSURF Research Cloud gives you and your project team complete control over your computing infrastructure. The infrastructure ranges from a single work station to a complete cluster and can be expanded to suit your needs. You can use your own operating system and analysis software. HPC Cloud is housed in SURF’s own data centre.\n\nGrid: for processing and storing large datasets.\n\nDo you want to process and store large- amounts of data? The Grid may very well be suitable for your project. The grid infrastructure consists of a large number of clusters for computing and data storage, which are interconnected via a fast network.\n\nVisualisation: more insight into your data.\n\nDo you want to analyse, process or visualise complex research data or big data? These services give you insight into your research data. SURF’s Visualisation service allows you to visualise your own datasets on your desktop. This makes it easy to identify connections between data or gain other insight into your datasets. SURFsara offers a powerful remote visualisation service that combines high performance with ease of use.\n\nCollaboratorium: a visualisation and presentation space for science and industry.\n\n\n\nExpertise, advice and training\nSURF offers advice and training on their services. Their training sessions are announced in the SURF Agenda.\n\nSURF Training courses for research.\n\nWant to get started with SURF systems but lack the necessary knowledge? SURF regularly organizes hands-on systems training courses at their offices in Utrecht and Amsterdam or at your education or research institution. You can also include the training courses in the educational programme of your institution.\n\nSURF Consultancy on ICT solutions for researchers.\n\nSURFsara possesses a wealth of experience in the field of ICT services for researchers. If you need help developing/improving your application or designing your infrastructure, then you’ve come to the right place. SURF experts will be happy to lend their expertise to support your research."
  },
  {
    "objectID": "guides/publish-and-share.html",
    "href": "guides/publish-and-share.html",
    "title": "How can I archive and publish my data?",
    "section": "",
    "text": "In the Data Management Plan the researcher describes if the data will be stored for the mid or the long term.\n\n\n\nA monochrome picture of two women operating the ENIAC, an early computer\n\n\n\n\nAccording to the VU RDM Policy, all publication-related data should be archived for at least ten years for verification and replication of research. For this purpose, VU Amsterdam offers researchers two options to archive their data in one of the organisational repositories (DataverseNL and Yoda). Other archival options may be used depending on the discipline as described in faculty data management policy documents.\n\n\n\nData relevant for future research should be archived for the long term. A dataset is relevant for future research when at least one of the following general criteria applies:\n1. The data have a scientific or historical value\n2. The data are unique\n3. Others may want to reuse the data\n4. The data cannot be reproduced\nResearchers should bear in mind that repositories can charge for archiving data. These costs can vary according to the data volume and the archive used. It is important that you consider in advance how you will budget for these costs. Whatever archiving option is used, proper descriptions of the dataset(s) and adding metadata are important.\n\n\n\n\nVU Amsterdam requests that researchers archive the data used in a publication in a repository for at least ten years after the release of the publication (see also VU Policies & Regulations). There are a lot of digital archives and many more keep appearing.\nThe right archival option depends on the nature of the data and the field of science as described in faculty or departmental data management policy documents. The university offers 2 different general repositories for data archiving.\n\nThe RDM Support Desk and faculty data stewards can help researchers with the selection of a repository that meets all the relevant criteria of privacy (sensitivity), dataset size, etc.\nDataverseNL - an online platform for the publication of citable research data in a semi-open environment. DataverseNL allows users to link publications to datasets directly, and to share the data through online archives such as DANS.\n\nSpecifications:\n\nFor publishing research data on the internet\nThe researcher publishing the data decides whether access to the data is public or restricted\nNot suitable for privacy or otherwise sensitive information\nEnables researchers to publish open data according to grant providers’ regulations\nGenerates a link (persistent identifier), e.g. for data citations in publications\nRetention period is at least 10 years\n\nYoda - besides active storage, Yoda also has an archive function: the vault. You can use the vault in two ways:\n\nFor archiving data securely; data are only available for verification purposes and may be access only by special request. A special procedure will be followed if anyone requests access to the data in order to verify them.\nFor publishing data; data can be available for anyone, or on request. The data will get a persistent identifier as well.\n\nBefore sending data to the vault, you will need to add metadata. A data steward, metadata specialist or functional manager can help you with the metadata and the entire process of sending data to the vault. Please get in touch with the RDM Support Desk to find this help.\n\n\n\nBesides the repositories offered by VU Amsterdam, there are many others. Unless you are working with personal or otherwise confidential data and you need to archive them in Yoda, you are, in principle, free to choose a different repository from the ones hosted by VU Amsterdam.\nThere can be various reasons to decide to use a different repository, including funder requirements, preferences of research partners, and a repository being a common choice in your field. For example, Dutch archaeologists mostly use DANS Data Stations to deposit and publish their data. Using a repository that is a common choice in your field will make your data more findable for your colleagues and increase the visibility of your work as a researcher. Some of the data repositories most commonly used in the Netherlands include:\n\nDANS Data Stations: a domain-agnostic research data repository hosted by the Data Archiving and Networked Services, an institute of NWO and KNAW. DANS also develops policies, services and new infrastructures for research data and provides researchers with advice on how to preserve their data. VU researchers are also welcome to deposit their data at DANS-EASY;\n4TU.ResearchData: a repository for science, engineering and design data hosted by the 4TU Federation. This is a consortium of the four Dutch technical universities: TU Delft, TU Eindhoven, University of Twente and Wageningen University and Research. VU researchers are also welcome to deposit their data at 4TU;\nZenodo: a domain-agnostic research data repository hosted by CERN in Switzerland and funded by the European Commission. Zenodo does not only host data, but also presentations, conference procedures and policy documents. It is also possible to archive GitHub repositories directly into Zenodo, by which you contribute to Open Science by making a snapshot of your code available in its current form and for the long term;\nOSF (Open Science Framework): a data management and research dissemination platform. VU Amsterdam is an institutional member of the OSF, which means that you can sign up (and in) using your VU account by clicking on the Institution Button on the sign in/up pages. You can use the OSF to create registrations and preregistrations for your research, to publish preprints, and publish and share data and documentation. You can also link other repositories such as DataverseNL to your OSF project. The same goes for GitHub and storage options such as Research Drive and Surfdrive. Do be careful about what you connect! A full guide for VU OSF users, including instructions about connecting external storage can be found here.\n\nYou can also find repositories via the Registry of Research Data Repositories. When you are choosing a repository, it is important to check that it provides all the services you need. A good way to find out is to check if a repository as a Core Trust Seal, which is a form of certification for quality repositories. But if a repository does not have the Core Trust Seal, it does not necessarily mean it is not a good repository. As a minimum, you should check that:\n\nThe repository provides a persistent identifier, such as a DOI;\nThe repository enables you to add rich metadata to your dataset and ideally follows an internationally recognised metadata standard, such as Dublin Core or DataCite;\nThe repository offers functionality to publish data with an embargo or under restrictions, if you need that;\nThe repository allows you to add a licence to the dataset;\nThe repository is funded sustainably for at least the next 50 years;\nAnd, in some cases, that the repository’s servers are located in the EU.\n\nMore recommendations for choosing a data repository can be found on CESSDA.\nIf you would like advice about what would be a good place for you to archive your research data, you can always reach out to the RDM Support Desk."
  },
  {
    "objectID": "guides/publish-and-share.html#selecting-an-archive",
    "href": "guides/publish-and-share.html#selecting-an-archive",
    "title": "How can I archive and publish my data?",
    "section": "",
    "text": "In the Data Management Plan the researcher describes if the data will be stored for the mid or the long term.\n\n\n\nA monochrome picture of two women operating the ENIAC, an early computer\n\n\n\n\nAccording to the VU RDM Policy, all publication-related data should be archived for at least ten years for verification and replication of research. For this purpose, VU Amsterdam offers researchers two options to archive their data in one of the organisational repositories (DataverseNL and Yoda). Other archival options may be used depending on the discipline as described in faculty data management policy documents.\n\n\n\nData relevant for future research should be archived for the long term. A dataset is relevant for future research when at least one of the following general criteria applies:\n1. The data have a scientific or historical value\n2. The data are unique\n3. Others may want to reuse the data\n4. The data cannot be reproduced\nResearchers should bear in mind that repositories can charge for archiving data. These costs can vary according to the data volume and the archive used. It is important that you consider in advance how you will budget for these costs. Whatever archiving option is used, proper descriptions of the dataset(s) and adding metadata are important.\n\n\n\n\nVU Amsterdam requests that researchers archive the data used in a publication in a repository for at least ten years after the release of the publication (see also VU Policies & Regulations). There are a lot of digital archives and many more keep appearing.\nThe right archival option depends on the nature of the data and the field of science as described in faculty or departmental data management policy documents. The university offers 2 different general repositories for data archiving.\n\nThe RDM Support Desk and faculty data stewards can help researchers with the selection of a repository that meets all the relevant criteria of privacy (sensitivity), dataset size, etc.\nDataverseNL - an online platform for the publication of citable research data in a semi-open environment. DataverseNL allows users to link publications to datasets directly, and to share the data through online archives such as DANS.\n\nSpecifications:\n\nFor publishing research data on the internet\nThe researcher publishing the data decides whether access to the data is public or restricted\nNot suitable for privacy or otherwise sensitive information\nEnables researchers to publish open data according to grant providers’ regulations\nGenerates a link (persistent identifier), e.g. for data citations in publications\nRetention period is at least 10 years\n\nYoda - besides active storage, Yoda also has an archive function: the vault. You can use the vault in two ways:\n\nFor archiving data securely; data are only available for verification purposes and may be access only by special request. A special procedure will be followed if anyone requests access to the data in order to verify them.\nFor publishing data; data can be available for anyone, or on request. The data will get a persistent identifier as well.\n\nBefore sending data to the vault, you will need to add metadata. A data steward, metadata specialist or functional manager can help you with the metadata and the entire process of sending data to the vault. Please get in touch with the RDM Support Desk to find this help.\n\n\n\nBesides the repositories offered by VU Amsterdam, there are many others. Unless you are working with personal or otherwise confidential data and you need to archive them in Yoda, you are, in principle, free to choose a different repository from the ones hosted by VU Amsterdam.\nThere can be various reasons to decide to use a different repository, including funder requirements, preferences of research partners, and a repository being a common choice in your field. For example, Dutch archaeologists mostly use DANS Data Stations to deposit and publish their data. Using a repository that is a common choice in your field will make your data more findable for your colleagues and increase the visibility of your work as a researcher. Some of the data repositories most commonly used in the Netherlands include:\n\nDANS Data Stations: a domain-agnostic research data repository hosted by the Data Archiving and Networked Services, an institute of NWO and KNAW. DANS also develops policies, services and new infrastructures for research data and provides researchers with advice on how to preserve their data. VU researchers are also welcome to deposit their data at DANS-EASY;\n4TU.ResearchData: a repository for science, engineering and design data hosted by the 4TU Federation. This is a consortium of the four Dutch technical universities: TU Delft, TU Eindhoven, University of Twente and Wageningen University and Research. VU researchers are also welcome to deposit their data at 4TU;\nZenodo: a domain-agnostic research data repository hosted by CERN in Switzerland and funded by the European Commission. Zenodo does not only host data, but also presentations, conference procedures and policy documents. It is also possible to archive GitHub repositories directly into Zenodo, by which you contribute to Open Science by making a snapshot of your code available in its current form and for the long term;\nOSF (Open Science Framework): a data management and research dissemination platform. VU Amsterdam is an institutional member of the OSF, which means that you can sign up (and in) using your VU account by clicking on the Institution Button on the sign in/up pages. You can use the OSF to create registrations and preregistrations for your research, to publish preprints, and publish and share data and documentation. You can also link other repositories such as DataverseNL to your OSF project. The same goes for GitHub and storage options such as Research Drive and Surfdrive. Do be careful about what you connect! A full guide for VU OSF users, including instructions about connecting external storage can be found here.\n\nYou can also find repositories via the Registry of Research Data Repositories. When you are choosing a repository, it is important to check that it provides all the services you need. A good way to find out is to check if a repository as a Core Trust Seal, which is a form of certification for quality repositories. But if a repository does not have the Core Trust Seal, it does not necessarily mean it is not a good repository. As a minimum, you should check that:\n\nThe repository provides a persistent identifier, such as a DOI;\nThe repository enables you to add rich metadata to your dataset and ideally follows an internationally recognised metadata standard, such as Dublin Core or DataCite;\nThe repository offers functionality to publish data with an embargo or under restrictions, if you need that;\nThe repository allows you to add a licence to the dataset;\nThe repository is funded sustainably for at least the next 50 years;\nAnd, in some cases, that the repository’s servers are located in the EU.\n\nMore recommendations for choosing a data repository can be found on CESSDA.\nIf you would like advice about what would be a good place for you to archive your research data, you can always reach out to the RDM Support Desk."
  },
  {
    "objectID": "guides/publish-and-share.html#alternative-strategies",
    "href": "guides/publish-and-share.html#alternative-strategies",
    "title": "How can I archive and publish my data?",
    "section": "Alternative strategies",
    "text": "Alternative strategies\n\nPublishing your data in a data journal\nInstead of archiving research data in a data repository, you may choose to publish an article about your data collection. This is not necessarily common for all disciplines. Some examples of data journals where you can publish your data and dataset, are:\n\nScientific Data - Nature\nGeoscience Data Journal\nGigascience\nJournal of Physical and Chemical Reference Data\nEarth System Science Data\nJournal of Open Archaeology Data\nJournal of Open Psychology Data\n\n\n\nPublishing your data as supplementary information with your article\nAnother way to make your data available, is to add them as supplementary information with your article in a journal. At first sight, this may seem a practical solution, because the publication and the underlying data in that case appear together as part of a single publication. However, making your data available as a seperate piece of research output has other advantages:\n\nThe dataset will be citable on its own, which also enables you to get acknowledged for the work on your dataset\nDatasets with many files or many different types of files are easier to structure and present in a repository\nYou can assign different levels of accessibility (unrestricted, restricted or closed) if necessary, which is not possible in a publication\nYou don’t transfer copyright of your data publication to the publisher of your article\n\nIf you make your data available through a repository, you can link from your article to your dataset and the other way around, so that you can present them as related research output."
  },
  {
    "objectID": "guides/publish-and-share.html#persistent-identifier",
    "href": "guides/publish-and-share.html#persistent-identifier",
    "title": "How can I archive and publish my data?",
    "section": "Persistent Identifier",
    "text": "Persistent Identifier\nA Persistent Identifier (PID) is a durable reference to a digital dataset, document, website or other object. In the context of research data and software, it is essentially a URL that will never break. By using a Persistent Identifier, you make sure that your dataset will be findable well into the future when it is registered online (for example at DataCite. Another advantage is that it makes a digital object citable.\n\nMultiple PID systems\nThere are multiple PID systems, each with its own particular properties. Examples of widely used PIDs in the research domain include the following.\n\nDOI: A Digital Object Identifier can be used to refer to research data, research software and publications.\nORCiD: An Open Researcher and Contributor ID is used to create a researcher profile with a unique identification number.\nROR: The Research Organization Registry is a global register with persistent identifiers for research institutes.\n\nSee the Persistent Identifier guide of Netwerk Digitaal Erfgoed for a more elaborate overview. Apart from widely used domain-agnostic PIDs, there is a wide range of domain-specific unique identifiers that can be used. If you are interested in domain-specific identifiers, it is useful to ask colleagues in your department or discipline.\n\n\nPersistent Identifiers for data and software in repositories\nPersistent Identifiers can be assigned to datasets and software upon their deposit in a repository. In many repositories, this is a DOI. Data repositories are entitled to generate Persistent Identifiers for data and software. This is one of the reasons why archiving and publishing data and software has to be done in a repository. After the process of uploading data or software to a repository, a Persistent Identifier will be generated. Upon publishing the data or software, the DOI is registered online (usually at DataCite when it concerns a dataset).\nSome repositories enable their users to reserve a Persistent Identifier before the publishing process has finished, so that you can include the Persistent Identifier in a publication before the data will be actually published, or to include the Persistent Identifier in a readme file. This is for example possible in Zenodo.\nThe repositories offered by VU Amsterdam, Yoda and DataverseNL provide DOIs for deposited datasets and software.\n\n\nCreating and using an ORCiD\nResearchers can use an ORCiD to identify their research output as their work. You can request an ORCiD yourself. Instructions for setting up an ORCiD and connecting it to your VU research profile in PURE are available in this ORCiD LibGuide. An ORCiD is often asked for when you submit a publication or upload data or software to a repository. You can use your ORCiD record to create a research profile as well.\n\n\nUsing a ROR\nResearchers can use the ROR for VU Amsterdam when filling metadata forms for their research output to show that their work has been created within their employment at VU Amsterdam."
  },
  {
    "objectID": "guides/publish-and-share.html#licensing-data-and-software",
    "href": "guides/publish-and-share.html#licensing-data-and-software",
    "title": "How can I archive and publish my data?",
    "section": "Licensing data and software",
    "text": "Licensing data and software\n\nLicensing the data\nA data licence agreement is a legal instrument that lets others know what they can and cannot do with your research data (and any documentation, scripts and metadata that are published with the data - information about software licensing can be found on the software licensing page). It is important to consider what kind of limitations are relevant. Usually, at least the following questions are considered:\n\nCan people make copies or even distribute copies?\nDo others (and you) reusing the dataset need to acknowledge you as the author of the original dataset? (This is called Attribution.)\nDo others (and you) who reuse the dataset and/or make derivatives of the dataset need to share their work under a similar licence? (This is called Share-Alike.)\nCan others (and you) use your dataset commercially? (A restriction on commercial use is called Non-Commercial.)\nCan others (and you) create a new work based on the dataset? (This is called a Derivative.)\n\nThe considerations above are the ‘building blocks’ that Creative Commons licences use. There are also other considerations, and also other licences.\n\n\n\nAn image of open data, made up of public domain icons\n\n\nIn principle, Dataverse allows you to choose your terms of use. If you publish your data in Yoda, there is guidance available on how to choose a licence and how to customise licences. Some data repositories require you to use a certain licence if you want to deposit your data with them. At Dryad, for example, all datasets are published under the terms of Creative Commons Zero to minimise legal barriers and to maximise the impact for research and education. Some funders may also require that you publish the data as open data. Open data are data that can be freely used, re-used and redistributed by anyone - subject only, at most, to the requirement to attribute and share alike (Open Knowledge International definition). If you need help with drawing up licence agreements, you can contact the VU’s legal office.\n\n\nAdditional websites and tools:\n\nExplanation about copyrights and licences by a professor from Leiden University (English subtitles available)\nThe Guide to Creative Commons for Scholarly Publishing and Educational Resources by NWO, VSNU and the University and Royal Libraries\nDCC how-to guide on licensing research data, a guide that links to the Creative Commons website, where many terms are explained\nOpen Data Commons Public Domain Dedication and License (PDDL)\nEUDAT B2SHARE licence selection wizard, which Pawel Kamocki (et al.) released under an open source licence.1\n\n\n\nLicensing software\nPublishing research software under an appropriate licence is crucial for its accessibility, usability, and further integration into research. Choosing a licence usually happens right when you start developing the software or when you put it in a public repository, rather than when the software is finished and fully baked.\nA software licence states how other people may re-use your code and under which circumstances. For research software, it is recommended (and often required by funders) that licences are as permissible as possible.\nThere are many licences out there; below we list some very frequently used licences in research software. However, if none of these licences fit your case, there are several tools that can help you to choose a suitable software licence. If you need guidance in choosing a licence for your software, get in touch with the RDM Support Desk.\n\n\nMIT License\nThe MIT License is a popular choice, due to its readability and permissiveness. It allows users to reuse the software for any purpose, including using, copying, modifying, and distributing it, provided they include the original copyright notice and licence text.\nHowever, its permissiveness means that derivative works can be closed-source and do not need to mention that they use your code, which might not align with all scientific openness goals or general.\n\n\nGNU GPLv3\nThe GNU General Public License (GPLv3) is another option, designed to ensure that the software and any derivatives remain open-source.\nThis encourages collaborative improvement of software. Any software that includes GPL-licensed code must also be open-source under the GPLpotentially deterring commercial use or integration with proprietary software. In conclusion, when you want your code to be used by others, but only the code that uses your code is also open source, this is the way to go.\n\n\nApache License 2.0\nThe Apache License 2.0 allows for modification and distribution of the software and its derivative works, with the requirement that changes to the original code are documented.\nIt is a more complex licence than the MIT License and can be incompatible with GPL-licensed software. The specifics of this go beyond the scope of the handbook.\n\n\nAdding a licence to GitHub\nOn GitHub you add a licence on creating a new repository, by selecting the licence from the drop-down menu. If your repository already exists, add a new file called “LICENSE” using the “+”-button on top of the repository (see below).\n\n\n\nLocation of file creation button\n\n\nOne the next page, start to type LICENSE as the file name, and a button to “Choose a license template” should automatically pop up. Follow the steps provided by GitHub to finish adding the licence to the repository.\nYou should now see your licence shown on the main page of your repository.\n\n\nFurther considerations\n\nIf you are reusing software or libraries written by someone else, you must stick to the clauses of the licence given to the original software/library;\nWhen choosing a licence, do not just think about what others may do with the software, but also what you might want to do with the software in the future."
  },
  {
    "objectID": "guides/publish-and-share.html#dataset-registration",
    "href": "guides/publish-and-share.html#dataset-registration",
    "title": "How can I archive and publish my data?",
    "section": "Dataset Registration",
    "text": "Dataset Registration\n\nRegistration & Findability\nWhen you have finished finalizing a dataset or research software and are ready to archive it, there are many options available. Depending on the research and choices made earlier the archive provides the option to fill in descriptive fields for a dataset. The descriptions in the archives often are automatically created using metadata standards like DataCite or Dublin Core, or some other type of standard. See also section Metadata\nWhen registering a dataset or research software in an archive it is important to use unique identifiers to allow for increased findability and easy attribution & citation. Examples of this are:\n\nPersonal names: try to consistently use the same notation for all researchers and assistants that are included as authors\nORCID: using a unique identifier like this for all authors is recommended. More information is available here.\nInstitutional names: avoid using different versions (or language versions) of participating Institutes/organisations and departments. In the case of VU Amsterdam the official written name is: Vrije Universiteit Amsterdam. For each organisation or Institute that is included: try to make sure that the official name is used each time.\n\nSome archives also allow you to preregister your project/dataset/software. Examples are:\n\nOpen Science Framework (OSF) Registration\nZenodo & registration\n\n\n\nRegister your Dataset/Software in PURE\nJust like your publications, data that you have collected for your research constitute research output, too. Therefore you are required to record your datasets and research software in PURE. Your datasets and research software can be of interest to others, which can in turn lead to new collaboration opportunities. Datasets and research software recorded in PURE also appear in reports that are used for research evaluations. Even if access to your dataset and research software is closed, you are required to register your dataset and research software in PURE. It is a record of the research, data collection and analysis that you have carried out.\n\nBenefits of recording your dataset/software in PURE\n\nIt increases the visibility and findability of your datasets and research software\nIt contributes to re-use and transparency\nIt boosts your collaboration opportunities\nIt counts towards research evaluations and assessments\n\n\n\nHow to register your dataset/software in PURE?\n\n\n\nAn image of PURE, indicating where to add a new dataset or software\n\n\n\nLog into the VU Research Portal (PURE) using your VU credentials\nClick on the “+” (plus) icon next to selecting “Datasets/Software” in the overview\nYou can fill in the form using the following manuals and read more about the various metadata in use (generic and subject specific):\n\ndataset manual (NL)\nsoftware manual (EN)\n\nClick on “Save” to store the registration"
  },
  {
    "objectID": "guides/publish-and-share.html#footnotes",
    "href": "guides/publish-and-share.html#footnotes",
    "title": "How can I archive and publish my data?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor the source code, see https://github.com/ufal/public-license-selector/↩︎"
  },
  {
    "objectID": "editors-guide.html",
    "href": "editors-guide.html",
    "title": "Editor’s guide",
    "section": "",
    "text": "Welcome to the Editor’s guide to the Handbook! This page contains resources around how the editors work.\nThe current editors are:\nThey can be pinged on GitHub as a team by using @ubvu/editors as the tag."
  },
  {
    "objectID": "editors-guide.html#what-does-an-editor-do",
    "href": "editors-guide.html#what-does-an-editor-do",
    "title": "Editor’s guide",
    "section": "What does an editor do?",
    "text": "What does an editor do?\nEditors tie together all the strings in this VU Amsterdam community handbook. We keep a bird’s eye view to ensure that what you read makes sense. Editors also help ensure the style and quality of the different pages are similar. Editors also help keep the content relevant to the entirety of VU Amsterdam (faculty specific information is not within scope).\nEach editor commits themselves to providing timely reviews of topics, guides, or both.1 This commitment is for a limited time and can be renewed. We also welcome more editors at any time, given that we do not expect all editors to review everything.\nAs we go on this journey together, we may assign more specific responsibilities as they emerge."
  },
  {
    "objectID": "editors-guide.html#quality-standards",
    "href": "editors-guide.html#quality-standards",
    "title": "Editor’s guide",
    "section": "Quality standards",
    "text": "Quality standards\nAs editors, we maintain a bunch of quality standards, both automated and not automated. If you are reading this as a contributor, you will greatly help us out by taking these into account.\nHere are some quality standards we maintain throughout the handbook:\n\nWriting must be primarily in active voice, both for consistent and engaging text across all pages\nAcronyms must be written in full at least once on the page where they are used\nAll changes to the handbook are made via pull requests. Each change needs approval from two editors.\n\nPull requests may not be merged if the QA automations fail\n\nLinks must be https://\nAll images must have alt text\nLinks must be descriptive (no “click here” links)\nNo writing in name of the handbook (for example, “we recommend repository X”)\nWhere possible, pages with a DOI must link through the DOI (for example, https://doi.org/10.4444/xxxx instead of the direct link https://nature.com/...)\n\nWe try to automate most of these rules, but this is not always possible or accurate enough.\n\nTopics\nFor topics we maintain an additional set of standards:\n\nTopics must be nouns or noun phrases\nTopics are self-contained and aim for brevity\nAll topics must be title capitalized (see also the helpful tool CapitalizeMyTitle.com)\nNo include statements are allowed in topics\n\nInclude statements must be prefaced with the relevant section heading, as the title of a topic is not reproduced.\n\nNo use of special Quarto code is allowed. Only use regular markdown in topics.\n\n\n\nGuides\nFor guides we maintain other standards:\n\nGuides must be phrased as questions that the reader will get answers to (for example, “how do I preserve data?”)"
  },
  {
    "objectID": "editors-guide.html#how-to-keep-an-overview-of-everything",
    "href": "editors-guide.html#how-to-keep-an-overview-of-everything",
    "title": "Editor’s guide",
    "section": "How to keep an overview of everything?",
    "text": "How to keep an overview of everything?\nWith so many issues and pull requests, it is easy to get lost as an editor. We have a project management board that can be helpful identifying what is going on at this time:\n\nTopics\nGuides"
  },
  {
    "objectID": "editors-guide.html#etiquette",
    "href": "editors-guide.html#etiquette",
    "title": "Editor’s guide",
    "section": "Etiquette",
    "text": "Etiquette\nAs editors, we may have to make tough calls at times. It is important for us to make people feel welcome and appreciated, even if their contribution is not immediately included. That being said, we reciprocate the consideration given to us. We operate under a generosity policy, and if reciprocated, we stay generous.\n\nGitHub etiquette\nAs editors, we also maintain a certain GitHub etiquette. It is necessary to make managing a project with so many moving pieces and contributors. Important is:\n\nNew topics or guides must be linked to the issue proposing it\nEach pull request should have a clear purpose and stick to it (for example, no editing a guide when proposing a topic)\n\nItem 2 also means changes should be branch specific, as pull requests are based off branches. It makes it much harder to review things if there are many different kinds of changes, as we editors will need to keep track of all of this.\nSimplicity is our friend. Simplicity helps us from making mistakes."
  },
  {
    "objectID": "editors-guide.html#protocols",
    "href": "editors-guide.html#protocols",
    "title": "Editor’s guide",
    "section": "Protocols",
    "text": "Protocols\n\nHackathon protocol\nWe sometimes run hackathons to create space to contribute. We run hackathons as follows:\nPreparation:\n\nHackathons are two hours long\nHackathons are run using Zoom\nEach hackathon has a theme (it helps focus people’s energy on something and can inspire participation)\nWe use a collaborative note taking document that requires no logging in, which is the central place to navigate the hackathon\nAssign a host\n\nDuring:\n\nOpen 10 breakout rooms in zoom, allowing participants to freely move around\nThe host…\n\n…Welcomes everyone with an icebreaker question\n…Shares the link to the note taking document when people join\n…Sets the stage for the hackathon when it starts\n…Announces a break at the halfway mark\n\nKeep track of all the issues and pull requests opened for the speed blog\n\nAfter:\n\nFinish up the speed blog for the hackathon within one week of the hackathon. It does not have to be perfect and is primarily to document that the hackathon happened and some of the things that were done."
  },
  {
    "objectID": "editors-guide.html#footnotes",
    "href": "editors-guide.html#footnotes",
    "title": "Editor’s guide",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEach editor chooses which of these they want to focus on. Editors get auto-invited to review the changes. Timely means within a week.↩︎"
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html",
    "href": "blog/2024-10-22post-mortem.html",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "",
    "text": "On Friday October 18th 2024, we experienced around ten hours of downtime on the rdm.vu.nl website. The downtime started around 10AM after merging changes to the handbook and was resolved the same day, by 8PM.1"
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html#root-cause",
    "href": "blog/2024-10-22post-mortem.html#root-cause",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "Root cause",
    "text": "Root cause\nThe downtime started after merging changes to the handbook in commit 669b065. These changes themselves, did not cause the downtime. The root cause was an incorrect configuration in the deployment of the webpage, which inadvertently removed the rdm.vu.nl domain name from the GitHub settings every time we made changes in the handbook and redeployed the website. This resulted in 404 errors that the page could not be found.\nWe first observed this issue on Thursday, one day prior to the downtime, in commit 678ff88. We proposed a fix for this issue in #220, before the downtime started."
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html#how-could-the-downtime-happen-if-the-fix-was-clear",
    "href": "blog/2024-10-22post-mortem.html#how-could-the-downtime-happen-if-the-fix-was-clear",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "How could the downtime happen if the fix was clear?",
    "text": "How could the downtime happen if the fix was clear?\nThe fix for the domain specification was not merged in time for two reasons.\n\nReason 1\nAt this time, we require two reviews before merging changes to the handbook. The fix was proposed at 1.11PM on Thursday, and did not receive the required reviews by the time the downtime happened (reason 1). However, this was a technical administration task and could have been merged immediately, as this supercedes regular review procedures.\n\n\nReason 2\nThe domain specification fix was not immediately merged to allow time to pass and ensure the fix was appropriate upon further reflection. This is because administrator (chartgerink?) both proposed the fix and would also be the one to supercede the “two reviews” requirement. Due to travel, the administrator forgot about it in the morning, and only saw the messages about the downtime at 8PM. At that time, the fix was quickly merged and the downtime resolved."
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html#improvements",
    "href": "blog/2024-10-22post-mortem.html#improvements",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "Improvements",
    "text": "Improvements\nThe domain configuration is corrected and the deployment ensures the domain name is re-added to the GitHub settings every time there are changes to the handbook. This is now automated, which ensures that the domain name will not be removed inadvertently when future changes are incorporated.\nHowever, we also learned that critical administration fixes should not be left open for longer than is absolutely necessary. Here it was left open for longer than absolutely necessary due to travel, and a second administrator could have caught this issue sooner. This means we should work towards resilient reporting mechanisms to escalate such critical issues, and build capacity in the editor team to ensure no one person is responsible for merging critical fixes that are already available."
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html#acknowledgements",
    "href": "blog/2024-10-22post-mortem.html#acknowledgements",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe would like to thank the editors for dealing with the stress from this inadvertent issue. We also thank the community for their patience as we only recently migrated to rdm.vu.nl and figure out these initial unexpected hurdles."
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html#references",
    "href": "blog/2024-10-22post-mortem.html#references",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "References",
    "text": "References\n\nRoot cause for the downtime first observed in commit 678ff88\nProposed a fix for the root cause in pull Request #220\nDowntime started at commit 669b065 is where the\nResolved downtime in commit 678ff88"
  },
  {
    "objectID": "blog/2024-10-22post-mortem.html#footnotes",
    "href": "blog/2024-10-22post-mortem.html#footnotes",
    "title": "Why was rdm.vu.nl down for ten hours?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nubvu.github.io/open-handbook remained online during this entire time, and functions indirectly as a backup.↩︎"
  },
  {
    "objectID": "blog/2024-11-28hackathon.html",
    "href": "blog/2024-11-28hackathon.html",
    "title": "Fifth Handbook Hackathon",
    "section": "",
    "text": "On November 28, 2024, all authors participated in the fifth hackathon for the Research Support Handbook. For this hackathon, we focused on adding new content and consolidating requests.\nWe had a large number of contributions related to tools. The handbook now has information about Research Cloud, SciCloud and Yoda. These were long-standing issues and it is really nice that they turned into topics.\nIrene helped us to revise the metadata topic.\nTycho is working on a page for ORCID, the ORCID Libguide page will be adjusted to redirect to the handbook.\nLena was working on a data backup topic, trying to make it generic and applicable to multiple tools.\nWe had a discussion of an overview page. New colleagues also within support miss an overview of the services available. There are many pages that give some ideas: the RDS portal on Tools, the guide on available services and RISP - but all these overviews have diverse struggles so we are still looking for a good way of doing it.\nITvO colleagues noticed that they miss an official VU page which gives a summary of what ITvO is and does.\nQuestion that came up: how to add new contributors? Do they need access rights? Do they work with forks or branches?"
  },
  {
    "objectID": "blog/2024-11-28hackathon.html#hackathon-issues",
    "href": "blog/2024-11-28hackathon.html#hackathon-issues",
    "title": "Fifth Handbook Hackathon",
    "section": "Hackathon Issues",
    "text": "Hackathon Issues\nhttps://github.com/ubvu/open-handbook/issues/275"
  },
  {
    "objectID": "blog/2024-11-28hackathon.html#hackathon-pull-requests",
    "href": "blog/2024-11-28hackathon.html#hackathon-pull-requests",
    "title": "Fifth Handbook Hackathon",
    "section": "Hackathon Pull Requests",
    "text": "Hackathon Pull Requests\nhttps://github.com/ubvu/open-handbook/pull/277\nhttps://github.com/ubvu/open-handbook/pull/276\nhttps://github.com/ubvu/open-handbook/pull/140\nhttps://github.com/ubvu/open-handbook/pull/273\nMerged https://github.com/ubvu/open-handbook/pull/270#pullrequestreview-2467652120"
  },
  {
    "objectID": "blog/2024-11-01hackathon.html",
    "href": "blog/2024-11-01hackathon.html",
    "title": "Fourth Handbook Hackathon",
    "section": "",
    "text": "On October 30th, 2024, all authors participated in the fourth hackathon for the Research Support Handbook. Since the third hackathon, we migrated to rdm.vu.nl, which is a huge milestone! 🎉\nFor the fourth hackathon, we focused on tying up loose ends that we accumulated. The migration means we are now in a stable state, yet there is always more work to be done. During this hackathon, we focused on picking up stale discussions, reviewing open pull requests, and generally closing issues that we took too long to revisit.\nWe considered how (un)balanced the various Topics had gotten, because we want readers to be able to form consistent expectations. We observed that some topics are related to tools, others to concepts. Some topics are concise, whereas others are lengthy.\nOne breakout group focused on creating templates for both kinds of topics, resulting in an initial structure that will make it easier to start new topics in the future. Specifically we propose the following template structure for tools (for example, Qualtrics, HPC, DMPonline):\nAnd the following structure for concepts (for example, DMP, data citation, data storage):\nWe will follow up with a new hackathon in late november."
  },
  {
    "objectID": "blog/2024-11-01hackathon.html#issues-worked-on",
    "href": "blog/2024-11-01hackathon.html#issues-worked-on",
    "title": "Fourth Handbook Hackathon",
    "section": "Issues worked on",
    "text": "Issues worked on\nhttps://github.com/ubvu/open-handbook/issues/232\nhttps://github.com/ubvu/open-handbook/issues/233"
  },
  {
    "objectID": "blog/2024-11-01hackathon.html#pull-requests-worked-on",
    "href": "blog/2024-11-01hackathon.html#pull-requests-worked-on",
    "title": "Fourth Handbook Hackathon",
    "section": "Pull Requests worked on",
    "text": "Pull Requests worked on\nhttps://github.com/ubvu/open-handbook/pull/229\nhttps://github.com/ubvu/open-handbook/pull/231\nhttps://github.com/ubvu/open-handbook/pull/234\nhttps://github.com/ubvu/open-handbook/pull/235\nhttps://github.com/ubvu/open-handbook/pull/236\nhttps://github.com/ubvu/open-handbook/pull/237"
  },
  {
    "objectID": "blog/2024-09-05hackathon.html",
    "href": "blog/2024-09-05hackathon.html",
    "title": "Second Handbook Hackathon",
    "section": "",
    "text": "On September 5th, 2024, all authors participated in the second hackathon for the Research Support Handbook. For this hackathon, we focused on quality assurance. Quality assurance is crucial in ensuring that all parties at VU Amsterdam feel confident adopting this evolving, community-led resource as an official university page. Our goal is to migrate the handbook to rdm.vu.nl in the near future, which requires us to everything is in tip-top shape.\nCollectively, we proofread the migrated LibGuide pages. The result of this are seven GitHub issues and nine pull requests for revisions. These include making sure all images are migrated into the handbook, ensuring appropriate page titles, and refining the contribution guide.\nDuring the hackathon, we observed a lot of links in the old LibGuide resource, are broken. We did some much needed maintenance work during the hackathon, given that the Research Support Handbook will replace the LibGuide resource. We identified broken links and replaced them where possible. There is a need to make this a less manual process in the future and will seek out automations to help us maintain the links moving forward. Additionally, there are many internal links that need updating, changing from LibGuide URLs to GitHub pages. We also discovered several links accessible only with university credentials, which we believe detract from the user experience; these links will require special labeling and contextualization.\nThe general sentiment at the end of the hackathon is that there is still lots of work to do. The community standards are manifesting themselves, and it is clear that pathways need more work to be production ready. These discussions surfaced a wish to have more frequent hackathons at this time, until the standards are set and the included content is ready for rdm.vu.nl."
  },
  {
    "objectID": "blog/2024-09-05hackathon.html#hackathon-issues",
    "href": "blog/2024-09-05hackathon.html#hackathon-issues",
    "title": "Second Handbook Hackathon",
    "section": "Hackathon Issues",
    "text": "Hackathon Issues\n\nhttps://github.com/ubvu/open-handbook/issues/123\nhttps://github.com/ubvu/open-handbook/issues/128\nhttps://github.com/ubvu/open-handbook/issues/125\nhttps://github.com/ubvu/open-handbook/issues/124\nhttps://github.com/ubvu/open-handbook/issues/123\nhttps://github.com/ubvu/open-handbook/issues/130\nhttps://github.com/ubvu/open-handbook/issues/131"
  },
  {
    "objectID": "blog/2024-09-05hackathon.html#hackathon-pull-requests",
    "href": "blog/2024-09-05hackathon.html#hackathon-pull-requests",
    "title": "Second Handbook Hackathon",
    "section": "Hackathon Pull Requests",
    "text": "Hackathon Pull Requests\n\nhttps://github.com/ubvu/open-handbook/pull/126\nhttps://github.com/ubvu/open-handbook/pull/110\nhttps://github.com/ubvu/open-handbook/pull/127\nhttps://github.com/ubvu/open-handbook/pull/129\nhttps://github.com/ubvu/open-handbook/pull/132\nhttps://github.com/ubvu/open-handbook/pull/133\nhttps://github.com/ubvu/open-handbook/pull/134\nhttps://github.com/ubvu/open-handbook/pull/135"
  },
  {
    "objectID": "guides.html",
    "href": "guides.html",
    "title": "Guides",
    "section": "",
    "text": "What is a guide?\n\n\n\nThese guides help you find answers to questions that come up while doing research. They help guide you through various topics at once.\nMissing a guide? You can submit questions you are dealing with using the Contribution portal.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can I archive and publish my data?\n\n\n\nPublish & Share\n\n\n\nAll data and software leading to a published result, must be archived and published.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you discover and reuse existing research data?\n\n\n\nDiscover & Initiate\n\n\n\nThere is so much data out there, that we want to help you find your way more easily.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you ensure data protection and security during collection, storage, and transfer?\n\n\n\nCollect & Store\n\n\n\nLearn about how to secure research data at any stage.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you ensure data provenance and accurate data analysis?\n\n\n\nProcess & Analyse\n\n\n\nWhere data and results come from matters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you ensure research data is FAIR?\n\n\n\nDocument & Preserve\n\n\n\nMaking your data Findable, Accessible, Interopable, Reusable is more doable than you might think.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you publish FAIR software\n\n\n\nPublish & Share\n\n\n\nA step-wise guide to make your software Findable, Accesible, Interoperable and Reusable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you set up research data management from the start?\n\n\n\nPlan & Design\n\n\n\nA good plan is half the work.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat policies and regulations support VU’s vision on Open Science?\n\n\nAs open as possible, as closed as necessary.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat research data services and support are available for VU researchers?\n\n\nFind some resources that can help you along your research journey.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "RDM-guidelines/RDM-resources.html#support",
    "href": "RDM-guidelines/RDM-resources.html#support",
    "title": "What research resources are available for VU researchers related to research data management?",
    "section": "Support",
    "text": "Support\n\nResearch Data Services\n\n\n\nImage showing the relations between VU Research Data Support Offices, at the center with grants, legal, library, security, IT for Research, and IXA around it.\n\n\nResearch Data Management is supported by various departments at the VU. These departments will help all VU researchers. There are also faculty specific support departments for research data support; they support their own faculty members.\nHere you find references to other organisational units and departments that can help you with matters related to collecting and managing data.\nVU research data support (for all researchers)*\n\nGrant office\nLibrary\nLegal\n🔒 IT for Research\nIXA"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Fifth Handbook Hackathon\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2024\n\n\nLena Karvovskaya, Jolien Scholten, Kostas Vilkelis, Tycho Hofstra, Irene Martorelli, Peter Vos\n\n\n\n\n\n\n\n\n\n\n\n\nFourth Handbook Hackathon\n\n\n\n\n\n\n\n\n\n\n\nNov 1, 2024\n\n\nChris Hartgerink, Lena Karvovskaya, Jolien Scholten, Tycho Hofstra, Elisa Rodenburg, Stephanie van de Sandt\n\n\n\n\n\n\n\n\n\n\n\n\nWhy was rdm.vu.nl down for ten hours?\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2024\n\n\nChris Hartgerink, Lena Karvovskaya\n\n\n\n\n\n\n\n\n\n\n\n\nThird Handbook Hackathon\n\n\n\n\n\n\n\n\n\n\n\nSep 30, 2024\n\n\nAlex van der Jagt, FGB, sec. KNOP, Chris Hartgerink (host), Diogenes Cruz de Arcelino, Elisa Rodenburg, UBVU, Jessica Hrudey, FGB, Jolien Scholten, UB, Lena Karvovskaya, UBVU, Stephanie van de Sandt, UBVU, Tycho Hofstra, UBVU\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Handbook Hackathon\n\n\n\n\n\n\n\n\n\n\n\nSep 5, 2024\n\n\nAlex van der Jagt, Chris Hartgerink, Elisa Rodenburg, Jens de Bruijn, Jolien Scholten, Joy Jiayi Cheng, Lena Karvovskaya, Meron Vermaas, Peter Vos, Stephanie van de Sandt, Tycho Hofstra\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Handbook Hackathon\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2024\n\n\nAlex van der Jagt, Chris Hartgerink, Dimitri Unger, Elisa Rodenburg, Jessica Hrudey, Jolien Scholten, Lena Karvovskaya, Lucy O’ Shea, Mar Barrantes-Cepas, Meron Vermaas, Peter Vos, Stephanie van de Sandt\n\n\n\n\n\n\n\n\n\n\n\n\nHello world!\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "topics/cff.html",
    "href": "topics/cff.html",
    "title": "Citation File Format (CFF)",
    "section": "",
    "text": "A Citation File Format (CFF) is a computer file that contains all information needed to cite something. For example, a dataset or a piece of software.\nSeveral data and software repositories, such as Zenodo and GitHub, support this format and enable others to easily select the citation information in their preferred format. Most reference managers can work with these standardized citation files, and automatically format the references in a document.\n\n\n\nA screenshot of the interface to cite a GitHub repository\n\n\nAn example, CFF-file is given below, but to enable you to easily create a CFF-file you can use this website.\ncff-version: 1.2.0\nmessage: \"If you use this data, please cite it as below.\"\nauthors:\n - family-names: Druskat\n   given-names: Stephan\n   orcid: https://orcid.org/1234-5678-9101-1121\ntitle: \"My Research Software\"\nversion: 2.0.4\nidentifiers:\n  - type: doi\n    value: 10.5281/zenodo.1234\ndate-released: 2021-08-11"
  },
  {
    "objectID": "topics/snellius.html",
    "href": "topics/snellius.html",
    "title": "Snellius",
    "section": "",
    "text": "Snellius is the National Supercomputer infrastructure hosted by SURF in Amsterdam."
  },
  {
    "objectID": "topics/snellius.html#what-is-it",
    "href": "topics/snellius.html#what-is-it",
    "title": "Snellius",
    "section": "",
    "text": "Snellius is the National Supercomputer infrastructure hosted by SURF in Amsterdam."
  },
  {
    "objectID": "topics/snellius.html#what-can-it-be-used-for",
    "href": "topics/snellius.html#what-can-it-be-used-for",
    "title": "Snellius",
    "section": "What can it be used for?",
    "text": "What can it be used for?\n\nSimulation and modelling\nDo you work with large and complex models that require a lot of computing power? The National Supercomputer provides that with a large number of super-fast processors. The system is ideally suited for large-scale experiments, such as simulations and modelling. These require a lot of processing power and memory usage, but also communication between the different processors. An important feature of Snellius is its fast internal network.\n\n\nComputing power\nSnellius runs on Linux. Besides AMD processors, the system also features GPGPUs (General Purpose Graphics Processing Units). These accelerators combine the processing power of graphics cards (GPUs) with that of CPUs. In addition, Snellius has ‘fat nodes’ with more memory space (1 TB) and ‘high-memory nodes’ (4 TB and 8 TB of memory space).\n\n\nTools and libraries\nAs a researcher, you can make use of a large collection of tools, compilers and libraries.\nAre you doing research or experiments in the field of machine learning, e.g. neural networks? The libraries and tools on Snellius make it a lot easier."
  },
  {
    "objectID": "topics/snellius.html#how-to-request-access",
    "href": "topics/snellius.html#how-to-request-access",
    "title": "Snellius",
    "section": "How to request access",
    "text": "How to request access\nYou can request access via a form on the 🔒SURF service desk portal. There are 2 options:\n\n1. Direct institute contract\nThe VU has a contract with SURF for the usage of Snellius. Every VU researcher or master student can request Snellius SBUs (System Billing Units). The total amount available to the VU is limited however, only use this option for smaller projects, say up to 1.000.000 CPU and/or GPU SBUs.\nThe SURF wiki provides some guidance on estimating the amount of SBUs you need. We recommend you start with the default 50.000 CPU and/or GPU SBUs. You can use the same form to request a top-up if you run out.\n\n\n2. NWO compute grant\nIf you have a large project involving more than 1.000.000 CPU and/or GPU SBUs you should apply for an NWO Large Compute applications grant.\nEach Snellius account is provided with 200GB Home space (backups available), apart from that 8TB of temporary fast scratch space is available for your calculations. If the Home space is not sufficient or you can request Project Space to store your data during your project. Note that the Project Space is not backed-up! Always make sure a copy of valuable data is also stored on a recommended storage system.\nNote that for large-scale GPU projects access the European LUMI supercomputer can also be requested by VU researcers. Obtaining compute time on LUMI."
  },
  {
    "objectID": "topics/snellius.html#are-there-costs-involved",
    "href": "topics/snellius.html#are-there-costs-involved",
    "title": "Snellius",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThere are no direct costs for researchers, but be aware that “Direct institute contract” usage costs are billed to the faculties via KDM (“Kosten Doorbelasting Model”)."
  },
  {
    "objectID": "topics/snellius.html#getting-started",
    "href": "topics/snellius.html#getting-started",
    "title": "Snellius",
    "section": "Getting started",
    "text": "Getting started\nThe SURF User Knowledge Base has lots of information to get you started.\nSURF organises regular “Introduction to Supercomputing” training sessions, these are free to attend for VU researchers. Please consult the SURF Agenda for dates and registration.\nNote that there is a free community partition available on the VU HPC cluser BAZIS, where you can refine your analysis scripts before running them on the more expensive Snellius cluster. Experts at IT for Research can help you optimise your code to run more efficiently."
  },
  {
    "objectID": "topics/snellius.html#contact",
    "href": "topics/snellius.html#contact",
    "title": "Snellius",
    "section": "Contact",
    "text": "Contact\nSURF offers limited direct support for researchers using Snellius. To ask a question create a ticket on the 🔒SURF Service Desk Portal.\nFor general questions on HPC please contact IT for Research."
  },
  {
    "objectID": "topics/metadata.html",
    "href": "topics/metadata.html",
    "title": "Metadata",
    "section": "",
    "text": "Metadata provide information about your data. Structured metadata are intended to provide this information in a standardised way. The structured metadata are readable for both humans and machines. It can be used by data catalogues, for example DataCite Commons.\nThe standardisation of metadata involves the following aspects:"
  },
  {
    "objectID": "topics/metadata.html#metadata-standards",
    "href": "topics/metadata.html#metadata-standards",
    "title": "Metadata",
    "section": "Metadata standards",
    "text": "Metadata standards\nMetadata standards allow for easier exchange of metadata and harvesting of the metadata by search engines. Many certified archives use a metadata standard for the descriptions. If you choose a data repository or registry, you should find out which metadata standard they use. At VU Amsterdam the following standards are used:\n\nYoda uses the DataCite metadata standard\nDataverseNL uses the Dublin Core metadata standard\nVU Amsterdam Research Information System PURE uses the CERIF metadata standard\n\nMany archives implement or make use of specific metadata standards. The UK Digital Curation Centre (DCC) provides an overview of metadata standards for different disciplines. The list is a great and useful resource in establishing and carrying out your research methodology."
  },
  {
    "objectID": "topics/metadata.html#controlled-vocabularies-classifications",
    "href": "topics/metadata.html#controlled-vocabularies-classifications",
    "title": "Metadata",
    "section": "Controlled Vocabularies & Classifications",
    "text": "Controlled Vocabularies & Classifications\nControlled vocabularies are lists of terms created by domain experts to refer to a specific phenomenon or event. Controlled vocabularies are intended to reduce ambiguity that is inherent in normal human languages where the same concept can be given different names and to ensure consistency. Controlled vocabularies are used in subject indexing schemes, subject headings, thesauri, taxonomies and other knowledge organisation systems. Some vocabularies are very internationally accepted and standardised and may even become an ISO standard or a regional standard/classification. Controlled vocabularies can be broad in scope or very limited to a specific field. When a Data Management Plan template includes a question on the used ontology (if any), what is usually meant is: is there a specific vocabulary or classification system used? The National Bioinformatics Infrastructure Sweden gives some more explanation about controlled vocabularies and ontologies here. In short, an ontology does not only describe terms, but also indicates relationships between these terms.\nExamples of controlled vocabularies are:\n\nCDWA (Categories for the Description of Works of Art)\nGetty Thesaurus of Geographic names\nNUTS (Nomenclature of territorial units for statistics)\nMedical Subject HEadings (MeSH)\nThe Environment Ontology (EnvO)\n\nMany examples of vocabularies and classification systems can be found at the FAIRsharing.org website. It has a large list for multiple disciplines. If you are working on new concepts or new ideas and are using or creating your own ontology/terminology, be sure to include them as part of the metadata documentation in your dataset (for example as part of your codebook)."
  },
  {
    "objectID": "topics/metadata.html#metadata-levels",
    "href": "topics/metadata.html#metadata-levels",
    "title": "Metadata",
    "section": "Metadata levels",
    "text": "Metadata levels\nFinally a distinction can be made on the level of description. Metadata can be about the data as a whole or about part of the data. It can depend on the research domain and the tools that are used on how many levels the data can be described. In repositories like Yoda and DataverseNL it is common practice to only create structured metadata on the level of the data as a whole. The Consortium of European Social Science Data Archives (CESSDA) explains this distinction for several types of data in their Data Management Expert Guide.\n\n\n\nFlowchart indicating a project with a Folder a and Folder b, where Folder a has File 1 and File 2. The project, Folder a, and File 1, have linked metadata to them."
  },
  {
    "objectID": "topics/metadata.html#dataset-registration",
    "href": "topics/metadata.html#dataset-registration",
    "title": "Metadata",
    "section": "Dataset registration",
    "text": "Dataset registration\nWhen you want to make sure that your dataset is findable it is recommended that the elements of the description of your dataset are made according to a certain metadata standard that allows for easier exchange of metadata and harvesting of the metadata by search engines. Many certified archives use a metadata standard for the descriptions. If you choose a data repository or registry, you should find out which metadata standard they use. At VU Amsterdam the following standards are used:\n\nDataverseNL and DANS use the Dublin Core metadata standard\nVU Amsterdam Research Portal PURE uses the CERIF metadata standard\n\nMany archives implement or make use of specific metadata standards. The UK Digital Curation Centre (DCC) provides an overview of metadata standards for different disciplines. The list is a great and useful resource in establishing and carrying out your research methodology. Go to the overview of metadata standards. More important tips are available at Dataset & Publication."
  },
  {
    "objectID": "topics/data-storage.html",
    "href": "topics/data-storage.html",
    "title": "Data Storage",
    "section": "",
    "text": "VU Amsterdam offers several options to store your research data. The choice for a specific option may depend on factors such as:\n\nDoes a project involve multiple organisations or departments?\nThe sensitivity of the data: does it involve personal data or copyrighted / commercial data?\nAre there any research partners with whom data need to be shared?\nAre any commercial parties involved?\nDoes the research project involve multiple locations (inside or maybe even outside the EU)?\nWill there be (lab) devices producing data that need to be stored as well?\nWhat will be the volume of the data?\nWill there be lots of interactions with the data (using software/tools)?\n\nStorage options may take several forms, for example:\n\nLocal storage on computers, networks or servers;\nCloud storage offered by VU Amsterdam;\nLocations where physical data samples are stored (fridges, lockers, etc.).\n\nResearchers, including PhD candidates, have multiple options that can be used, some of which are listed below. More information about these storage options is available behind their respective links. The Storage finder is a tool that will give you a number of storage options suitable for your research. For more individual guidance, please get in touch with the Research Data Management Support Desk for advice, particularly when you are working with commercial, personal or otherwise sensitive data, or when you have a complex IT setup."
  },
  {
    "objectID": "topics/data-storage.html#storage-during-research",
    "href": "topics/data-storage.html#storage-during-research",
    "title": "Data Storage",
    "section": "",
    "text": "VU Amsterdam offers several options to store your research data. The choice for a specific option may depend on factors such as:\n\nDoes a project involve multiple organisations or departments?\nThe sensitivity of the data: does it involve personal data or copyrighted / commercial data?\nAre there any research partners with whom data need to be shared?\nAre any commercial parties involved?\nDoes the research project involve multiple locations (inside or maybe even outside the EU)?\nWill there be (lab) devices producing data that need to be stored as well?\nWhat will be the volume of the data?\nWill there be lots of interactions with the data (using software/tools)?\n\nStorage options may take several forms, for example:\n\nLocal storage on computers, networks or servers;\nCloud storage offered by VU Amsterdam;\nLocations where physical data samples are stored (fridges, lockers, etc.).\n\nResearchers, including PhD candidates, have multiple options that can be used, some of which are listed below. More information about these storage options is available behind their respective links. The Storage finder is a tool that will give you a number of storage options suitable for your research. For more individual guidance, please get in touch with the Research Data Management Support Desk for advice, particularly when you are working with commercial, personal or otherwise sensitive data, or when you have a complex IT setup."
  },
  {
    "objectID": "topics/data-storage.html#standard-services-offered-by-vu-amsterdam",
    "href": "topics/data-storage.html#standard-services-offered-by-vu-amsterdam",
    "title": "Data Storage",
    "section": "Standard services offered by VU Amsterdam",
    "text": "Standard services offered by VU Amsterdam\nVU IT offers several services for employees to store their files. Examples are:\n\n🔒 OneDrive: personal storage for all VU employees and part of the Microsoft 365 platform. OneDrive allows you to store files locally and in the Microsoft cloud, and share folders and documents with colleagues. Since this is personal storage, tied to someone’s personal VU account, we don’t usually recommend storing research data in OneDrive: if the account holder leaves VU Amsterdam, the account and all the data on it, disappear.\n🔒 Teams. Faculties, divisions and departments have their own Team - part of the Microsoft 365 platform - where they store shared documents and where they can interact and chat. Projects may also request a project team. But note that Teams is not always the best location to store your research data and has several limitations, especially when it comes to working with non-Microsoft file formats, large volumes of data, interacting with data, and collaborating with partners outside of VU Amsterdam. Contact the RDM Support Desk to find out more about the suitability of Teams for your project."
  },
  {
    "objectID": "topics/data-storage.html#research-data-specific-storage-options",
    "href": "topics/data-storage.html#research-data-specific-storage-options",
    "title": "Data Storage",
    "section": "Research data-specific storage options",
    "text": "Research data-specific storage options\nThe options above are standard data storage options at VU Amsterdam to which all employees have access. But VU Amsterdam also offers storage specifically for research data. Some of them are hosted locally at VU Amsterdam, while others are SURF cloud services. When selecting a cloud-based service it is important to remember to check where the data will be hosted. If the research project involves sensitive data it may be necessary to choose cloud-based options that guarantee that the data will stay in the EEA or on servers based in the EEA.\n\n🔒 SciStor (short for ‘Storage for Scientists’): This is storage hosted by IT for Research (ITvO) and allows for inexpensive storage of large volumes of data. There are various levels of security possible and various ways to get access to the files. SciStor is only intended for ongoing research, not for archiving.\nYoda (short for Your Data) is a cloud storage at SURF and is suitable for storing large-scale and sensitive datasets. Yoda also supports collaborating on projects in and outside VU Amsterdam and adding contextual information (metadata) about your dataset as you go. Yoda is usually the best choice if your research data are very sensitive.\n🔒 Research Drive is a cloud storage at SURF for research projects and is suitable for collaboration in and outside VU Amsterdam, for storing sensitive data and large-scale research projects. You are able to request storage space in Research Drive via a 🔒 web form in the selfservice portal (VU employees only). Research Drive is the best choice if you need to manage access rights on a folder level. SURF has general information about Research Drive, and you can find tutorials on the wiki pages.\n\nThere are differences between Research Drive and Yoda and each one may support certain projects better than others. The storage finder can help you to get an idea of what would be the best choice for your project, but get in touch with the RDM Support Desk for more details."
  },
  {
    "objectID": "topics/data-storage.html#sending-research-data-to-partners",
    "href": "topics/data-storage.html#sending-research-data-to-partners",
    "title": "Data Storage",
    "section": "Sending research data to partners",
    "text": "Sending research data to partners\nSome projects may require data sharing with partners. Although Research Drive and Yoda support sharing data all through the project, it may also be the case that some data only need to be sent to a partner once. There are some secure options to send data to research partners:\n\n🔒 Surf Filesender: cloud service that allows you to send files of 1 Terabyte to other researchers and encrypted files of up to 250 GB.\n🔒 Zivver: All employees of VU Amsterdam can use Zivver, the encryption programme that allows you to send email or data (sensitive or otherwise) securely by email. Attachments will also be encrypted and can be several Terabytes in size (max = 5 TB). Specific information on how to get and use Zivver are available on the selfservice portal. General explanations on how to use it are available at the Zivver website."
  },
  {
    "objectID": "topics/trainings.html",
    "href": "topics/trainings.html",
    "title": "Trainings",
    "section": "",
    "text": "It is easy to get overwhelmed with all the trainings available. On this page we provide a list of trainings available."
  },
  {
    "objectID": "topics/trainings.html#bytes-and-bites",
    "href": "topics/trainings.html#bytes-and-bites",
    "title": "Trainings",
    "section": "Bytes and Bites",
    "text": "Bytes and Bites\nDo you want to meet other researchers, improve your programming skills, or ask questions related to programming? Pick up your laptop and come to Bytes & Bites. We’re back in full swing for another edition of our coding cafe Bytes & Bites. At Bytes & Bites anyone is welcome, whether you are a beginner or advanced programmer, whether you write in R or in C++. And of course, you can’t program and work with “Bytes” without any tasty “Bites”! We’ll make sure there is pizza or snacks available!\n\n\nMore information: https://ubvu.github.io/bytes-and-bites/\nTopics: Programming, Python, R, Community, Software, Coding\nTarget audience: Students, researchers, data stewards\nStatus: Monthly\nDuration: 120 minutes\nOnline/in-person: In-person"
  },
  {
    "objectID": "topics/trainings.html#data-analysis-with-r-data-carpentry-workshop-for-programming-beginners",
    "href": "topics/trainings.html#data-analysis-with-r-data-carpentry-workshop-for-programming-beginners",
    "title": "Trainings",
    "section": "Data Analysis with R — Data Carpentry workshop for programming beginners",
    "text": "Data Analysis with R — Data Carpentry workshop for programming beginners\nAre you analysing tabular data in your research? Would you like to learn how to use the programming language R to make your work more effective and efficient? This workshop is for absolute programming beginners and introduces basic steps for the analysis and visualization of tabular data with R Studio. You will:\n\nOrganize tabular data, handle date formatting, carry out quality control and quality assurance and export data to use with downstream applications.\nExplore, summarize, and clean tabular data reproducibly.\nImport data, calculate summary statistics, and create publication-quality graphics using the programming language R\n\n\n\nRegistration form: https://vu-nl.libcal.com/calendar/universitylibrary?t=g&q=data%20carpentry&cid=7052&cal=7052&inc=0\nTraining materials: https://datacarpentry.org/lessons/#social-science-curriculum\nTopics: Software skills, Data analysis, Plotting, R, OpenRefine, Spreadsheets\nTarget audience: Researchers, students\nStatus: Available on set moments\nDuration: 28 hours over four days\nOnline/in-person: In-person and online (self-study)"
  },
  {
    "objectID": "topics/trainings.html#escape-room-data-horror",
    "href": "topics/trainings.html#escape-room-data-horror",
    "title": "Trainings",
    "section": "Escape Room: Data Horror",
    "text": "Escape Room: Data Horror\nResolve the data horror of professor Hutseephluts and secure the grant! This online escape room challenges everyone to tackle the horrors of research data management. Will you be able to escape within an hour?\nThe Data Horror Escape Room was made for the Data Horror week 2020.\n\n\nTraining materials: https://doi.org/10.5281/zenodo.6949510\nLicence: CC-BY-SA-4.0\nTopics: Research data, Escape room, Workshop, Data management, Research data management, FAIR\nTarget audience: Students, researchers, data stewards\nStatus: Active\nDuration: 60 minutes\nOnline/in-person: Online"
  },
  {
    "objectID": "topics/trainings.html#escape-room-open-science-horror",
    "href": "topics/trainings.html#escape-room-open-science-horror",
    "title": "Trainings",
    "section": "Escape Room: Open Science Horror",
    "text": "Escape Room: Open Science Horror\nHelp the cyborgs by publishing their code the right way — the open science way! This online escape room challenges everyone to tackle the horrors of open science and open access publishing. Will you be able to save the cyborgs and finally get a coffee?\nThe Open Science Horror Escape Room was made for the Data Horror week 2021.\n\n\nTraining materials: https://doi.org/10.5281/zenodo.6963493\nLicence: CC-BY-4.0\nTopics: Open science, Escape room, Workshop, Open access, Research data management, FAIR\nTarget audience: Students, researchers, data stewards\nStatus: Active\nDuration: 30-60 minutes\nOnline/in-person: Online"
  },
  {
    "objectID": "topics/trainings.html#escape-room-software-horror",
    "href": "topics/trainings.html#escape-room-software-horror",
    "title": "Trainings",
    "section": "Escape Room: Software Horror",
    "text": "Escape Room: Software Horror\nThe only thing between you and certain doom — getting your software management in order! This online escape room challenges everyone to tackle the horrors of software management and open software publishing. Will you be able to save your own soul and publish in Frontiers in Hell?\nThe Software Horror Escape Room was made for the Data Horror week 2022.\n\n\nTraining materials: https://doi.org/10.5281/zenodo.7350527\nLicence: CC-BY-4.0\nTopics: Software management, Escape room, Workshop, Software, Research data management, FAIR,\nTarget audience: Students, researchers, data stewards\nStatus: Active\nDuration: 60 minutes\nOnline/in-person: Online"
  },
  {
    "objectID": "topics/trainings.html#lego-workshop",
    "href": "topics/trainings.html#lego-workshop",
    "title": "Trainings",
    "section": "Lego Workshop",
    "text": "Lego Workshop\nThis workshop offers a hands-on experience in the importance of careful documentation during research. Participants will discover the pitfalls in communicating research progress through written media. This offers a fun introduction in writing well structured contextual metadata such as research logs, protocols, machine settings and general README files.\nThe data package offers a powerpoint and general guidelines in hosting the workshop.\n\n\nTraining materials: https://doi.org/10.5281/zenodo.10174000\nLicence: CC-BY-4.0\nTopics: Metadata, Contextual metadata, LEGO, Workshop\nTarget audience: Researchers\nStatus: Active\nDuration: 30-90 minutes\nOnline/in-person: In-person"
  },
  {
    "objectID": "topics/trainings.html#open-science-framework-osf-workshop",
    "href": "topics/trainings.html#open-science-framework-osf-workshop",
    "title": "Trainings",
    "section": "Open Science Framework (OSF) Workshop",
    "text": "Open Science Framework (OSF) Workshop\nThis is a hands-on course to get started with the Open Science Framework (OSF). You won’t need any experience with the tool beforehand. We will show the differences and similarities between OSF and other tools at VU Amsterdam (such as Yoda). We will make a preregistration of a (mock) OSF research.\nThe OSF is an open-source project management tool that supports researchers throughout their entire project life cycle. As a collaboration tool, OSF helps research teams work on projects privately or make the whole project publicly accessible for broad dissemination. As a workflow system, OSF enables connections to the many scientific tools researchers already use, streamlining their process and increasing efficiency. You may even use OSF as a portfolio tool for sharing your work as a prepublication with potential collaborators.\n\n\nTraining materials: https://osf.io/ab923/\nTopics: OSF, Preprint, Publishing, Archiving, RDM tools, Data management\nTarget audience: Students, researchers, data stewards\nStatus: Bi-annually during the Support Training Days\nDuration: 120 minutes\nOnline/in-person: Online"
  },
  {
    "objectID": "topics/trainings.html#open-science-against-humanity",
    "href": "topics/trainings.html#open-science-against-humanity",
    "title": "Trainings",
    "section": "Open Science against Humanity",
    "text": "Open Science against Humanity\nThis card game is based on “Cards Against Humanity” and teaches basic concepts of Open Science, Research Data Management, Software Management, FAIR principles, and Research Ethics in a fun and entertaining way. The white cards describe research related situations or statements relevant for researchers. The black cards contain potential answers or prompts that have a connection to Open Science. The goal of the game is to pair the white cards (prompts) and the black cards in the funniest, most provocative, or smartest way you can. Playing the card game online or with a physical deck creates awareness of issues around resesarch practices and allows for discussions around Open Science.\n\n\nTraining materials: https://doi.org/10.5281/zenodo.10017280\nLicence: CC-BY-4.0\nTopics: Open science, Card game, Workshop, Game, Research data management, FAIR, Software management\nTarget audience: Students, researchers, data stewards\nStatus: Active\nDuration: 30-60 minutes\nOnline/in-person: Online and in-person"
  },
  {
    "objectID": "topics/trainings.html#open-loves-science",
    "href": "topics/trainings.html#open-loves-science",
    "title": "Trainings",
    "section": "Open loves Science",
    "text": "Open loves Science\nOpen Science aims to improve, streamline and elevate science to something bigger. Why? Out of love for science of course!\nIn Open loves Science, players are invited to engage in playful and deep conversations about Open Science. The card game features an encyclopedia of issues that pervade this movement of research reform and ask participants to consider their role and values in changing academic culture. Like Open Science, this game is about connection. Players are meant to look into each other’s eyes, engage in conversation, and better understand one another.\n“Open loves Science” was made for the Data love week 2024.\n\n\nTraining materials: https://nlesc.github.io/open-loves-science/\nLicence: CC-BY-4.0\nTopics: Open science, Card game, Workshop, Game, Research data management, FAIR, Software management\nTarget audience: Students, researchers, data stewards\nStatus: Active\nDuration: 30-60 minutes\nOnline/in-person: Online and in-person"
  },
  {
    "objectID": "topics/trainings.html#software-carpentries",
    "href": "topics/trainings.html#software-carpentries",
    "title": "Trainings",
    "section": "Software Carpentries",
    "text": "Software Carpentries\nThe Software Carpentries are hands-on workshops that teach basic skills needed to program in a reproducible way.\nA Software Carpentry workshop covers lessons on:\n\nPlotting and Programming in Python or R\nThe Unix Shell\nVersion Control with Git and GitHub\n\nThe lessons are designed for programming beginners and do not require any experience. You program along, learn by helping one another, and apply what you have learned in exercises.\n\n\nRegistration form: https://vu-nl.libcal.com/calendar/universitylibrary?t=g&q=software%20carpentry&cid=7052&cal=7052&inc=0\nTraining materials: https://software-carpentry.org/lessons/\nTopics: Coding, Software skills, Python, R, Bash, Unix Shell, Git, GitHub, Version control\nTarget audience: Researchers, students\nStatus: Available on set moments\nDuration: 28 hours over four days\nOnline/in-person: In-person and online (self-study)"
  },
  {
    "objectID": "topics/trainings.html#writing-a-data-management-plan",
    "href": "topics/trainings.html#writing-a-data-management-plan",
    "title": "Trainings",
    "section": "Writing a Data Management Plan",
    "text": "Writing a Data Management Plan\nIn this course you learn how you write a good Data Management Plan (DMP) for your research project. The course is aimed at PhD students at the beginning of their research project.\nThe course consists of 2 workshops (either in person or online) and an online peer review session. In preparation for the workshops, you are requested to study some materials. You will do three assignments (RDM Framework, First draft of DMP and Final DMP) and peer review one other participant’s DMP. You will receive a certificate worth 1 EC for this course if you successfully complete all mandatory components.\n\n\nRegistration form: https://vu-nl.libcal.com/calendar/universitylibrary?t=g&q=writing%20a%20data%20management%20plan&cid=7052&cal=7052&inc=0\nMore information: https://vu.nl/en/employee/university-library/course-for-phd-students-writing-a-data-management-plan\nTopics: Data Management Plan, data overview, legal and ethical requirements, data storage, data archiving and publishing, metadata and documentation\nTarget audience: Researchers, PhD\nStatus: Available on set moments\nDuration: 60 minutes\nOnline/in-person: In-person or online (see registration form for particular course)"
  },
  {
    "objectID": "topics/finding-existing-software.html",
    "href": "topics/finding-existing-software.html",
    "title": "Finding Existing Research Software",
    "section": "",
    "text": "Depending on your particular field of research, there may be research software available that can help you develop your research.\nThere is a lot of proprietary software which can be acquired through the VU. Proprietary software generally has strict constraints regarding further sharing and re-use of the software.\nOpen-source software allows you to use and build upon existing software available in a variety of programming languages and domains. Research software can be found through both generic and discipline-specific registries or catalogues.\nWhen re-using research software, you must comply to constraints imposed by the licence of that software. Technically, this means some familiarity is needed with the rules and regulations governing software copyright and intellectual property rights. Practically, you will need to be compatible with the licence’s terms and conditions.\nThe following scheme provides an overview of compatibility of commonly used software licences:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCombine with ↓\n\n\n\n\n\n\n\n\n\n\nOriginal →\n\nCC0\nMIT\nBSD\nApache\nGPL, AGPL, LGPL\nProprietary\n\n\n\nCCO\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nMIT\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nBSD\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nApache\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nGPL, AGPL, LGPL\nYES\nYES\nYES\nNO\nYES\nNO\n\n\n\nProprietary\nYES\nYES\nYES\nClaused\nNO\nDepends on licence\n\n\n\nA more complete list of open source licences with terms and conditions is available here.\nIXA can provide legal help with the re-use of software."
  },
  {
    "objectID": "topics/finding-existing-software.html#re-using-existing-software",
    "href": "topics/finding-existing-software.html#re-using-existing-software",
    "title": "Finding Existing Research Software",
    "section": "",
    "text": "Depending on your particular field of research, there may be research software available that can help you develop your research.\nThere is a lot of proprietary software which can be acquired through the VU. Proprietary software generally has strict constraints regarding further sharing and re-use of the software.\nOpen-source software allows you to use and build upon existing software available in a variety of programming languages and domains. Research software can be found through both generic and discipline-specific registries or catalogues.\nWhen re-using research software, you must comply to constraints imposed by the licence of that software. Technically, this means some familiarity is needed with the rules and regulations governing software copyright and intellectual property rights. Practically, you will need to be compatible with the licence’s terms and conditions.\nThe following scheme provides an overview of compatibility of commonly used software licences:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCombine with ↓\n\n\n\n\n\n\n\n\n\n\nOriginal →\n\nCC0\nMIT\nBSD\nApache\nGPL, AGPL, LGPL\nProprietary\n\n\n\nCCO\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nMIT\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nBSD\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nApache\nYES\nYES\nYES\nYES\nNO\nNO\n\n\n\nGPL, AGPL, LGPL\nYES\nYES\nYES\nNO\nYES\nNO\n\n\n\nProprietary\nYES\nYES\nYES\nClaused\nNO\nDepends on licence\n\n\n\nA more complete list of open source licences with terms and conditions is available here.\nIXA can provide legal help with the re-use of software."
  },
  {
    "objectID": "topics/finding-existing-software.html#finding-existing-research-software",
    "href": "topics/finding-existing-software.html#finding-existing-research-software",
    "title": "Finding Existing Research Software",
    "section": "Finding Existing Research Software",
    "text": "Finding Existing Research Software\nThere is a large growth in the number of available open source research software. Many registries (also known as catalogues or “yellow pages”) are available to find existing research software. For example, PyPI (for python), CRAN (for R), Research Software Directory (generic).\nAn extensive list of research software registries is maintained by the eScience Center here."
  },
  {
    "objectID": "topics/open-science.html",
    "href": "topics/open-science.html",
    "title": "Open Science",
    "section": "",
    "text": "UNESCO defines Open Science as\n\na set of principles and practices that aim to make scientific research from all fields accessible to everyone for the benefits of scientists and society as a whole. Open science is about making sure not only that scientific knowledge is accessible but also that the production of that knowledge itself is inclusive, equitable and sustainable\n\nThis includes making openly available research data, methods, and documentation where possible. As such, the practices outlined in the VU CS Department RDM and Open Science Handbook are a precondition of Open Science.\nMore information about how researchers can practice Open Science at VU Amsterdam is available on the VU page about Open Science. The VU Open Access Policy and more information about different ways of open access publishing and how VU Amsterdam supports those, can be found on the VU Open Access page.\nYou can read more about Open Science in the Netherlands on the website of the Nationaal Programma Open Science. If you are interested in learning more about Open Science or if you are looking for ways to make your research more open and transparent, you can join the Open Science Community Amsterdam, the community of VU employees and students interested in Open Science (joint with the University of Amsterdam and Amsterdam University of Applied Sciences)."
  },
  {
    "objectID": "topics/scistor.html",
    "href": "topics/scistor.html",
    "title": "SciStor",
    "section": "",
    "text": "The storage service SciStor is intended for cheaply storing large amounts of research data.\nSciStor is hosted by IT for Research (ITvO) on the VU campus enabling a high-speed connection to lab equipment, laptops and workstations, the BAZIS HPC cluster and SciCloud. It can also be accessed off-campus.\nYour data is stored in a share, basically a folder with group-based access rights (read/write or read-only). Access rights can be set one level deep, so one share could be used to host data from different projects.\nIf desired, automatic backups can be made of the data."
  },
  {
    "objectID": "topics/scistor.html#what-is-it",
    "href": "topics/scistor.html#what-is-it",
    "title": "SciStor",
    "section": "",
    "text": "The storage service SciStor is intended for cheaply storing large amounts of research data.\nSciStor is hosted by IT for Research (ITvO) on the VU campus enabling a high-speed connection to lab equipment, laptops and workstations, the BAZIS HPC cluster and SciCloud. It can also be accessed off-campus.\nYour data is stored in a share, basically a folder with group-based access rights (read/write or read-only). Access rights can be set one level deep, so one share could be used to host data from different projects.\nIf desired, automatic backups can be made of the data."
  },
  {
    "objectID": "topics/scistor.html#what-can-it-be-used-for",
    "href": "topics/scistor.html#what-can-it-be-used-for",
    "title": "SciStor",
    "section": "What can it be used for?",
    "text": "What can it be used for?\n\nNetworked Drive\nBecause SciStor is connected to the VU on-campus network you can directly mount (map a network drive) SciStor shares on your laptop and work as if the data is on a local disk.\n\n\nAccess off-campus\nAlthough SciStor is most useful on campus you can also access your shares off-campus.\n\n\nLab instruments\nIn many cases lab equipment can write data directly to SciStor. IT for Research can help you setup an automated and secure connection.\n\n\nStorage space for SciCloud servers\nSciCloud virtual servers are provisioned with a 20 to 50GB local disk. A SciStor share can be directly mounted on the server to increase storage for your application or directly access your source data for analysis.\n\n\nBAZIS\nThe BAZIS HPC cluster is connected to SciStor via a high speed netwodrk. You can run your analysis software directly on your data and easily access the results on your laptop.\n\n\nSharing data\nBecause SciStor is mainly intended for high performance, on-campus use, access is only possible with a VUnetId. If you need to share data with non-VU researchers you could register them as an external employee or host a copy of the data on another storage platform like Research Drive or Yoda\n\n\nData life-cycle\nSciStor is meant for data you are actively working with. We recommend archiving datasets that are no langer actively used, but can’t be deleted, in Yoda. This ensures SciStor is used optimally and costs are kept down for your research group and the VU."
  },
  {
    "objectID": "topics/scistor.html#how-to-request-access",
    "href": "topics/scistor.html#how-to-request-access",
    "title": "SciStor",
    "section": "How to request access",
    "text": "How to request access\n\nRequesting a new share\nSciStor is available for all VU research groups. You can find the request form on 🔒 ServiceNow, go to: IT &gt; My work field &gt; Research &gt; SciStor &gt; Realisation of new storage for research (SciStor)\nMinimum storage space that can be requested is 100 GB, for a minimum of three months. The capacity can be increased or decreased in units of 100 GB if needed.\nAfter submitting the application, IT for Research will contact you to schedule an interview to discuss naming the SciStor share, how the backups work, who should have access, etc.\nMost SciStor configurations can be delivered within one or two days. More complex configurations may take a little longer.\n\n\nAdding a colleague to an existing share\nThe owner of a SciStor share can request to add or remove access to the share via 🔒 ServiceNow, go to: IT &gt; My work field &gt; Research &gt; SciStor &gt; Change SciStor access rights"
  },
  {
    "objectID": "topics/scistor.html#are-there-costs-involved",
    "href": "topics/scistor.html#are-there-costs-involved",
    "title": "SciStor",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nYou pay for the amount of space reserved for your share: €0,10 per GB per year without backup or €0,20 per GB per year with backup. Note that without backup data will be lost in case of accidental deletion or major problems with the SciStor infrastructure.\nThe owner of the SciStor share receives monthly usage reports. The report provides insight on used and available space.\n\nBackups\nThere are two type of flavours when it comes to data protection within SciStor.\n\n\n\n\n\n\n\nSnapshots\nBackups\n\n\n\n\n“Photo moments” of your data stored within the same location storage\nComplete copy stored in a different physical location\n\n\nDefault Policies within ITvO: a) Daily snapshots kept for 1 week (1d:1w) b) Weekly snapshots kept for 4 weeks (1w:4w)\nAutomatic daily backups around midnight\n\n\nCustom policies available upon request\nInvisible to users - runs in the background\n\n\nNo additional storage costs\nAdditional Costs: Doubles the storage costs\n\n\n\nThe ITvO team recommend having both ways activated for complete data protection."
  },
  {
    "objectID": "topics/scistor.html#getting-started",
    "href": "topics/scistor.html#getting-started",
    "title": "SciStor",
    "section": "Getting started",
    "text": "Getting started\n\nOn-campus access\n\nMacOS\n\nOpen the Finder application\nIn the “Go” menu, pick “Connect to Server…” or press “⌘K”\nFill in: smb://scistor.vu.nl/shares\nClick “Connect”\nSelect “Registered User” if this is not yet selected\nFill in your VUnetID and password\nPress “Connect”. Optionally, tick the “Remember this password in my keychain” checkbox. After doing this, macOS will no longer ask for credentials the next time this connection is used.\n\nSciStor shares appear on the left after opening the SciStor location. You may open the desired SciStor share by double-clicking it.\n\n\nWindows\n\nOpen Windows File Explorer\nRight-click on This PC and choose “Map network drive…””\nSelect a desired drive letter, for example S. In the Folder field you can enter the following: \\\\scistor.vu.nl\\shares\\&lt;the name of the share folder&gt;. Make sure the checkboxes are checked.\nClick “Finish”\nYou will now be asked to log in. This is not possible with your PIN code. Choose the “More choices” option, and log in with your VU email address and password\n\n\n\n‘Green’ Linux workspaces\nGreen Linux workplaces (supported by VU IT) have a connection to SciStor from home. All SciStor shares can be found under the path /research.\n\n\nOther Linux workstations\nOther self-managed Linux workstations can also connect to SciStor.\nVia the SFTP protocol: SciStor with the SFTP protocol can be used via the server sftp.data.vu.nl. Find the shares under the path /research.\nYou can do as follows:\n$ ssh &lt;vunetID&gt;@sftp.data.vu.nl # this will ask your vunet password\n$ cd /research/&lt;name-of-scitstor-share&gt;\nTo to connect to SciStor using samba protocol, you can do as follows:\n$ sudo apt install cifs-utils\n$ sudo nano /etc/credentials/&lt;vunetID&gt;\n    # nano\nusername=&lt;vumail@vu.nl&gt;\npassword=&lt;your-vunet-password&gt;\n$ sudo mkdir /data/VU/shares/&lt;name-of-your-share&gt; \n$ sudo mount -t cifs //scistor.vu.nl/shares/&lt;name-of-your-share&gt; /data/VU/shares/&lt;name-of-your-share&gt; -o credentials=/etc/credentials/&lt;vunetID&gt;\nThe scistor share will be mounted at location: /data/VU/shares. To unmount it, simply do:\n$ sudo umount /data/VU/shares/&lt;name-of-your-share&gt;\n\n\n\n\nOff-campus access\n\neduVPN\nThe easiest way is to install the app for eduVPN institute access. Once the VPN is active you can follow the “on-campus access” steps above. Note that performance over the internet is limited, you might run into problems when editing large files. If needed copy them to you local disk.\n\n\nSFTP\nOn windows you can use a free tool like WinSCP or CyberDuck to access your data via the SFTP protocol. The server URL is sftp.data.vu.nl, find the shares under the path /research.\nOn a Mac you can connect via the IT supported 🔒 Expandrive (follow the SFTP instructions).\nThe configuration is as follows:\n\n\n\nItem\nValue\n\n\n\n\nHost\nssh.data.vu.nl OR sftp.data.vu.nl\n\n\nProtocol\nSFTP\n\n\nPort\n22\n\n\nUsername\nYour VUnetID\n\n\nPassword\nYour VUnet password\n\n\n\nLinux users outside campus can follow the previous SFTP explanation."
  },
  {
    "objectID": "topics/scistor.html#contact",
    "href": "topics/scistor.html#contact",
    "title": "SciStor",
    "section": "Contact",
    "text": "Contact\nWondering if SciStor fits your research needs? Please contact IT for Research"
  },
  {
    "objectID": "topics/yoda.html",
    "href": "topics/yoda.html",
    "title": "Yoda",
    "section": "",
    "text": "Yoda is an application for institutions that supports Research Data Management (RDM) throughout the entire research cycle: from the safe and easy storage and sharing of data during the research process, to the sharing of data within research collaborations and ultimately to research data archiving and publication.\n\nYoda helps the researcher make their data “FAIR” by providing a solution that enables data discovery and sharing (i.e., findable, accessible). In addition, it facilitates the use of metadata, contributing to data interoperability and reusability. Yoda provides a platform for the implementation of standard workflows that can ensure metadata quality satisfying VU policy requirements for data archiving and publication. In addition, Yoda is built on iRODS so it accommodates both researchers with data heavy requirements, as well as those seeking an accessible, user-friendly solution.\nYoda presents researchers a comfortable, easy-to-use solution for securely storing, sharing and organising their research data that follows the internationally adopted FAIR data principles. Many research institutions and funding organisations (such as NWO and ZonMw) require researchers to make their data FAIR.\nProject space in Yoda is basically a folder with group based access rights. Access restrictions are only set on the top level, meaning you need one Project Space per research project.\nYoda is open source software developed and maintained by Utrecht University for the Yoda Consortium (VU, Wageningen University, Erasmus University, Amsterdam UMC, Utrecht University and SURF). Yoda is hosted by SURF in their Amsterdam datacentre."
  },
  {
    "objectID": "topics/yoda.html#what-is-it",
    "href": "topics/yoda.html#what-is-it",
    "title": "Yoda",
    "section": "",
    "text": "Yoda is an application for institutions that supports Research Data Management (RDM) throughout the entire research cycle: from the safe and easy storage and sharing of data during the research process, to the sharing of data within research collaborations and ultimately to research data archiving and publication.\n\nYoda helps the researcher make their data “FAIR” by providing a solution that enables data discovery and sharing (i.e., findable, accessible). In addition, it facilitates the use of metadata, contributing to data interoperability and reusability. Yoda provides a platform for the implementation of standard workflows that can ensure metadata quality satisfying VU policy requirements for data archiving and publication. In addition, Yoda is built on iRODS so it accommodates both researchers with data heavy requirements, as well as those seeking an accessible, user-friendly solution.\nYoda presents researchers a comfortable, easy-to-use solution for securely storing, sharing and organising their research data that follows the internationally adopted FAIR data principles. Many research institutions and funding organisations (such as NWO and ZonMw) require researchers to make their data FAIR.\nProject space in Yoda is basically a folder with group based access rights. Access restrictions are only set on the top level, meaning you need one Project Space per research project.\nYoda is open source software developed and maintained by Utrecht University for the Yoda Consortium (VU, Wageningen University, Erasmus University, Amsterdam UMC, Utrecht University and SURF). Yoda is hosted by SURF in their Amsterdam datacentre."
  },
  {
    "objectID": "topics/yoda.html#what-can-it-be-used-for",
    "href": "topics/yoda.html#what-can-it-be-used-for",
    "title": "Yoda",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nThe particular strength of Yoda lies in the fact that it is an all-in-one solution for managing your data during and after your project. It makes it easy to share and organise your data and add descriptive metadata at any moment. If (part of) your datasets needs to be published during or after your project, this can be done by a few simple steps within Yoda itself. There is no need to upload your data to another platform.\n\nData storage\nYoda is a Cloud storage solution that can be used for small to very large datasets. The underlying iRODS software ensures data integrity. Data in Yoda is backed up daily.\n\n\nData sharing\nOnce a new Yoda group has been created you can invite collaborators yourself. Researchers from national and international research institutes can login with their institutional account via SURF Research Access Management (SRAM). Collaborators from non-research institutes can create a free EduID NL account.\n\n\nSensitive data\nThe use of Multi-Factor Authentication (MFA) with SRAM and hosting at SURF ensure, among other things, Yoda is suitable for the storage and sharing of data that score High on confidentiality in a data classification (see the Policy Classification of Research Data and the Research Data Classification Tool). Please make sure to contact the RDM Support Desk to check if further measures are needed.\n\n\nMetadata\nAt any moment you can add descriptive metadata to a folder in Yoda via a web form. This means you can easily organize your data in such a way that it is not only ready for archiving and publishing but also findable for your collaborators.\n\n\nArchiving\nAt any moment you can submit a data folder with metadata for Archiving in the Yoda Vault. Data in the Vault is read-only and cannot be deleted. To help make sure the dataset is suitable for archiving a Yoda datamanager (usually a data manager from your department or a faculty data steward) will review your submission before final approval. Data in the Vault is directly accessible for your collaborators. Access for the Yoda datamanager role ensures the data remains accessible on the long term.\n\n\nPublishing metadata and data\nFrom the Yoda Vault you can submit the dataset for publication. A DOI will be generated and registered with DataCite together with the metadata. DataCite ensures your dataset becomes findable on the internet and citable.\nThe DOI link will lead to a landing page in Yoda showing the metadata. The dataset itself can be Open, allowing direct download, Restricted, meaning other researchers need to follow a data request procedure, or Closed, signalling the dataset is properly archived but not available for reuse.\n\n\nAutomated workflows\nSince Yoda is build on iRODS you could also build (automated) ingest and analysis workflows using iRODS Rules and Policies. Please contact IT for Research if you need assistance."
  },
  {
    "objectID": "topics/yoda.html#how-to-request-access",
    "href": "topics/yoda.html#how-to-request-access",
    "title": "Yoda",
    "section": "How to request access",
    "text": "How to request access\nYoda is available for every VU researcher. If you need space to store data for your research project, you can request it via the linked form.\nOnce the project space has been created you can start to invite your collaborators yourself. Note that VU students must 🔒 connect a token to SURFsecureID to be able to log in."
  },
  {
    "objectID": "topics/yoda.html#are-there-costs-involved",
    "href": "topics/yoda.html#are-there-costs-involved",
    "title": "Yoda",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThe costs of storing data in Yoda are detailed on the 🔒 VU website."
  },
  {
    "objectID": "topics/yoda.html#getting-started",
    "href": "topics/yoda.html#getting-started",
    "title": "Yoda",
    "section": "Getting Started",
    "text": "Getting Started\nThe VU Yoda website has practical information on the use of the Yoda for users starting with Yoda.\nMore information can be found on the SURF User Knowledge base.\nThe Yoda site of Utrecht University also contains useful information and is being redeveloped so it can also be used by VU Amsterdam and the other Consortium Partners."
  },
  {
    "objectID": "topics/yoda.html#contact",
    "href": "topics/yoda.html#contact",
    "title": "Yoda",
    "section": "Contact",
    "text": "Contact\nWondering if Yoda fits your research needs? Please contact the RDM support desk."
  },
  {
    "objectID": "topics/data-protection.html",
    "href": "topics/data-protection.html",
    "title": "Data Protection",
    "section": "",
    "text": "Protection from what? From whom? When, and why? Before we talk about data protection, let us consider security first. More often than not, ‘security’ is regarded as a fixed state. In reality, security is an assessment of the level of protection against a certain threat, that you consider to deal with that threat adequately enough. Whether or not security is accurate depends on the value of the data and the quality of protective measures.\nThe question for you as a researcher is ‘when are the measures that you take secure enough?’. In order to answer this, please be aware that there are three entities that have an opinion about what is ‘secure enough’, namely: the law, the University, and you yourself as the data processor.\nThe University has a Security Baseline that sets a norm for levels of protection for every application it uses. The Baseline is based on international standards. For each of these applications, the University is considering for which means the security of these applications are adequate enough.\nThe legal requirements for the processing of personal data can be found in the section ‘GDPR and Privacy’ under Plan & Design There are additional laws and regulations as well. The assumption is that you are familiar with these, especially with laws regulating medical and criminal research.\nWhat you personally consider to be secure might be very different from what your colleagues, the Faculty or the University considers to be secure enough and the norms will vary with the variety of data that is being processed by different researchers and Faculties of VU Amsterdam. Very generally speaking, there are three points of protection to consider:\n\nProtection against data loss, for which you need a back up periodically.\nProtection against data leakage, for which you need to consider all storage places and their access points.\nProtection of data integrity, for which you need version control and synchronisation management.\n\nThe security of your protection measures depends on the threat you face. We often think of threats as active, and motivated by bad intentions. But most common forms of data loss are accidental and most leakage is caused by trusting others. In reality, devices just get lost or break down, people download malware by accident, and each one of us forgets to save a document at times or gets confused about which version was last updated.\nIn all cases, protection starts with oversight on where your data is stored and processed. If you forget that you temporarily stored it in a certain place, you have then lost oversight of where that data is. The opposite is also true: if you know where you data is, you have insight in the level of security of the space in which you store it. As you can see, protection begins with organising your work in a reliable manner and thinking through your steps.\nFor example, if you data is on your laptop and synchronised with your phone, then it is stored in two places. Perhaps this is enough back up, perhaps not. If you put both you devices in the same bag and you lose your bag, you have no backup. A backup to an online storage might be a good solution, but might also mean your data leaks via the internet of via the storage provider who sells the data and your behavioural data for profit. Most importantly, there is no absolute security. It is best if you consider your personal behaviour and then think of scenarios that are more or less likely to happen and what would impact you most. If you frequently work in public places you should make it a habit to lock your device each time you leave it. If you eat and drink behind your desk often, better work with a remote keyboard to protect your laptop from the unavoidable coffee shower. Do you save your respondents’ contact details on your personal phone? Then protect it with a pin.\nHere are some basic protection guidelines:\n\nData are very difficult to erase. You have probably never done it.\nDecide how to back up data and test it before you rely on it.\nDo not give others your log-in credentials. If you have done so and your family members use your work device, then change it.\nDo not use passwords twice, do not use your birthday, initials, streetname, hobby.\nEncryption sounds secure, but it fails completely without good password management."
  },
  {
    "objectID": "topics/data-protection.html#what-is-data-protection",
    "href": "topics/data-protection.html#what-is-data-protection",
    "title": "Data Protection",
    "section": "",
    "text": "Protection from what? From whom? When, and why? Before we talk about data protection, let us consider security first. More often than not, ‘security’ is regarded as a fixed state. In reality, security is an assessment of the level of protection against a certain threat, that you consider to deal with that threat adequately enough. Whether or not security is accurate depends on the value of the data and the quality of protective measures.\nThe question for you as a researcher is ‘when are the measures that you take secure enough?’. In order to answer this, please be aware that there are three entities that have an opinion about what is ‘secure enough’, namely: the law, the University, and you yourself as the data processor.\nThe University has a Security Baseline that sets a norm for levels of protection for every application it uses. The Baseline is based on international standards. For each of these applications, the University is considering for which means the security of these applications are adequate enough.\nThe legal requirements for the processing of personal data can be found in the section ‘GDPR and Privacy’ under Plan & Design There are additional laws and regulations as well. The assumption is that you are familiar with these, especially with laws regulating medical and criminal research.\nWhat you personally consider to be secure might be very different from what your colleagues, the Faculty or the University considers to be secure enough and the norms will vary with the variety of data that is being processed by different researchers and Faculties of VU Amsterdam. Very generally speaking, there are three points of protection to consider:\n\nProtection against data loss, for which you need a back up periodically.\nProtection against data leakage, for which you need to consider all storage places and their access points.\nProtection of data integrity, for which you need version control and synchronisation management.\n\nThe security of your protection measures depends on the threat you face. We often think of threats as active, and motivated by bad intentions. But most common forms of data loss are accidental and most leakage is caused by trusting others. In reality, devices just get lost or break down, people download malware by accident, and each one of us forgets to save a document at times or gets confused about which version was last updated.\nIn all cases, protection starts with oversight on where your data is stored and processed. If you forget that you temporarily stored it in a certain place, you have then lost oversight of where that data is. The opposite is also true: if you know where you data is, you have insight in the level of security of the space in which you store it. As you can see, protection begins with organising your work in a reliable manner and thinking through your steps.\nFor example, if you data is on your laptop and synchronised with your phone, then it is stored in two places. Perhaps this is enough back up, perhaps not. If you put both you devices in the same bag and you lose your bag, you have no backup. A backup to an online storage might be a good solution, but might also mean your data leaks via the internet of via the storage provider who sells the data and your behavioural data for profit. Most importantly, there is no absolute security. It is best if you consider your personal behaviour and then think of scenarios that are more or less likely to happen and what would impact you most. If you frequently work in public places you should make it a habit to lock your device each time you leave it. If you eat and drink behind your desk often, better work with a remote keyboard to protect your laptop from the unavoidable coffee shower. Do you save your respondents’ contact details on your personal phone? Then protect it with a pin.\nHere are some basic protection guidelines:\n\nData are very difficult to erase. You have probably never done it.\nDecide how to back up data and test it before you rely on it.\nDo not give others your log-in credentials. If you have done so and your family members use your work device, then change it.\nDo not use passwords twice, do not use your birthday, initials, streetname, hobby.\nEncryption sounds secure, but it fails completely without good password management."
  },
  {
    "objectID": "topics/data-protection.html#data-protection",
    "href": "topics/data-protection.html#data-protection",
    "title": "Data Protection",
    "section": "Data Protection",
    "text": "Data Protection\nThere can be many reasons why the data of a project needs to be kept protected:\n\nSensitivity of the data collected\nProtection of the research data from competition\nCommercial reasons / Intellectual property\nEtc.\n\n\n\n\nAn image of a lock composed of code in a matrix green style.\n\n\nThere are also many levels of security that may be implemented, depending on the needs. Sometimes it will be enough to use a password-protected cloud-based server. In extreme cases encryption may be needed and also when data is transmitted between researchers or organisations. You should contact the RDM Support Desk to discuss available options, who may connect you to legal experts where sensitive data is concerned. Check the Data Storage topic for links to find out more on campus solutions and cloud-based options.\n\n\n\n\n\n\nTip\n\n\n\nSee also the Safe Data Transfer topic for more information on how to transport and transfer data."
  },
  {
    "objectID": "topics/academic-integrity.html",
    "href": "topics/academic-integrity.html",
    "title": "Academic Integrity",
    "section": "",
    "text": "Dutch scientists are required to comply with the Netherlands Code of Conduct for Research Integrity (VSNU, 2018). The principles of proper scientific and scholarly research, according to the Code of Conduct are:\n\nHonesty\nScrupulousness\nTransparency\nIndependence\nResponsibility\n\nThe principles of honesty and transparency state explicit guidelines for the way in which you treat your research data:\n\nHonesty: you should refrain from fabricating or falsifying data\nTransparency:\n\nYou should ensure that it is clear to others what data your research is based on, how the data were obtained, what the results are and how you got to these results\nAll steps in your research process must be verifiable (e.g. choice of research question, research design, methodology, sources used), so that it is clear to others how your research was conducted\n\n\nTo live up to these general principles, the Code of Conduct provides the following standards, which are addressed in a Data Management Plan (DMP), for good research practices related to data management:\n\nProvide a description of the way in which the collected research data are organised and classified, so that they can be verified and re-used (standard 3.2.10)\nMake research data public upon completion of your research project; if this is not possible, explain why (standards 3.2.11 and 3.4.45)\nDescribe the data you have collected and used in your research honestly, scrupulously and transparently (standard 3.3.23)\nManage your data carefully and store both the raw and processed versions for a period appropriate for your discipline (standard 3.3.24)\nContribute towards making data FAIR, where possible (standard 3.3.25)\nBe transparent about your methods and working procedures by using e.g. research protocols, logs, lab journals or reports to describe these processes (standard 3.4.35)"
  },
  {
    "objectID": "topics/academic-integrity.html#netherlands-code-of-conduct-for-research-integrity",
    "href": "topics/academic-integrity.html#netherlands-code-of-conduct-for-research-integrity",
    "title": "Academic Integrity",
    "section": "",
    "text": "Dutch scientists are required to comply with the Netherlands Code of Conduct for Research Integrity (VSNU, 2018). The principles of proper scientific and scholarly research, according to the Code of Conduct are:\n\nHonesty\nScrupulousness\nTransparency\nIndependence\nResponsibility\n\nThe principles of honesty and transparency state explicit guidelines for the way in which you treat your research data:\n\nHonesty: you should refrain from fabricating or falsifying data\nTransparency:\n\nYou should ensure that it is clear to others what data your research is based on, how the data were obtained, what the results are and how you got to these results\nAll steps in your research process must be verifiable (e.g. choice of research question, research design, methodology, sources used), so that it is clear to others how your research was conducted\n\n\nTo live up to these general principles, the Code of Conduct provides the following standards, which are addressed in a Data Management Plan (DMP), for good research practices related to data management:\n\nProvide a description of the way in which the collected research data are organised and classified, so that they can be verified and re-used (standard 3.2.10)\nMake research data public upon completion of your research project; if this is not possible, explain why (standards 3.2.11 and 3.4.45)\nDescribe the data you have collected and used in your research honestly, scrupulously and transparently (standard 3.3.23)\nManage your data carefully and store both the raw and processed versions for a period appropriate for your discipline (standard 3.3.24)\nContribute towards making data FAIR, where possible (standard 3.3.25)\nBe transparent about your methods and working procedures by using e.g. research protocols, logs, lab journals or reports to describe these processes (standard 3.4.35)"
  },
  {
    "objectID": "topics/academic-integrity.html#academic-integrity-at-vu-amsterdam",
    "href": "topics/academic-integrity.html#academic-integrity-at-vu-amsterdam",
    "title": "Academic Integrity",
    "section": "Academic integrity at VU Amsterdam",
    "text": "Academic integrity at VU Amsterdam\nTo protect academic integrity at VU Amsterdam and Amsterdam UMC (location VUmc) subscribe to the Netherlands Code of Conduct for Research Integrity. On the Academic Integrity page on the VU website, you can find more information about how these organisations implement the duties of care for institutions to uphold the principles of academic integrity.\n\nConfidential counsellors\nVU Amsterdam has a number of confidential counsellors who handle academic integrity issues.\n\n\nAcademic integrity complaints procedure\nVU Amsterdam and Amsterdam UMC, location VUmc employ a joint policy for the handling academic integrity complaints. This policy outlines the steps to be taken in the event of a complaint, the officers who play a role in this procedure, and what should be expected once a complaint has been lodged."
  },
  {
    "objectID": "topics/academic-integrity.html#rios-center-for-research-integrity-and-open-science",
    "href": "topics/academic-integrity.html#rios-center-for-research-integrity-and-open-science",
    "title": "Academic Integrity",
    "section": "RIOS: Center for Research Integrity and Open Science",
    "text": "RIOS: Center for Research Integrity and Open Science\nRIOS connects initiatives related to research integrity, research ethics, responsible research and innovation, open science, and research culture at VU Amsterdam and Amsterdam UMC. The mission of RIOS is to strengthen the position of VU Amsterdam and Amsterdam UMC regarding research integrity and open science."
  },
  {
    "objectID": "topics/fair-principles.html",
    "href": "topics/fair-principles.html",
    "title": "FAIR Principles",
    "section": "",
    "text": "This page discusses what the FAIR principles (Wilkinson et al. 2016) are, why they are important and how you can work in line with these principles at VU."
  },
  {
    "objectID": "topics/fair-principles.html#what-are-the-fair-principles",
    "href": "topics/fair-principles.html#what-are-the-fair-principles",
    "title": "FAIR Principles",
    "section": "What are the FAIR principles?",
    "text": "What are the FAIR principles?\nThe FAIR principles were formulated in 2016 to guide researchers in increasing the Findability, Accessibility, Interoperability and Reusability of their data (see the publication in the journal Scientific Data and the summary of the principles). The goal is to ensure that scholarly data can be used as widely as possible – accelerating scientific discoveries and benefiting society in the process.\nA lot of good resources exist already that explain the FAIR principles very well:\n\nGO FAIR provides a clear overview of the FAIR principles\nThe Turing Way has a great information page about FAIR, containing a lot of references to other useful sources\nThe story A FAIRy tale explains all principles in an understable way\n\nThe FAIR principles were rapidly adopted by Dutch and European funding agencies. If you receive a research grant from NWO, ZonMw, or the European Commission, you will be asked to make your data FAIR."
  },
  {
    "objectID": "topics/fair-principles.html#how-can-you-benefit-from-working-in-line-with-the-fair-principles",
    "href": "topics/fair-principles.html#how-can-you-benefit-from-working-in-line-with-the-fair-principles",
    "title": "FAIR Principles",
    "section": "How can you benefit from working in line with the FAIR principles?",
    "text": "How can you benefit from working in line with the FAIR principles?\nYou do not need to apply all FAIR principles at once to start benefiting from making your data FAIR. Applying even just some of the principles will increase the visibility and impact of your data, leading to:\n\nIncreased citations of the datasets themselves and your research\nImproved reproducibility of your research\nCompliance with funder and publisher requirements\n\nMaking your data FAIR will also make it possible for you to easily find, access and reuse your own data in the future. You may be the first and most important beneficiary of making your own data FAIR."
  },
  {
    "objectID": "topics/fair-principles.html#making-data-fair-how-to-get-started-in-three-easy-steps",
    "href": "topics/fair-principles.html#making-data-fair-how-to-get-started-in-three-easy-steps",
    "title": "FAIR Principles",
    "section": "Making data FAIR – how to get started in three easy steps?",
    "text": "Making data FAIR – how to get started in three easy steps?\n\nStart with a data management plan\nA DMP is a living document in which you specify what kinds of data you will use in your project, and how you will process, store and archive them. Preparing a data management plan should be your first step in the process to make data FAIR. The DMP template will ask questions that enable you to systematically address the things that need to be done to make your data FAIR. Writing a DMP is also a requirement from funding agencies and some faculties at VU Amsterdam. At VU Amsterdam, you can use DMPonline to create and share DMPs.\n\n\nDescribe and document your data\nTo be findable, data need to be described with appropriate metadata. Metadata can include keywords, references to related papers, the researchers’ ORCID identifiers, and the codes for the grants that supported the research. You will need to provide such metadata when you are uploading data to a repository (see below). You increase findability by filling out as many metadata fields as possible and by providing rich descriptions in terminology that is common in your field.\nTo be reusable, data need to be accompanied by documentation describing how the data was created, structured, processed, and so on. It is good practice to integrate writing documentation during the research process. It will be easier and take less time compared to when you try to do this at the end. Having documentation on the research process will also help you to redo parts of your data cleaning actions or data analysis if necessary.\nIf you have questions about metadata and documentation, contact the RDM Support Desk and we will be happy to help you and to provide advice.\n\n\nMake your data available through a trustworthy repository\nIf you choose a repository that: assigns a persistent identifier to both the data and the metadata; attaches metadata to the data according to standard metadata schemas; releases data with a license; and provides access to the data and metadata via an open and standard communication protocol (such as http) – then your data will meet many, if not most, of the FAIR principles.\nVU Amsterdam provides three repositories which meets all of these conditions:\n\nDataverseNL\nYoda - Yoda information page and Yoda publication platform\nOpen Science Framework (OSF)\n\nCosts for using these repositories for datasets up to 500 GB are covered by the faculty. There are costs involved for you department or project if a datasets is larger than 500 GB. See the storage cost model for details."
  },
  {
    "objectID": "topics/fair-principles.html#what-if-i-cannot-share-my-data",
    "href": "topics/fair-principles.html#what-if-i-cannot-share-my-data",
    "title": "FAIR Principles",
    "section": "What if I cannot share my data?",
    "text": "What if I cannot share my data?\nData do not need to be open to be FAIR. The FAIR principles allow for controlled access, which can be important for certain types of data, such as personal data, medical data, competitive company data. The guiding principle is always that data should be as “as open as possible, as closed as necessary”. If data cannot be openly shared, because they are too sensitive, then “the FAIR approach would be to make the metadata publicly available and provide information about the conditions for accessing the data itself.”"
  },
  {
    "objectID": "topics/researchcloud.html",
    "href": "topics/researchcloud.html",
    "title": "SURF Research Cloud",
    "section": "",
    "text": "SURF Research Cloud is a portal where you easily build a virtual research environment. You can use preconfigured workspaces and datasets or add them yourself. Institutions, research communities and suppliers can contribute to Research Cloud’s functionality and catalogue by integrating their computing and data services.\nSURF Research Cloud is hosted at the SURF datacenter in Amsterdam."
  },
  {
    "objectID": "topics/researchcloud.html#what-is-it",
    "href": "topics/researchcloud.html#what-is-it",
    "title": "SURF Research Cloud",
    "section": "",
    "text": "SURF Research Cloud is a portal where you easily build a virtual research environment. You can use preconfigured workspaces and datasets or add them yourself. Institutions, research communities and suppliers can contribute to Research Cloud’s functionality and catalogue by integrating their computing and data services.\nSURF Research Cloud is hosted at the SURF datacenter in Amsterdam."
  },
  {
    "objectID": "topics/researchcloud.html#what-can-it-be-used-for",
    "href": "topics/researchcloud.html#what-can-it-be-used-for",
    "title": "SURF Research Cloud",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nSURF Research Cloud enables you to run 1 or more servers with applications that can be accessible over the internet.\n\nHosting web applications, these can be connected to SRAM for secure authentication. You can easily start more servers to increase availability and preformance.\nRunning a desktop environment with analysis tools, use your favorite desktop tools on an environment with more performance. Unlike SciCloud GPU resources are available. You can easily connect an environment to your data on Research Drive or Yoda.\nHosting a highly secure research environment where sensitive data cannot leave the VRE: SURF SANE."
  },
  {
    "objectID": "topics/researchcloud.html#are-there-costs-involved",
    "href": "topics/researchcloud.html#are-there-costs-involved",
    "title": "SURF Research Cloud",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nYou will need to apply for a wallet with credits, see How to request access below.\nIn 2025 the credit cost is:\n\n1.03 credits per CPU hour (only if the system is active).\n21 credits per GPU hour (only if the system is active).\nHDD storage 681 credits per TB per month, SSD storage 1525 credits per TB per month.\n\nSee the SURF services and rates document."
  },
  {
    "objectID": "topics/researchcloud.html#how-to-request-access",
    "href": "topics/researchcloud.html#how-to-request-access",
    "title": "SURF Research Cloud",
    "section": "How to request access",
    "text": "How to request access\nAll VU researchers can get access to SURF Research Cloud. To start building an environment in Research Cloud you need 2 things:\n\n1. An SRAM Collaboration connected to Research Cloud\n\nFirst apply for a new SRAM Collaboration (CO): log in to SRAM and click the “Request collaboration” button.\nThe SRAM admins at IT for Research (ITvO) will contact you to discuss your specific needs and help you to get started.\nOnce the Collaboration request is approved you can connect the Research Cloud Application to the new collaboration.\nInvite the colleagues that need to work in your VRE to your new CO.\n\n\n\n2. A Wallet with credits\nThere are 2 ways to obtain credits:\n\nApply for a NWO Small Compute Grant by following the links on the Small Compute applications page. In the request form select “SURF Research Cloud - HPC Cloud”.\nIf for whatever reason your application for this grant is denied, you could also claim credits from VU Amsterdam Research Capacity Computing Service contract with SURF contract. Please contact IT for Research for details on how to obtain these credits.\n\nOnce the request is granted you will have access to a wallet in Research Cloud and can start to build an environment."
  },
  {
    "objectID": "topics/researchcloud.html#getting-started",
    "href": "topics/researchcloud.html#getting-started",
    "title": "SURF Research Cloud",
    "section": "Getting started",
    "text": "Getting started\nDocumentation for Research Cloud can be found on the SURF User Knowledge Base.\nIT for Research can assist you in setting up a new Research Cloud environment."
  },
  {
    "objectID": "topics/researchcloud.html#contact",
    "href": "topics/researchcloud.html#contact",
    "title": "SURF Research Cloud",
    "section": "Contact",
    "text": "Contact\nWondering if SURF Research Cloud fits your research needs? Please contact IT for Research"
  },
  {
    "objectID": "topics/dataset-and-software-registration.html",
    "href": "topics/dataset-and-software-registration.html",
    "title": "Dataset and Software Registration in PURE",
    "section": "",
    "text": "When you have finished finalizing a dataset or research software and are ready to archive it, there are many options available. Depending on the research and choices made earlier the archive provides the option to fill in descriptive fields for a dataset. The descriptions in the archives often are automatically created using metadata standards like DataCite or Dublin Core, or some other type of standard. See also section Metadata\nWhen registering a dataset or research software in an archive it is important to use unique identifiers to allow for increased findability and easy attribution & citation. Examples of this are:\n\nPersonal names: try to consistently use the same notation for all researchers and assistants that are included as authors\nORCID: using a unique identifier like this for all authors is recommended. More information is available here.\nInstitutional names: avoid using different versions (or language versions) of participating Institutes/organisations and departments. In the case of VU Amsterdam the official written name is: Vrije Universiteit Amsterdam. For each organisation or Institute that is included: try to make sure that the official name is used each time.\n\nSome archives also allow you to preregister your project/dataset/software. Examples are:\n\nOpen Science Framework (OSF) Registration\nZenodo & registration"
  },
  {
    "objectID": "topics/dataset-and-software-registration.html#registration-findability",
    "href": "topics/dataset-and-software-registration.html#registration-findability",
    "title": "Dataset and Software Registration in PURE",
    "section": "",
    "text": "When you have finished finalizing a dataset or research software and are ready to archive it, there are many options available. Depending on the research and choices made earlier the archive provides the option to fill in descriptive fields for a dataset. The descriptions in the archives often are automatically created using metadata standards like DataCite or Dublin Core, or some other type of standard. See also section Metadata\nWhen registering a dataset or research software in an archive it is important to use unique identifiers to allow for increased findability and easy attribution & citation. Examples of this are:\n\nPersonal names: try to consistently use the same notation for all researchers and assistants that are included as authors\nORCID: using a unique identifier like this for all authors is recommended. More information is available here.\nInstitutional names: avoid using different versions (or language versions) of participating Institutes/organisations and departments. In the case of VU Amsterdam the official written name is: Vrije Universiteit Amsterdam. For each organisation or Institute that is included: try to make sure that the official name is used each time.\n\nSome archives also allow you to preregister your project/dataset/software. Examples are:\n\nOpen Science Framework (OSF) Registration\nZenodo & registration"
  },
  {
    "objectID": "topics/dataset-and-software-registration.html#register-your-datasetsoftware-in-pure",
    "href": "topics/dataset-and-software-registration.html#register-your-datasetsoftware-in-pure",
    "title": "Dataset and Software Registration in PURE",
    "section": "Register your Dataset/Software in PURE",
    "text": "Register your Dataset/Software in PURE\nJust like your publications, data that you have collected for your research constitute research output, too. Therefore you are required to record your datasets and research software in PURE. Your datasets and research software can be of interest to others, which can in turn lead to new collaboration opportunities. Datasets and research software recorded in PURE also appear in reports that are used for research evaluations. Even if access to your dataset and research software is closed, you are required to register your dataset and research software in PURE. It is a record of the research, data collection and analysis that you have carried out.\n\nBenefits of recording your dataset/software in PURE\n\nIt increases the visibility and findability of your datasets and research software\nIt contributes to re-use and transparency\nIt boosts your collaboration opportunities\nIt counts towards research evaluations and assessments\n\n\n\nHow to register your dataset/software in PURE?\n\n\n\nAn image of PURE, indicating where to add a new dataset or software\n\n\n\nLog into the VU Research Portal (PURE) using your VU credentials\nClick on the “+” (plus) icon next to selecting “Datasets/Software” in the overview\nYou can fill in the form using the following manuals and read more about the various metadata in use (generic and subject specific):\n\ndataset manual (NL)\nsoftware manual (EN)\n\nClick on “Save” to store the registration"
  },
  {
    "objectID": "topics/persistent-identifier.html",
    "href": "topics/persistent-identifier.html",
    "title": "Persistent Identifier",
    "section": "",
    "text": "A Persistent Identifier (PID) is a durable reference to a digital dataset, document, website or other object. In the context of research data and software, it is essentially a URL that will never break. By using a Persistent Identifier, you make sure that your dataset will be findable well into the future when it is registered online (for example at DataCite. Another advantage is that it makes a digital object citable."
  },
  {
    "objectID": "topics/persistent-identifier.html#multiple-pid-systems",
    "href": "topics/persistent-identifier.html#multiple-pid-systems",
    "title": "Persistent Identifier",
    "section": "Multiple PID systems",
    "text": "Multiple PID systems\nThere are multiple PID systems, each with its own particular properties. Examples of widely used PIDs in the research domain include the following.\n\nDOI: A Digital Object Identifier can be used to refer to research data, research software and publications.\nORCiD: An Open Researcher and Contributor ID is used to create a researcher profile with a unique identification number.\nROR: The Research Organization Registry is a global register with persistent identifiers for research institutes.\n\nSee the Persistent Identifier guide of Netwerk Digitaal Erfgoed for a more elaborate overview. Apart from widely used domain-agnostic PIDs, there is a wide range of domain-specific unique identifiers that can be used. If you are interested in domain-specific identifiers, it is useful to ask colleagues in your department or discipline."
  },
  {
    "objectID": "topics/persistent-identifier.html#persistent-identifiers-for-data-and-software-in-repositories",
    "href": "topics/persistent-identifier.html#persistent-identifiers-for-data-and-software-in-repositories",
    "title": "Persistent Identifier",
    "section": "Persistent Identifiers for data and software in repositories",
    "text": "Persistent Identifiers for data and software in repositories\nPersistent Identifiers can be assigned to datasets and software upon their deposit in a repository. In many repositories, this is a DOI. Data repositories are entitled to generate Persistent Identifiers for data and software. This is one of the reasons why archiving and publishing data and software has to be done in a repository. After the process of uploading data or software to a repository, a Persistent Identifier will be generated. Upon publishing the data or software, the DOI is registered online (usually at DataCite when it concerns a dataset).\nSome repositories enable their users to reserve a Persistent Identifier before the publishing process has finished, so that you can include the Persistent Identifier in a publication before the data will be actually published, or to include the Persistent Identifier in a readme file. This is for example possible in Zenodo.\nThe repositories offered by VU Amsterdam, Yoda and DataverseNL provide DOIs for deposited datasets and software."
  },
  {
    "objectID": "topics/persistent-identifier.html#creating-and-using-an-orcid",
    "href": "topics/persistent-identifier.html#creating-and-using-an-orcid",
    "title": "Persistent Identifier",
    "section": "Creating and using an ORCiD",
    "text": "Creating and using an ORCiD\nResearchers can use an ORCiD to identify their research output as their work. You can request an ORCiD yourself. Instructions for setting up an ORCiD and connecting it to your VU research profile in PURE are available in this ORCiD LibGuide. An ORCiD is often asked for when you submit a publication or upload data or software to a repository. You can use your ORCiD record to create a research profile as well."
  },
  {
    "objectID": "topics/persistent-identifier.html#using-a-ror",
    "href": "topics/persistent-identifier.html#using-a-ror",
    "title": "Persistent Identifier",
    "section": "Using a ROR",
    "text": "Using a ROR\nResearchers can use the ROR for VU Amsterdam when filling metadata forms for their research output to show that their work has been created within their employment at VU Amsterdam."
  },
  {
    "objectID": "topics/qualtrics.html",
    "href": "topics/qualtrics.html",
    "title": "Qualtrics",
    "section": "",
    "text": "Qualtrics is a cloud-based subscription and software platform (SaaS) that enables users to create and manage online surveys. The Qualtrics survey tool can support a variety of (complex) survey design requirements by providing such functionalities as different question types, display and branching logic configuration and the use of embedded data and APIs."
  },
  {
    "objectID": "topics/qualtrics.html#what-is-it",
    "href": "topics/qualtrics.html#what-is-it",
    "title": "Qualtrics",
    "section": "",
    "text": "Qualtrics is a cloud-based subscription and software platform (SaaS) that enables users to create and manage online surveys. The Qualtrics survey tool can support a variety of (complex) survey design requirements by providing such functionalities as different question types, display and branching logic configuration and the use of embedded data and APIs."
  },
  {
    "objectID": "topics/qualtrics.html#what-can-it-be-used-for",
    "href": "topics/qualtrics.html#what-can-it-be-used-for",
    "title": "Qualtrics",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nAll VU students, employees and researchers are eligible to make use of a Qualtrics licence. VU’s Qualtrics licence usage is limited for creating, managing and collecting data for scientific research purposes only.\nQualtrics should not be used for non-scientific purposes such as the creation of registration or attendance lists and course evaluation surveys for example; instead users should go to other available tools such as MS Forms.\nVU Amsterdam holds an academic licence which includes non-standard, advanced features and functions, including but not limited to:\n\nFILE UPLOAD – a non-standard question type that allows respondents to upload a file along with their survey response\nSIGNATURE QUESTION – a non-standard question type that presents survey participants with an entry box where they can draw their signature.\nAPI INTEGRATION – an advanced licence feature that can be used to automate repetitive processes inside of Qualtrics or to pass information in and out of Qualtrics.\nOFFLINE SURVEY APP – an advanced licence feature that comprises a downloadable application available for iOS and Android that allows you to administer surveys on your mobile device or tablet without an internet connection."
  },
  {
    "objectID": "topics/qualtrics.html#how-to-request-access",
    "href": "topics/qualtrics.html#how-to-request-access",
    "title": "Qualtrics",
    "section": "How to request access",
    "text": "How to request access\n\nCreating and Accessing User Accounts\nVU Amsterdam Qualtrics Central Brand (hereafter VU’s Central Brand) at vuamsterdam.eu.qualtrics.com allows for user’s auto-enrolment, an automated account creation and registration process. Any user with an enabled VU email address may auto-enroll on VU’s Central Brand. The email address will function as the account’s username.\nVU’s Central Brand makes use of Single-Sign On (SSO). This means that users can log in to Qualtrics using VU’s internal login system. Multi-Factor Authentication (MFA) is mandatory to all Qualtrics users utilising the vuamsterdam brand (i.e. employees and researchers – students will be informed of upcoming project for MFA implementation). MFA acts as an additional layer of security to prevent unauthorised users from accessing accounts and resources, even when the password has been stolen. Qualtrics will use multi-factor authentication to validate user identity and provide quick and convenient access to authorised users.\nTo create a user account and access the Qualtrics environment at the Central Brand, please proceed as follows:\n\nGo to: https://vuamsterdam.eu.qualtrics.com\nOn the login page, choose: Vrije Universiteit SSO\nLog in with your VU account credentials (email address and password)\n\n\n\nVU’s central brand login page\n\n\nChoose “No, I don’t have a preexisting account here” when it is your first time enrolling the central brand\n\n\n\nQualtrics preexisting account\n\n\nClick [Sign In]\n\n\n\nQualtrics account created successfully\n\n\nTerms of Service or General Terms and Conditions for Qualtrics Services are presented for review and acceptance.\n\n\n\nQualtrics terms conditions\n\n\n\n\nIt is recommended to save VU’s Central Brand as a Favourite or Bookmark link for future reference.\n\n\n\nNote to Existing Users\n\nSecurity Settings: Login Error Disabled Account\nSecurity settings are in place that disable a user account after a certain amount of inactivity. This threshold is currently 12 months. This setting follows security requirements regarding User Account Management.\n\n\n\nNotification of disabled Qualtrics account\n\n\nA disabled account status does not affect its data.\nUsers who receive an error when trying to log back in after extended periods of inactivity ([User account is disabled]) should contact the RDM Support Desk to have their accounts re-enabled."
  },
  {
    "objectID": "topics/qualtrics.html#are-there-costs-involved",
    "href": "topics/qualtrics.html#are-there-costs-involved",
    "title": "Qualtrics",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThere are no costs involved. All students and researchers with a VU email address enabled can use Qualtrics for scientific purposes."
  },
  {
    "objectID": "topics/qualtrics.html#getting-started",
    "href": "topics/qualtrics.html#getting-started",
    "title": "Qualtrics",
    "section": "Getting Started",
    "text": "Getting Started\nThe following resources are available for you to get started with Qualtrics:\n\nQualtrics Basecamp\nbasecamp.qualtrics.com, the online learning platform where you have access to learning instructions on how to use Qualtrics.\n\n\nQualtrics Knowledge Base\nQualtrics offers access to an extensive library of knowledge base articles, including detailed instructions on how to use and configure (advance) features.\nQualtrics Knowledge Base library can be accessed directly at qualtrics.com/support\n\n\nQualtrics Community\nAsk questions to the Qualtrics community (platform of all Qualtrics users).\nWhen logging in choose “Sign in with SSO”, when asked “Enter your company’s Organization ID” fill in vuamsterdam."
  },
  {
    "objectID": "topics/qualtrics.html#contact",
    "href": "topics/qualtrics.html#contact",
    "title": "Qualtrics",
    "section": "Contact",
    "text": "Contact\nThe following support channels are available:\n\nFor general queries on how to use the tool, including the configuration of advanced features, please refer to the online documentation at the Qualtrics website.\nFor questions concerning survey design and faculty policies with regards to the usage of Qualtrics for your specific research area, please contact your faculty Data Steward/Privacy Champion (see Qualtrics Faculty Contact – Division Managers). Students should contact their course coordinator.\n\nIf you cannot login or encounter an error, for example when using collaboration or email distribution functionalities, please contact the RDM Support Desk (an FAQ is not available at the moment, but we are working on it)."
  },
  {
    "objectID": "topics/finding-existing-data.html",
    "href": "topics/finding-existing-data.html",
    "title": "Finding Existing Data",
    "section": "",
    "text": "Anything that can be used for analysis can be considered “data(sets)”. Many national and international organisations provide access to large datasets free of charge: this is called Open Data.\nDatasets may contain different kinds of data files, e.g. raw or edited/cleaned data, and macro or micro data. Raw data refers to the data as they are primarily collected, and includes all data, even the missed or mismatched pieces in the data file. Edited or cleaned data refers to data that have been tidied up for analysis and publication. Macro data and statistics are results based on micro data units and provide a general overview of the micro data. Although datasets can contain data of varying type or aggregation level, and there may be overlap between these definitions, each element can contain very important information.\nWhen re-using research data, scientists must be familiar with the rules and regulations governing data copyright, intellectual property rights, and laws governing sensitive or personal information. SURF has compiled a report on the legal status of raw data including information on the types of consent required for the re-use of data. Your 🔒 Privacy Champion can answer questions about the use of personal data. IXA can provide legal help with the re-use of data.\nSee also the ZonMw explanation of different kinds of property rights in the Netherlands (text available in Dutch only)."
  },
  {
    "objectID": "topics/finding-existing-data.html#re-using-existing-data",
    "href": "topics/finding-existing-data.html#re-using-existing-data",
    "title": "Finding Existing Data",
    "section": "",
    "text": "Anything that can be used for analysis can be considered “data(sets)”. Many national and international organisations provide access to large datasets free of charge: this is called Open Data.\nDatasets may contain different kinds of data files, e.g. raw or edited/cleaned data, and macro or micro data. Raw data refers to the data as they are primarily collected, and includes all data, even the missed or mismatched pieces in the data file. Edited or cleaned data refers to data that have been tidied up for analysis and publication. Macro data and statistics are results based on micro data units and provide a general overview of the micro data. Although datasets can contain data of varying type or aggregation level, and there may be overlap between these definitions, each element can contain very important information.\nWhen re-using research data, scientists must be familiar with the rules and regulations governing data copyright, intellectual property rights, and laws governing sensitive or personal information. SURF has compiled a report on the legal status of raw data including information on the types of consent required for the re-use of data. Your 🔒 Privacy Champion can answer questions about the use of personal data. IXA can provide legal help with the re-use of data.\nSee also the ZonMw explanation of different kinds of property rights in the Netherlands (text available in Dutch only)."
  },
  {
    "objectID": "topics/finding-existing-data.html#sources-for-finding-existing-datasets",
    "href": "topics/finding-existing-data.html#sources-for-finding-existing-datasets",
    "title": "Finding Existing Data",
    "section": "Sources for Finding Existing Datasets",
    "text": "Sources for Finding Existing Datasets\nThe number of datasets that are available grows rapidly. Datasets are made available in many formats, by many people or organizations. Some datasets are raw files and some are specifically organised and formatted as databases that require a licence or subscription to use them. The library of VU Amsterdam has collected links to some of the data repositories used and has licensed several databases.\n\nPopular Free and Licensed Databases: These can be found with LibSearch Advanced.\n\nIf you need help finding & using free or licensed sources you can contact the Research Data Services Helpdesk. For students and personnel in the fields of economics, finance, or organisation science a separate LibGuide has been created to help them find and use/re-use data.\nYou can also start looking for data in these four places:\n\nThe literature. Research articles may point you to the data that they are based on. Sometimes, (part of) the data are added to the article as supplementary files, and sometimes the data are published separately in a data repository. In the latter case, the article usually provides a clear reference to the published dataset. Some datasets may even be specifically published in Data Journals.\nScientific data repositories. Data repositories are platforms used to access and archive research data. Universities often provide a repository for data archiving, but other platforms arranged by discipline or by country also exist. Some repositories are only accessible to consortium members, whereas others are free of charge. Many universities in the Netherlands use DataverseNL to archive datasets for the mid-term. Long-term archiving is provided by the national research data archives DANS and 4TU.Research Data. In Europe, B2SHARE and Zenodo are platforms used to access research data. Data repositories can be accessed by searching by topic or country using Re3data, a data repository registry. VU Amsterdam has its own research portal, PURE, where researchers register their datasets. You can find instructions on how to register your own dataset in PURE on the Dataset Registration page of this LibGuide.\nData search engines. Search engines allow you to quickly browse data sets and supplementary data files published by researchers. They cover data sets from many sources. This makes them useful for quick orientation on a topic. Example of a search engines are: DataCite, Google DataSet Search.\nData portals of (governmental) organisations. Organisations that regularly collect (statistical) data sometimes offer these data through their own portal. An example is Eurostat, which collects and disseminates statistics at the European level, by country and by theme. Some of these websites have been linked in the Finding data LibGuide."
  },
  {
    "objectID": "topics/finding-existing-data.html#data-sources-for-vu-researchers",
    "href": "topics/finding-existing-data.html#data-sources-for-vu-researchers",
    "title": "Finding Existing Data",
    "section": "Data Sources for VU Researchers",
    "text": "Data Sources for VU Researchers\nResearchers from VU Amsterdam have also developed some databases containing data collected during research. See here for some examples:\n\nNederlands Tweelingenregister (Netherlands Twin Register) The database contains data on twins and their families and was created to do research on the relationship between genetics and growth, development, personality, behaviour, diseases, mental health and all kinds of risks.\nGeoplaza VU - the portal for all matters related to GIS (Geographical Information Systems) and geodata at VU Amsterdam. It offers students and employers a platform to exchange, examine and download digital map material.\nDutch monasteries - database with information about Dutch monasteries of the Middle Ages.\nSlave owners in Amsterdam 1863 - the place of living of owners of slaves in Amsterdam in 1863, visualized in GeoPlaza.\nDeaths at the Borders Database - collection of official, state-produced evidence on people who died while attempting to reach southern EU countries from the Balkans, the Middle East, and North & West Africa, and whose bodies were found in or brought to Europe.\nDatasets published by VU Researchers can be found at the VU Research Portal."
  },
  {
    "objectID": "topics/selecting-data.html",
    "href": "topics/selecting-data.html",
    "title": "Storing vs. Archiving Data",
    "section": "",
    "text": "There is a difference between storing and archiving data. Storing refers to putting the data in a safe location while the research is ongoing. Because you are still working on the data, the data still change from time to time: they are cleaned, and analysed, and this analysis generates output. As the image below illustrates, storing could be like cooking a dish: you are cleaning and combining ingredients.\nArchiving, on the other hand, refers to putting the data in a safe place after the research is finished. The data are in a fixed state, they don’t change anymore. Archiving is done for verification purposes: so others can check that your research is sound. Or: it is done so that others can reuse the resulting dataset. There is also a difference between archiving and publishing, but in essence, archiving and publishing happen at a similar moment and for both, data do not change anymore.\nThis illustration is created by Scriberia with The Turing Way community. Used under a CC-BY 4.0 licence. DOI: 10.5281/zenodo.3332807"
  },
  {
    "objectID": "topics/selecting-data.html#selecting-data-for-archiving",
    "href": "topics/selecting-data.html#selecting-data-for-archiving",
    "title": "Storing vs. Archiving Data",
    "section": "Selecting Data for Archiving",
    "text": "Selecting Data for Archiving\nThere are various reasons to archive your data: replication, longitudinal research, data being unique or expensive to collect, re-usability and acceleration of research inside or outside your own discipline. It is VU policy to archive your data for (at least) 10 years after the last publication based on the dataset. Part of preparing your dataset for archiving is appraising and selecting your data.\n\nMake a selection before archiving your data\nDuring your research you may accumulate a lot of data, some of which will be eligible for archiving. It is impossible to preserve all data infinitely. Archiving all digital data leads to high costs for storage itself and for maintaining and managing this ever-growing volume of data and their metadata; it may also lead to decline in discoverability (see the website of the Digital Curation Centre). For those reasons, it is crucial that you make a selection.\n\n\nRemove redundant and sensitive data\nSelecting data means making choices about what to keep for the long term, and what data to archive securely and what data to publish openly. This means that you have to decide whether your dataset contains data that need to be removed or separated. Reasons to exclude data from publishing include (but are not limited to):\n\ndata are redundant\ndata concern temporary byproducts which are irrelevant for future use\ndata contain material that is sensitive, for example personal data in the sense of the GDPR, like consent forms, voice recordings, DNA data; state secrets; data that are sensitive to competition in a commercial sense. These data need to be separated from other data and archived securely\npreserving data for the long term is in breach of contractual arrangements with your consortium partners or other parties involved\n\nIn preparing your dataset for archiving, the first step is to determine which parts of your data are sensitive, which can then be separated from the other data. Redundant data can be removed altogether.\n\n\nDifferent forms of datasets for different purposes\nOnce you have separated the sensitive data from the rest of your dataset, you have to think about what to do with these sensitive materials. In some cases they may be destroyed, but you may also opt for archiving multiple datasets. For example, you may want to archive your dataset in more than one form depending on the purpose. For example:\n\nOne for reusability to share\nA second one that contains the sensitive data, and needs to be handled differently.\n\nFor the first, the non-sensitive data can be stored in an archive under restricted or open access conditions, so that you can share it and link it to publications. For the second, you need to make a separate selection, so the sensitive part can be stored safely in a secure archive (a so-called offline or dark archive). In the metadata of both archives you can create stable links between the two datasets using persistent identifiers.\n\n\nWhat to appraise for archiving\nThere are several factors that determine what data to select for archiving. For example, whether data are unique, expensive to reproduce, or if your funder requires that you make your data publicly available. This might also help you or your department to think about a standard policy or procedures for what needs to be kept, what is vital for reproducing research or reuse in future research projects.\nMore information on selecting data:\n\nTjalsma, H. & Rombouts, J. (2011). Selection of research data: Guidelines for appraising and selecting research data. Data Archiving and Networked Services (DANS).\nDigital Curation Centre (DCC): Whyte, A. & Wilson, A. (2010). How to appraise and select research data for curation. DCC How-to Guides. Edinburgh: Digital Curation Centre.\nResearch Data Netherlands: Data selection."
  },
  {
    "objectID": "topics/selecting-data.html#data-set-packaging-which-files-should-be-part-of-my-dataset",
    "href": "topics/selecting-data.html#data-set-packaging-which-files-should-be-part-of-my-dataset",
    "title": "Storing vs. Archiving Data",
    "section": "Data Set Packaging: Which Files should be Part of my Dataset?",
    "text": "Data Set Packaging: Which Files should be Part of my Dataset?\nA dataset consists of the following documents:\n\nRaw or cleaned data (if the cleaned data has been archived, the provenance documentation is also required)\nProject documentation\nCodebook or protocol\nLogbook or lab journal (when available, dependent on the discipline)\nSoftware (& version) needed to open the files when no preferred formats for the data can be provided\n\nSee the topic Metadata for more information about documenting your data.\nDepending on the research project it may be that more than one dataset is stored in more than one repository. Make sure that each consortium partner that collects data also stores all necessary data that is required for transparency and verification. A Consortium Agreement and Data Management Plan will include information on who is responsible for archiving the data."
  },
  {
    "objectID": "topics/ada.html",
    "href": "topics/ada.html",
    "title": "ADA HPC",
    "section": "",
    "text": "ADA is a compute cluster for research at the Vrije Universiteit Amsterdam. ADA is named in honor of Ada Lovelace, the pioneering mathematician and writer known for her work on Charles Babbage’s Analytical Engine. She was the first to recognise that the machine had applications beyond pure calculation. ADA is the rebranded name of our previous cluster, BAZIS, and is maintained by the IT for Research team.\nADA is a heterogenious cluster composed of partitions and servers financed by various VU research departments and the VU IT department. The cluster is particularly useful for executing multi-node computations that are not possible on the general VU compute servers but do not require the scale of the National Supercomputer, Snellius.\nADA users are granted access to a set of compute partitions based on the resources owned by their research department. Users not affiliated with a research department that owns cluster hardware can get access to the general (IT) partition.\nA large collection of tools, compilers and libraries is available for your analysis, and your data on SciStor are directly accessible from ADA."
  },
  {
    "objectID": "topics/ada.html#what-is-it",
    "href": "topics/ada.html#what-is-it",
    "title": "ADA HPC",
    "section": "",
    "text": "ADA is a compute cluster for research at the Vrije Universiteit Amsterdam. ADA is named in honor of Ada Lovelace, the pioneering mathematician and writer known for her work on Charles Babbage’s Analytical Engine. She was the first to recognise that the machine had applications beyond pure calculation. ADA is the rebranded name of our previous cluster, BAZIS, and is maintained by the IT for Research team.\nADA is a heterogenious cluster composed of partitions and servers financed by various VU research departments and the VU IT department. The cluster is particularly useful for executing multi-node computations that are not possible on the general VU compute servers but do not require the scale of the National Supercomputer, Snellius.\nADA users are granted access to a set of compute partitions based on the resources owned by their research department. Users not affiliated with a research department that owns cluster hardware can get access to the general (IT) partition.\nA large collection of tools, compilers and libraries is available for your analysis, and your data on SciStor are directly accessible from ADA."
  },
  {
    "objectID": "topics/ada.html#what-can-it-be-used-for",
    "href": "topics/ada.html#what-can-it-be-used-for",
    "title": "ADA HPC",
    "section": "What can it be used for?",
    "text": "What can it be used for?\nMost researchers start out by running their analysis tools on their laptop. The performance of a laptop is limited however. You might find your analysis takes up so many resources that your laptop becomes unusable for other tasks, or tasks take so long that you have to find a way to keep your laptop running overnight. For example a lot of AI tasks, such as running Large Language Models (LLMs), require a dedicated GPU, which most laptops don’t have. These tasks will run very slowly, or not at all.\nA next step might be purchasing a Workstation with more performance and maybe a GPU. You can run the same applications as your laptop and leave it running overnight and during weekends. The modern VU offices are not geared for workstations, however, so that might not be possible.\nThe point where your laptop or even a workstation becomes unusable for your analysis workflow is when you should consider HPC. HPC nodes have a large amount of RAM, many processor cores and often multiple GPUs. HPC clusters work with a queueing system, meaning the system will wait until enough resources are available to run your job and it will run multiple jobs simultaneously so its resources are used optimally.\nBe aware that it is generally not possible to run graphical desktop applications (such as RStudio, SPSS or ArcGIS) on an HPC cluster. Your analysis needs to be able to run as a script that can be started from a Linux command line. This means there is a learning curve to use HPC, especially if you are not used to a Command-line Interface (CLI) and scripting.\nCLI and scripting skills are very useful to have for every researcher, but if you feel you do not have the time to learn these skills there might be other options available such as the VU Compute Hub or SURF Research Cloud where you can run some graphical tools.\nAt the moment the community partition does not include GPU resources. If you have tasks that need a GPU (such as Machine Learning) you can apply for access to the national HPC infrastructure Snellius or consider buying ADA compute nodes."
  },
  {
    "objectID": "topics/ada.html#how-to-request-access",
    "href": "topics/ada.html#how-to-request-access",
    "title": "ADA HPC",
    "section": "How to request access",
    "text": "How to request access\nA form to request an account on ADA can be found on 🔒 VU Service Portal under IT &gt; My work field &gt; Research &gt; HPC Cluster Computing &gt; New ADA HPC Cluster Computing."
  },
  {
    "objectID": "topics/ada.html#are-there-costs-involved",
    "href": "topics/ada.html#are-there-costs-involved",
    "title": "ADA HPC",
    "section": "Are there costs involved?",
    "text": "Are there costs involved?\nThe ADA cluster community nodes are free to use for VU researchers, although resources are limited.\n\nBuying dedicated compute nodes\nIf your research projects require heavy usage of HPC you can consider spending part of your research budget to buy compute hardware for your group. Please contact IT for Research for more information on what is possible."
  },
  {
    "objectID": "topics/ada.html#getting-started",
    "href": "topics/ada.html#getting-started",
    "title": "ADA HPC",
    "section": "Getting started",
    "text": "Getting started\nThere is a guide with ADA tips & tricks in the Handbook.\nAlso take a look at the SURF wiki Snellius pages, they contain a lot of information that applies to ADA as well.\nSURF organises regular “Introduction to Supercomputing” training sessions, these are free to attend for VU researchers. The course is aimed at using Snellius, but what you learn is applicable to ADA as well. Please consult the SURF Agenda for dates and registration."
  },
  {
    "objectID": "topics/ada.html#contact",
    "href": "topics/ada.html#contact",
    "title": "ADA HPC",
    "section": "Contact",
    "text": "Contact\nWondering if ADA fits your research needs? Please contact IT for Research"
  }
]